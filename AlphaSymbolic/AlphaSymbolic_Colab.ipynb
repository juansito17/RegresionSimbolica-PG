{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install gradio torch torchvision torchaudio scipy matplotlib sympy\n",
        "\n",
        "# Create directories\n",
        "!mkdir -p core data search ui utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/environment.py\n",
        "import gymnasium as gym\nfrom gymnasium import spaces\nimport numpy as np\nfrom core.grammar import VOCABULARY, OPERATORS, TOKEN_TO_ID, ExpressionTree\nfrom data.synthetic_data import DataGenerator\n\nclass SymbolicEnv(gym.Env):\n    def __init__(self, max_length=50):\n        super(SymbolicEnv, self).__init__()\n        \n        self.vocab_size = len(VOCABULARY)\n        self.max_length = max_length\n        self.vocab = VOCABULARY\n        \n        # Action space: Choose a token from the vocabulary\n        self.action_space = spaces.Discrete(self.vocab_size)\n        \n        # Observation space: \n        # 1. Current token sequence (padded)\n        # 2. X values (fixed size for simplicity)\n        # 3. Y values\n        # For this prototype we will expose a dictionary observation\n        self.observation_space = spaces.Dict({\n            \"sequence\": spaces.Box(low=0, high=self.vocab_size, shape=(max_length,), dtype=np.int32),\n            \"x\": spaces.Box(low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32),\n            \"y\": spaces.Box(low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32)\n        })\n        \n        self.data_gen = DataGenerator(max_depth=4)\n        self.current_problem = None\n        self.current_sequence = []\n        self.open_branches = 0\n        \n    def reset(self, seed=None, options=None):\n        super().reset(seed=seed)\n        \n        # Generate a new problem (X, Y)\n        # In a real scenario, this could be sampled from a fixed dataset\n        batch = self.data_gen.generate_batch(1, point_count=10)\n        self.current_problem = batch[0]\n        \n        self.current_sequence = []\n        self.open_branches = 1 # Start expecting a root node\n        \n        return self._get_obs(), {}\n\n    def step(self, action_id):\n        token = self.vocab[action_id]\n        self.current_sequence.append(token)\n        \n        # Update open branches\n        if token in OPERATORS:\n            arity = OPERATORS[token]\n            self.open_branches += (arity - 1)\n        else:\n            self.open_branches -= 1\n            \n        term = False\n        trunc = False\n        reward = 0.0\n        \n        # Check completion\n        if self.open_branches == 0:\n            term = True\n            # Tree is complete, evaluate\n            reward = self._calculate_reward()\n        elif self.open_branches < 0:\n            # Should not happen if we mask actions, but for safety\n            term = True\n            reward = -100.0 # Syntax error penalty\n        elif len(self.current_sequence) >= self.max_length:\n            trunc = True\n            reward = -10.0 # Incomplete penalty\n            \n        return self._get_obs(), reward, term, trunc, {}\n\n    def _get_obs(self):\n        # Convert sequence to IDs and pad\n        seq_ids = [TOKEN_TO_ID[t] for t in self.current_sequence]\n        padded_seq = np.zeros(self.max_length, dtype=np.int32)\n        padded_seq[:len(seq_ids)] = seq_ids\n        \n        return {\n            \"sequence\": padded_seq,\n            \"x\": self.current_problem['x'].astype(np.float32),\n            \"y\": self.current_problem['y'].astype(np.float32)\n        }\n\n    def _calculate_reward(self):\n        try:\n            tree = ExpressionTree(self.current_sequence)\n            if not tree.is_valid:\n                return -100.0\n            \n            y_pred = tree.evaluate(self.current_problem['x'])\n            \n            # Root Mean Squared Error (RMSE)\n            mse = np.mean((y_pred - self.current_problem['y'])**2)\n            rmse = np.sqrt(mse)\n            \n            if np.isnan(rmse) or np.isinf(rmse):\n                return -1000.0\n                \n            # Reward is negative RMSE\n            # We want to maximize reward -> minimize RMSE\n            # Normalize or scale? simpler is just -RMSE\n            return -rmse\n            \n        except Exception:\n            return -100.0\n\nif __name__ == \"__main__\":\n    env = SymbolicEnv()\n    obs, _ = env.reset()\n    print(\"Initial Observation Keys:\", obs.keys())\n    \n    # Simulate a few steps for x + x\n    # Prefix: + x x\n    actions = ['+', 'x', 'x']\n    tot_reward = 0\n    for tok in actions:\n        aid = TOKEN_TO_ID[tok]\n        obs, reward, term, trunc, _ = env.step(aid)\n        print(f\"Action: {tok}, Reward: {reward}, Term: {term}, Branches: {env.open_branches}\")\n        tot_reward += reward\n        if term: break\n    \n    print(f\"Total Reward: {tot_reward}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/grammar.py\n",
        "import numpy as np\nfrom scipy.special import gamma as scipy_gamma\nimport math\n\n# Supported operators and their arity (number of arguments)\nOPERATORS = {\n    # Binary\n    '+': 2,\n    '-': 2,\n    '*': 2,\n    '/': 2,\n    'pow': 2,\n    'mod': 2,\n    # Unary\n    'sin': 1,\n    'cos': 1,\n    'tan': 1,\n    'exp': 1,\n    'log': 1,\n    'sqrt': 1,\n    'abs': 1,\n    'floor': 1,\n    'ceil': 1,\n    'gamma': 1,  # Gamma function (for combinatorics)\n    'neg': 1,    # Negation\n    'sign': 1,\n    'max': 2,\n    'min': 2,\n}\n\n# Terminal tokens\nVARIABLES = ['x']\n# 'C' is a placeholder for learnable constants\nCONSTANTS = ['C', '0', '1', '2', '3', '5', '10', 'pi', 'e']\n\n# Full Vocabulary\nVOCABULARY = list(OPERATORS.keys()) + VARIABLES + CONSTANTS\nTOKEN_TO_ID = {token: i for i, token in enumerate(VOCABULARY)}\nID_TO_TOKEN = {i: token for token, i in TOKEN_TO_ID.items()}\n\n# Special token for start of sequence\nSOS_TOKEN = '<SOS>'\nEOS_TOKEN = '<EOS>'\nPAD_TOKEN = '<PAD>'\n\nclass Node:\n    def __init__(self, value, children=None):\n        self.value = value\n        self.children = children if children else []\n\n    def __repr__(self):\n        if not self.children:\n            return str(self.value)\n        return f\"({self.value} \" + \" \".join([str(c) for c in self.children]) + \")\"\n    \n    def to_infix(self):\n        if not self.children:\n            return str(self.value)\n        \n        op = self.value\n        if len(self.children) == 1:\n            return f\"{op}({self.children[0].to_infix()})\"\n        elif len(self.children) == 2:\n            if op == 'pow':\n                return f\"({self.children[0].to_infix()} ^ {self.children[1].to_infix()})\"\n            elif op == 'mod':\n                return f\"({self.children[0].to_infix()} % {self.children[1].to_infix()})\"\n            return f\"({self.children[0].to_infix()} {op} {self.children[1].to_infix()})\"\n        return str(self.value)\n    \n    def count_constants(self):\n        \"\"\"Count the number of 'C' placeholders in the tree.\"\"\"\n        count = 1 if self.value == 'C' else 0\n        for child in self.children:\n            count += child.count_constants()\n        return count\n    \n    def get_constant_positions(self, path=None):\n        \"\"\"Returns a list of paths to all 'C' nodes for optimization.\"\"\"\n        if path is None:\n            path = []\n        positions = []\n        if self.value == 'C':\n            positions.append(path.copy())\n        for i, child in enumerate(self.children):\n            positions.extend(child.get_constant_positions(path + [i]))\n        return positions\n\n\nclass ExpressionTree:\n    def __init__(self, token_list):\n        \"\"\"\n        Parses a list of tokens in Pre-order traversal (Prefix notation)\n        Example: ['+', 'x', 'sin', 'x'] -> x + sin(x)\n        \"\"\"\n        self.tokens = token_list\n        try:\n            self.root, remaining = self._build_tree(token_list)\n            if remaining:\n                raise ValueError(\"Tokens remained after building tree\")\n            self.is_valid = True\n        except Exception:\n            self.root = None\n            self.is_valid = False\n\n    def _build_tree(self, tokens):\n        if not tokens:\n            raise ValueError(\"Empty token list\")\n        \n        token = tokens[0]\n        remaining = tokens[1:]\n        \n        if token in OPERATORS:\n            arity = OPERATORS[token]\n            children = []\n            for _ in range(arity):\n                child, remaining = self._build_tree(remaining)\n                children.append(child)\n            return Node(token, children), remaining\n        elif token in VARIABLES or token in CONSTANTS:\n            return Node(token), remaining\n        else:\n            # Try to parse as float literal\n            try:\n                float(token)\n                return Node(token), remaining\n            except:\n                raise ValueError(f\"Unknown token: {token}\")\n\n    def evaluate(self, x_values, constants=None):\n        \"\"\"\n        Evaluates the expression tree for a given array of x values.\n        constants: optional dict mapping path tuples to constant values\n        Returns a numpy array of results.\n        \"\"\"\n        if not self.is_valid:\n            return np.full_like(x_values, np.nan, dtype=np.float64)\n        return self._eval_node(self.root, x_values, constants, path=[])\n\n    def _eval_node(self, node, x, constants=None, path=None):\n        val = node.value\n        \n        if val == 'x':\n            return x.astype(np.float64)\n        if val == 'pi':\n            return np.full_like(x, np.pi, dtype=np.float64)\n        if val == 'e':\n            return np.full_like(x, np.e, dtype=np.float64)\n        if val == 'C':\n            # Check if we have an optimized constant for this position\n            if constants is not None and tuple(path) in constants:\n                return np.full_like(x, constants[tuple(path)], dtype=np.float64)\n            return np.full_like(x, 1.0, dtype=np.float64)  # Default constant = 1\n        \n        # Check for numeric constants\n        try:\n            return np.full_like(x, float(val), dtype=np.float64)\n        except:\n            pass\n            \n        # Recursive evaluation\n        args = []\n        for i, c in enumerate(node.children):\n            args.append(self._eval_node(c, x, constants, path + [i] if path is not None else None))\n        \n        # Operators\n        with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n            if val == '+': return args[0] + args[1]\n            if val == '-': return args[0] - args[1]\n            if val == '*': return args[0] * args[1]\n            if val == '/': \n                return np.divide(args[0], args[1], out=np.zeros_like(x, dtype=np.float64), where=args[1]!=0)\n            if val == 'pow':\n                # Safe power\n                return np.power(np.abs(args[0]) + 1e-10, np.clip(args[1], -10, 10))\n            if val == 'mod':\n                return np.mod(args[0], args[1] + 1e-10)\n            if val == 'sin': return np.sin(args[0])\n            if val == 'cos': return np.cos(args[0])\n            if val == 'tan': return np.tan(args[0])\n            if val == 'exp': \n                return np.exp(np.clip(args[0], -100, 100))\n            if val == 'log': \n                return np.log(np.abs(args[0]) + 1e-10)\n            if val == 'sqrt':\n                return np.sqrt(np.abs(args[0]))\n            if val == 'abs':\n                return np.abs(args[0])\n            if val == 'floor':\n                return np.floor(args[0])\n            if val == 'ceil':\n                return np.ceil(args[0])\n            if val == 'gamma':\n                # Safe gamma (clip to avoid overflow)\n                clipped = np.clip(args[0], -50, 50)\n                result = np.zeros_like(clipped)\n                valid = clipped > 0\n                result[valid] = scipy_gamma(clipped[valid])\n                return result\n            if val == 'neg':\n                return -args[0]\n            if val == 'sign':\n                return np.sign(args[0])\n            if val == 'max':\n                return np.maximum(args[0], args[1])\n            if val == 'min':\n                return np.minimum(args[0], args[1])\n                \n        return np.zeros_like(x, dtype=np.float64)\n\n    def get_infix(self):\n        if not self.is_valid:\n            return \"Invalid\"\n        return self.root.to_infix()\n    \n    def count_constants(self):\n        if not self.is_valid:\n            return 0\n        return self.root.count_constants()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/model.py\n",
        "import torch\nimport torch.nn as nn\nimport numpy as np\n\nclass AlphaSymbolicModel(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_encoder_layers=2, num_decoder_layers=2, max_seq_len=50):\n        super(AlphaSymbolicModel, self).__init__()\n        \n        self.d_model = d_model\n        \n        # 1. Point Encoder: Processes pairs of (x, y)\n        # Input dim: 2 (x value, y value)\n        self.point_embedding = nn.Linear(2, d_model)\n        \n        # We use a standard Transformer Encoder for the \"Problem Embedding\"\n        # Since points are a set, we don't necessarily need positional encoding, \n        # but the Transformer will process them as a sequence.\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n        self.problem_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n        \n        # 2. Formula Decoder: Generates tokens\n        self.token_embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_encoder = PositionalEncoding(d_model, max_len=max_seq_len)\n        \n        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n        self.formula_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n        \n        # 3. Heads\n        self.policy_head = nn.Linear(d_model, vocab_size)\n        self.value_head = nn.Sequential(\n            nn.Linear(d_model, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1) # Expected negative RMSE\n        )\n        \n    def forward(self, x_values, y_values, formula_input, formula_mask=None):\n        \"\"\"\n        x_values: [batch, num_points]\n        y_values: [batch, num_points]\n        formula_input: [batch, seq_len] (Token IDs)\n        formula_mask: Optional mask for the decoder (causal mask)\n        \"\"\"\n        batch_size, num_points = x_values.shape\n        \n        # -- Problem Encoding --\n        # Stack x and y: [batch, num_points, 2]\n        points = torch.stack([x_values, y_values], dim=2)\n        \n        # Project to d_model\n        points_emb = self.point_embedding(points) # [batch, num_points, d_model]\n        \n        # Encode problem (memory for decoder)\n        memory = self.problem_encoder(points_emb)\n        \n        # -- Formula Decoding --\n        # Embed tokens\n        tgt = self.token_embedding(formula_input) # [batch, seq_len, d_model]\n        tgt = self.pos_encoder(tgt)\n        \n        # Decode\n        # memory is [batch, num_points, d_model]\n        # tgt is [batch, seq_len, d_model]\n        if formula_mask is None:\n             # Create causal mask\n            seq_len = formula_input.size(1)\n            formula_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(formula_input.device)\n\n        output = self.formula_decoder(tgt, memory, tgt_mask=formula_mask)\n        \n        # -- Heads --\n        # Policy: distribution over vocab for each token position\n        logits = self.policy_head(output) # [batch, seq_len, vocab_size]\n        \n        # Value: estimate value from the LAST token's state\n        # (Assuming the last token summarizes the current state)\n        last_token_output = output[:, -1, :] # [batch, d_model]\n        value = self.value_head(last_token_output) # [batch, 1]\n        \n        return logits, value\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        \n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        \n        self.register_buffer('pe', pe.unsqueeze(0))\n\n    def forward(self, x):\n        # x: [batch, seq_len, d_model]\n        x = x + self.pe[:, :x.size(1), :]\n        return x\n\nif __name__ == \"__main__\":\n    # Smoke Test\n    vocab_size = 20\n    model = AlphaSymbolicModel(vocab_size=vocab_size, d_model=32)\n    \n    # Dummy data\n    bs = 2\n    points = 10\n    x = torch.randn(bs, points)\n    y = torch.randn(bs, points)\n    \n    # Formula input (start token + some tokens)\n    seq = torch.randint(0, vocab_size, (bs, 5))\n    \n    logits, value = model(x, y, seq)\n    \n    print(\"Logits shape:\", logits.shape) # Should be [2, 5, 20]\n    print(\"Value shape:\", value.shape)   # Should be [2, 1]\n    print(\"Smoke test passed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/benchmark_data.py\n",
        "import numpy as np\n\n# Standard Benchmark Problems\n# Levels: 1 (Easy), 2 (Medium), 3 (Hard)\n\nBENCHMARK_SUITE = [\n    # --- Level 1: Polynomials & Basic Arithmetic ---\n    {\n        'id': 'p1',\n        'name': 'Lineal',\n        'formula_str': '2.5 * x + 1.0',\n        'lambda': lambda x: 2.5 * x + 1.0,\n        'domain': (-10, 10),\n        'points': 20,\n        'level': 1\n    },\n    {\n        'id': 'p2',\n        'name': 'Cuadratica Simple',\n        'formula_str': 'x * x',\n        'lambda': lambda x: x**2,\n        'domain': (-5, 5),\n        'points': 20,\n        'level': 1\n    },\n    {\n        'id': 'p3',\n        'name': 'Polinomio Cubico',\n        'formula_str': 'x**3 + x**2',\n        'lambda': lambda x: x**3 + x**2,\n        'domain': (-3, 3),\n        'points': 20,\n        'level': 1\n    },\n    \n    # --- Level 2: Trigonometric & Transcendental ---\n    {\n        'id': 'p4',\n        'name': 'Seno Basico',\n        'formula_str': 'sin(x)',\n        'lambda': lambda x: np.sin(x),\n        'domain': (-np.pi, np.pi),\n        'points': 30,\n        'level': 2\n    },\n    {\n        'id': 'p5',\n        'name': 'Coseno Desplazado',\n        'formula_str': 'cos(x) + 1',\n        'lambda': lambda x: np.cos(x) + 1,\n        'domain': (-np.pi, np.pi),\n        'points': 30,\n        'level': 2\n    },\n    {\n        'id': 'p6',\n        'name': 'Exponencial Simple',\n        'formula_str': 'exp(x)',\n        'lambda': lambda x: np.exp(x),\n        'domain': (-2, 2), # Small domain to avoid explosion\n        'points': 20,\n        'level': 2\n    },\n    \n    # --- Level 3: Physics / Complex ---\n    {\n        'id': 'p7',\n        'name': 'Damped Oscillation',\n        'formula_str': 'exp(-x) * sin(2*x)',\n        'lambda': lambda x: np.exp(-x) * np.sin(2*x),\n        'domain': (0, 4),\n        'points': 40,\n        'level': 3\n    },\n    {\n        'id': 'p8',\n        'name': 'Gaussian',\n        'formula_str': 'exp(-x**2)',\n        'lambda': lambda x: np.exp(-x**2),\n        'domain': (-3, 3),\n        'points': 30,\n        'level': 3\n    },\n    {\n        'id': 'p9',\n        'name': 'Nguyen-3 (x^3 + x^2 + x)',\n        'formula_str': 'x**3 + x**2 + x',\n        'lambda': lambda x: x**3 + x**2 + x,\n        'domain': (-2, 2),\n        'points': 20,\n        'level': 3\n    },\n    {\n        'id': 'p10',\n        'name': 'Rational Function',\n        'formula_str': 'x / (1 + x**2)',\n        'lambda': lambda x: x / (1 + x**2),\n        'domain': (-4, 4),\n        'points': 30,\n        'level': 3\n    }\n]\n\ndef get_benchmark_data(problem_id):\n    \"\"\"Returns (x, y) for a specific problem ID.\"\"\"\n    for p in BENCHMARK_SUITE:\n        if p['id'] == problem_id:\n            x = np.linspace(p['domain'][0], p['domain'][1], p['points'])\n            y = p['lambda'](x)\n            return x, y, p\n    return None, None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/pattern_memory.py\n",
        "\"\"\"\nPattern Memory for AlphaSymbolic.\nStores successful formula patterns for experience replay and warm-starting searches.\n\"\"\"\nimport json\nimport os\nfrom datetime import datetime\n\nclass PatternMemory:\n    def __init__(self, path=\"pattern_memory.json\", max_patterns=500):\n        self.path = path\n        self.max_patterns = max_patterns\n        self.patterns = {}  # pattern_str -> PatternInfo\n        self.load()\n    \n    def load(self):\n        \"\"\"Load patterns from disk.\"\"\"\n        if os.path.exists(self.path):\n            try:\n                with open(self.path, 'r') as f:\n                    data = json.load(f)\n                    self.patterns = data.get('patterns', {})\n                print(f\"Loaded {len(self.patterns)} patterns from {self.path}\")\n            except:\n                self.patterns = {}\n    \n    def save(self):\n        \"\"\"Save patterns to disk.\"\"\"\n        with open(self.path, 'w') as f:\n            json.dump({\n                'patterns': self.patterns,\n                'updated': datetime.now().isoformat()\n            }, f, indent=2)\n    \n    def record(self, tokens, rmse, formula_str):\n        \"\"\"\n        Record a successful pattern.\n        \"\"\"\n        # Extract structure (replace constants with 'C')\n        structure = self._extract_structure(tokens)\n        key = ' '.join(structure)\n        \n        if key not in self.patterns:\n            self.patterns[key] = {\n                'structure': structure,\n                'best_rmse': rmse,\n                'uses': 0,\n                'examples': []\n            }\n        \n        info = self.patterns[key]\n        info['uses'] += 1\n        \n        if rmse < info['best_rmse']:\n            info['best_rmse'] = rmse\n        \n        # Store some examples\n        if len(info['examples']) < 5:\n            info['examples'].append({\n                'tokens': tokens,\n                'formula': formula_str,\n                'rmse': rmse\n            })\n        \n        # Prune if too many patterns\n        if len(self.patterns) > self.max_patterns:\n            self._prune()\n        \n        return key\n    \n    def _extract_structure(self, tokens):\n        \"\"\"Extract structural pattern (replace numeric constants with 'C').\"\"\"\n        structure = []\n        for t in tokens:\n            if t in ['0', '1', '2', '3', '5', '10', 'C', 'pi', 'e']:\n                structure.append('C')  # Generalize constants\n            else:\n                structure.append(t)\n        return structure\n    \n    def _prune(self):\n        \"\"\"Remove least useful patterns.\"\"\"\n        # Sort by (best_rmse ASC, uses DESC)\n        sorted_patterns = sorted(\n            self.patterns.items(),\n            key=lambda kv: (kv[1]['best_rmse'], -kv[1]['uses'])\n        )\n        \n        # Keep top max_patterns\n        self.patterns = dict(sorted_patterns[:self.max_patterns])\n    \n    def get_best_patterns(self, n=10):\n        \"\"\"Get the top N patterns by RMSE.\"\"\"\n        sorted_patterns = sorted(\n            self.patterns.items(),\n            key=lambda kv: kv[1]['best_rmse']\n        )\n        return sorted_patterns[:n]\n    \n    def get_frequent_patterns(self, n=10):\n        \"\"\"Get the top N most frequently used patterns.\"\"\"\n        sorted_patterns = sorted(\n            self.patterns.items(),\n            key=lambda kv: -kv[1]['uses']\n        )\n        return sorted_patterns[:n]\n    \n    def suggest_starting_tokens(self):\n        \"\"\"Suggest good starting tokens based on pattern history.\"\"\"\n        if not self.patterns:\n            return None\n        \n        # Get best pattern\n        best = self.get_best_patterns(1)\n        if best:\n            return best[0][1]['structure']\n        return None\n    \n    def summary(self):\n        \"\"\"Print a summary of stored patterns.\"\"\"\n        print(f\"\\n=== Pattern Memory ({len(self.patterns)} patterns) ===\")\n        \n        print(\"\\nBest by RMSE:\")\n        for key, info in self.get_best_patterns(5):\n            print(f\"  RMSE={info['best_rmse']:.4f}, Uses={info['uses']}, Pattern: {key[:50]}...\")\n        \n        print(\"\\nMost Frequent:\")\n        for key, info in self.get_frequent_patterns(5):\n            print(f\"  Uses={info['uses']}, RMSE={info['best_rmse']:.4f}, Pattern: {key[:50]}...\")\n\n\nif __name__ == \"__main__\":\n    # Test\n    memory = PatternMemory(\"test_memory.json\")\n    \n    # Add some patterns\n    memory.record(['+', 'x', 'C'], 5.0, \"(x + C)\")\n    memory.record(['+', '*', 'C', 'x', 'C'], 1.0, \"(C*x + C)\")\n    memory.record(['+', '*', 'C', 'x', 'C'], 0.5, \"(2*x + 3)\")  # Same structure, better RMSE\n    memory.record(['pow', 'x', '2'], 2.0, \"x^2\")\n    \n    memory.summary()\n    \n    print(f\"\\nSuggested starting: {memory.suggest_starting_tokens()}\")\n    \n    memory.save()\n    print(f\"\\nSaved to {memory.path}\")\n    \n    # Cleanup\n    os.remove(\"test_memory.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/synthetic_data.py\n",
        "import numpy as np\nimport random\nfrom core.grammar import VOCABULARY, OPERATORS, VARIABLES, CONSTANTS, ExpressionTree\n\nclass DataGenerator:\n    def __init__(self, max_depth=5, population_size=1000, allowed_operators=None):\n        self.max_depth = max_depth\n        self.population_size = population_size\n        self.vocab = VOCABULARY\n        # Pre-compute terminal vs operator lists\n        self.terminals = VARIABLES + CONSTANTS\n        if allowed_operators:\n            self.operators = [op for op in allowed_operators if op in OPERATORS]\n        else:\n            self.operators = list(OPERATORS.keys())\n\n    def generate_random_tree(self, max_depth, current_depth=0):\n        if current_depth >= max_depth:\n            # Must return a terminal\n            return [random.choice(self.terminals)]\n        \n        # Decide if terminal or operator\n        # Higher probability of operator at shallow depths\n        if random.random() < 0.7: \n            op = random.choice(self.operators)\n            arity = OPERATORS[op]\n            tokens = [op]\n            for _ in range(arity):\n                tokens.extend(self.generate_random_tree(max_depth, current_depth + 1))\n            return tokens\n        else:\n            return [random.choice(self.terminals)]\n\n    def generate_batch(self, batch_size, point_count=10, x_range=(-10, 10)):\n        \"\"\"\n        Generates a batch of (X, Y) pairs and their generating formulas.\n        \"\"\"\n        data = []\n        \n        while len(data) < batch_size:\n            # Generate random formula\n            tokens = self.generate_random_tree(self.max_depth)\n            tree = ExpressionTree(tokens)\n            \n            if not tree.is_valid:\n                continue\n                \n            # Generate random X points\n            x_values = np.random.uniform(x_range[0], x_range[1], point_count)\n            # Sort X for cleaner visualization/learning\n            x_values.sort()\n            \n            # Calculate Y\n            y_values = tree.evaluate(x_values)\n            \n            # Check for validity (no NaNs, Infs, or extremely large values)\n            if np.any(np.isnan(y_values)) or np.any(np.isinf(y_values)):\n                continue\n            if np.max(np.abs(y_values)) > 1e6: # Reject too large numbers\n                continue\n            if np.std(y_values) < 1e-6: # Reject flat lines (too simple)\n                 # Optionally keep some, but mostly we want interesting curves\n                 if random.random() > 0.1: continue\n\n            data.append({\n                'tokens': tokens,\n                'infix': tree.get_infix(),\n                'x': x_values,\n                'y': y_values\n            })\n            \n        return data\n\n    def generate_inverse_batch(self, batch_size, point_count=10, x_range=(-5, 5)):\n        \"\"\"\n        Inverse data generation (AlphaTensor-style):\n        Generate KNOWN formulas with guaranteed solutions.\n        This helps the model learn from solvable problems first.\n        \"\"\"\n        data = []\n        \n        # Known formula templates with their token representations\n        templates = [\n            # Linear: a*x + b\n            lambda a, b: (['+', '*', str(a), 'x', str(b)], f\"({a}*x + {b})\"),\n            # Quadratic: a*x^2 + b\n            lambda a, b: (['+', '*', str(a), 'pow', 'x', '2', str(b)], f\"({a}*x^2 + {b})\"),\n            # Simple sin: sin(x)\n            lambda a, b: (['sin', 'x'], \"sin(x)\"),\n            # Scaled sin: a*sin(x)\n            lambda a, b: (['*', str(a), 'sin', 'x'], f\"{a}*sin(x)\"),\n            # Exponential: exp(x/a)\n            lambda a, b: (['exp', '/', 'x', str(max(1, abs(a)))], f\"exp(x/{max(1, abs(a))})\"),\n            # Square root: sqrt(x + a) \n            lambda a, b: (['sqrt', '+', 'x', str(abs(a)+1)], f\"sqrt(x+{abs(a)+1})\"),\n            # Polynomial: x^2 - a\n            lambda a, b: (['-', 'pow', 'x', '2', str(a)], f\"(x^2 - {a})\"),\n            # Cosine\n            lambda a, b: (['cos', 'x'], \"cos(x)\"),\n        ]\n        \n        while len(data) < batch_size:\n            # Random coefficients (small integers for stability)\n            a = random.randint(1, 5)\n            b = random.randint(-3, 3)\n            \n            # Pick random template\n            template = random.choice(templates)\n            \n            try:\n                tokens, formula_str = template(a, b)\n                \n                # Convert string numbers back to proper tokens\n                final_tokens = []\n                for t in tokens:\n                    if t in VOCABULARY:\n                        final_tokens.append(t)\n                    else:\n                        # It's a number - use 'C' placeholder or closest constant\n                        final_tokens.append('C')\n                \n                tree = ExpressionTree(final_tokens)\n                if not tree.is_valid:\n                    continue\n                \n                # Generate X points (positive for sqrt/log safety)\n                if 'sqrt' in final_tokens or 'log' in final_tokens:\n                    x_values = np.linspace(0.5, x_range[1], point_count)\n                else:\n                    x_values = np.linspace(x_range[0], x_range[1], point_count)\n                \n                y_values = tree.evaluate(x_values)\n                \n                # Validity checks\n                if np.any(np.isnan(y_values)) or np.any(np.isinf(y_values)):\n                    continue\n                if np.max(np.abs(y_values)) > 1e6:\n                    continue\n                \n                data.append({\n                    'tokens': final_tokens,\n                    'infix': tree.get_infix(),\n                    'x': x_values,\n                    'y': y_values\n                })\n            except:\n                continue\n                \n        return data\n\n# Quick test if run directly\nif __name__ == \"__main__\":\n    gen = DataGenerator(max_depth=4)\n    batch = gen.generate_batch(5)\n    for item in batch:\n        print(f\"Formula: {item['infix']}\")\n        print(f\"Tokens: {item['tokens']}\")\n        print(f\"Y sample: {item['y'][:3]}...\")\n        print(\"-\" * 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/basic_search.py\n",
        "\"\"\"\nAlphaSymbolic Search Script - Enhanced Version\nCombines MCTS with Constant Optimization and Simplification.\n\"\"\"\nimport torch\nimport numpy as np\nimport time\nimport sys\nimport os\n\n# Add project root to sys.path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom core.model import AlphaSymbolicModel\nfrom search.mcts import MCTS\nfrom core.grammar import VOCABULARY, ExpressionTree\nfrom utils.optimize_constants import optimize_constants\nfrom utils.simplify import simplify_tree\n\ndef solve_problem(target_x, target_y, model_path=\"alpha_symbolic_model.pth\", simulations=500):\n    \"\"\"\n    Solve a symbolic regression problem using AlphaSymbolic.\n    \n    Pipeline:\n    1. MCTS finds best formula structure (with 'C' placeholders)\n    2. Constant Optimization fills in optimal values for 'C'\n    3. Simplification cleans up the formula\n    \"\"\"\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    VOCAB_SIZE = len(VOCABULARY)\n    \n    print(\"=\"*50)\n    print(\"AlphaSymbolic Symbolic Regression Engine\")\n    print(\"=\"*50)\n    print(f\"Device: {DEVICE}\")\n    print(f\"Data points: {len(target_x)}\")\n    print(f\"Vocabulary size: {VOCAB_SIZE}\")\n    \n    # Load Model\n    model = AlphaSymbolicModel(vocab_size=VOCAB_SIZE + 1, d_model=128).to(DEVICE)\n    try:\n        model.load_state_dict(torch.load(model_path, map_location=DEVICE, weights_only=True))\n        model.eval()\n        print(\"\u2713 Model loaded successfully\")\n    except FileNotFoundError:\n        print(\"\u26a0 Model not found - using random weights (results will be poor)\")\n    except Exception as e:\n        print(f\"\u26a0 Model load warning: {e}\")\n    \n    # Initialize MCTS\n    mcts = MCTS(model, DEVICE)\n    \n    print(\"\\n--- Phase 1: Neural-Guided Tree Search ---\")\n    start_time = time.time()\n    \n    # Run Search\n    best_sequence = mcts.search(target_x, target_y, num_simulations=simulations)\n    \n    mcts_time = time.time() - start_time\n    \n    # Build tree\n    tree = ExpressionTree(best_sequence)\n    raw_formula = tree.get_infix()\n    \n    print(f\"Time: {mcts_time:.2f}s\")\n    print(f\"Found structure: {raw_formula}\")\n    print(f\"Constants to optimize: {tree.count_constants()}\")\n    \n    # Phase 2: Constant Optimization\n    print(\"\\n--- Phase 2: Constant Optimization ---\")\n    opt_start = time.time()\n    \n    constants, rmse_before_opt = optimize_constants(tree, target_x, target_y)\n    \n    opt_time = time.time() - opt_start\n    \n    # Evaluate with optimized constants\n    y_pred = tree.evaluate(target_x, constants=constants)\n    final_rmse = np.sqrt(np.mean((y_pred - target_y)**2))\n    \n    print(f\"Time: {opt_time:.2f}s\")\n    print(f\"Optimized constants: {len(constants)}\")\n    print(f\"RMSE after optimization: {final_rmse:.6f}\")\n    \n    # Phase 3: Simplification\n    print(\"\\n--- Phase 3: Algebraic Simplification ---\")\n    simplified_formula = simplify_tree(tree)\n    \n    # Build final formula string with constants substituted\n    final_formula = raw_formula\n    if constants:\n        positions = tree.root.get_constant_positions()\n        for pos in positions:\n            key = tuple(pos)\n            if key in constants:\n                val = constants[key]\n                if abs(val - round(val)) < 0.001:\n                    val_str = str(int(round(val)))\n                else:\n                    val_str = f\"{val:.4f}\"\n                final_formula = final_formula.replace('C', val_str, 1)\n    \n    # Final Report\n    print(\"\\n\" + \"=\"*50)\n    print(\"FINAL RESULTS\")\n    print(\"=\"*50)\n    print(f\"Total Time: {mcts_time + opt_time:.2f}s\")\n    print(f\"Raw Formula: {raw_formula}\")\n    print(f\"With Constants: {final_formula}\")\n    print(f\"Simplified: {simplified_formula}\")\n    print(f\"Final RMSE: {final_rmse:.6f}\")\n    \n    print(\"\\n--- Predictions vs Targets ---\")\n    for i in range(min(5, len(target_x))):\n        diff = abs(y_pred[i] - target_y[i])\n        print(f\"x={target_x[i]:8.2f} | Pred={y_pred[i]:12.4f} | Target={target_y[i]:12.4f} | \u0394={diff:.4f}\")\n    \n    if len(target_x) > 5:\n        print(f\"... ({len(target_x) - 5} more points)\")\n    \n    return {\n        'raw_formula': raw_formula,\n        'final_formula': final_formula,\n        'simplified': simplified_formula,\n        'rmse': final_rmse,\n        'constants': constants,\n        'tokens': best_sequence\n    }\n\n\nif __name__ == \"__main__\":\n    # Test Case 1: y = x^2 + 1\n    print(\"\\n\" + \"#\"*60)\n    print(\"# TEST 1: y = x^2 + 1\")\n    print(\"#\"*60)\n    x_test = np.linspace(-5, 5, 20).astype(np.float64)\n    y_test = x_test**2 + 1\n    result1 = solve_problem(x_test, y_test, simulations=200)\n    \n    # Test Case 2: y = 2*x + 3 (linear)\n    print(\"\\n\" + \"#\"*60)\n    print(\"# TEST 2: y = 2*x + 3 (Linear)\")\n    print(\"#\"*60)\n    x_test2 = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=np.float64)\n    y_test2 = 2 * x_test2 + 3\n    result2 = solve_problem(x_test2, y_test2, simulations=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/beam_search.py\n",
        "\"\"\"\nBeam Search for AlphaSymbolic.\nExplores multiple formula candidates in parallel, keeping top-K at each step.\n\"\"\"\nimport torch\nimport numpy as np\nfrom core.grammar import VOCABULARY, OPERATORS, TOKEN_TO_ID, ExpressionTree\nfrom utils.optimize_constants import optimize_constants\n\nclass BeamSearch:\n    def __init__(self, model, device, beam_width=10, max_length=30):\n        self.model = model\n        self.device = device\n        self.beam_width = beam_width\n        self.max_length = max_length\n        self.vocab_size = len(VOCABULARY)\n        self.sos_id = self.vocab_size  # SOS token ID\n        \n    def search(self, x_values, y_values):\n        \"\"\"\n        Beam Search to find the best formula structure.\n        \"\"\"\n        # Prepare data once\n        x_tensor = torch.tensor(x_values, dtype=torch.float32).unsqueeze(0).to(self.device) # [1, points]\n        y_tensor = torch.tensor(y_values, dtype=torch.float32).unsqueeze(0).to(self.device) # [1, points]\n        \n        # Each element in beams is just the sequence of tokens (list of strings)\n        # We track scores and open branches in parallel lists or a list of dicts\n        beams = [{'seq': [], 'log_prob': 0.0, 'open': 1}]\n        \n        completed = []\n        \n        for step in range(self.max_length):\n            if not beams:\n                break\n                \n            # Filter valid beams just in case\n            active_beams = [b for b in beams if b['open'] > 0]\n            if not active_beams:\n                break\n                \n            # Prepare batch for model\n            # Batch size = number of active beams\n            batch_size = len(active_beams)\n            \n            # Expand X and Y to match batch size [batch, points]\n            x_batch = x_tensor.expand(batch_size, -1)\n            y_batch = y_tensor.expand(batch_size, -1)\n            \n            # Prepare input sequences [batch, current_seq_len]\n            # Must prepend SOS token\n            seqs = [[self.sos_id] + [TOKEN_TO_ID[t] for t in b['seq']] for b in active_beams]\n            input_tensor = torch.tensor(seqs, dtype=torch.long).to(self.device)\n            \n            # Single model call for all beams\n            with torch.no_grad():\n                logits, _ = self.model(x_batch, y_batch, input_tensor)\n            \n            # Logits shape: [batch, seq_len, vocab_size]\n            # We want the last token's probabilities\n            last_token_logits = logits[:, -1, :self.vocab_size]\n            log_probs = torch.log_softmax(last_token_logits, dim=-1) # [batch, vocab]\n            \n            # We need to find the top-K candidates ACROSS current beams?\n            # Standard beam search: expand all, then prune to K\n            \n            all_candidates = []\n            \n            # Get top-K for EACH beam to avoid explosion (e.g. top 2*width)\n            k_per_beam = min(self.beam_width, self.vocab_size)\n            beam_topk_scores, beam_topk_indices = torch.topk(log_probs, k_per_beam, dim=-1)\n            \n            # Move to CPU for processing logic\n            beam_topk_scores = beam_topk_scores.cpu().numpy()\n            beam_topk_indices = beam_topk_indices.cpu().numpy()\n            \n            for i, beam in enumerate(active_beams):\n                for score, idx in zip(beam_topk_scores[i], beam_topk_indices[i]):\n                    token = VOCABULARY[idx]\n                    new_seq = beam['seq'] + [token]\n                    \n                    # Calculate new open branches\n                    if token in OPERATORS:\n                        new_open = beam['open'] + OPERATORS[token] - 1\n                    else:\n                        new_open = beam['open'] - 1\n                    \n                    if new_open < 0:\n                        continue\n                        \n                    all_candidates.append({\n                        'seq': new_seq,\n                        'log_prob': beam['log_prob'] + score,\n                        'open': new_open\n                    })\n            \n            # Global prune: keep top beam_width\n            all_candidates.sort(key=lambda x: x['log_prob'], reverse=True)\n            beams = all_candidates[:self.beam_width]\n            \n            # Check for completions\n            still_active = []\n            for b in beams:\n                if b['open'] == 0:\n                    completed.append(b)\n                else:\n                    still_active.append(b)\n            \n            beams = still_active\n            # If we filled up on completions, we might still want to explore? \n            # Usually we keep exploring until all beams are done or max length\n            if len(completed) >= self.beam_width:\n                 # Optional: early exit if we found enough good candidates\n                 pass\n\n        # Add any partial completions that happen to be valid (unlikely if open > 0)\n        # But maybe we ran out of steps?\n        \n        # Evaluate results\n        scored_results = []\n        for beam in completed:\n            tree = ExpressionTree(beam['seq'])\n            if tree.is_valid:\n                constants, rmse = optimize_constants(tree, x_values, y_values)\n                scored_results.append({\n                    'tokens': beam['seq'],\n                    'log_prob': beam['log_prob'],\n                    'rmse': rmse,\n                    'constants': constants,\n                    'formula': tree.get_infix()\n                })\n        \n        scored_results.sort(key=lambda x: x['rmse'])\n        return scored_results\n\n\ndef beam_solve(target_x, target_y, model, device, beam_width=20, max_length=25):\n    \"\"\"\n    Solve symbolic regression using beam search.\n    \"\"\"\n    searcher = BeamSearch(model, device, beam_width=beam_width, max_length=max_length)\n    results = searcher.search(target_x, target_y)\n    \n    if not results:\n        return None\n        \n    return results  # Return all results for Pareto analysis\n\n\nif __name__ == \"__main__\":\n    from core.model import AlphaSymbolicModel\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    VOCAB_SIZE = len(VOCABULARY)\n    \n    model = AlphaSymbolicModel(vocab_size=VOCAB_SIZE + 1, d_model=64).to(DEVICE)\n    try:\n        model.load_state_dict(torch.load(\"alpha_symbolic_model.pth\", map_location=DEVICE, weights_only=True))\n    except:\n        print(\"Model not found, using random weights\")\n    model.eval()\n    \n    # Test\n    x_test = np.linspace(-5, 5, 20).astype(np.float64)\n    y_test = 2 * x_test + 3\n    \n    print(\"Running Beam Search...\")\n    results = beam_solve(x_test, y_test, model, DEVICE, beam_width=10)\n    \n    print(f\"\\nFound {len(results)} valid formulas:\")\n    for i, r in enumerate(results[:5]):\n        print(f\"  {i+1}. {r['formula']} (RMSE: {r['rmse']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/mcts.py\n",
        "import math\nimport numpy as np\nimport torch\nimport copy\nfrom core.grammar import VOCABULARY, TOKEN_TO_ID, OPERATORS, ExpressionTree, VARIABLES\nfrom utils.optimize_constants import optimize_constants\n\nclass MCTSNode:\n    def __init__(self, tokens, parent=None, prior=0.0):\n        self.tokens = tokens\n        self.parent = parent\n        self.children = {}\n        self.visit_count = 0\n        self.value_sum = 0.0\n        self.prior = prior\n        self.is_expanded = False\n        \n        # for parallel search\n        self.virtual_loss = 0.0\n        self.virtual_visits = 0\n\n    @property\n    def value(self):\n        count = self.visit_count + self.virtual_visits\n        if count == 0:\n            return 0.0\n        # Combine real value and virtual loss\n        # Virtual loss is SUBTRACTED to discourage visits\n        return (self.value_sum - self.virtual_loss) / count\n\n    def ucb_score(self, c_puct=1.0):\n        count = self.visit_count + self.virtual_visits\n        parent_count = self.parent.visit_count + self.parent.virtual_visits if self.parent else 1\n        \n        if self.parent is None:\n            return 0.0\n            \n        u = c_puct * self.prior * math.sqrt(parent_count) / (1 + count)\n        return self.value + u\n\nclass MCTS:\n    def __init__(self, model, device, max_simulations=100, max_depth=30, c_puct=1.0, lambda_mix=0.5, batch_size=8):\n        self.model = model\n        self.device = device\n        self.max_simulations = max_simulations\n        self.max_depth = max_depth\n        self.c_puct = c_puct\n        self.lambda_mix = lambda_mix \n        self.batch_size = batch_size\n        self.vocab_size = len(VOCABULARY)\n        self.sos_id = self.vocab_size\n        \n        # Virtual loss constant usually 1-3\n        self.v_loss_const = 3.0\n        \n    def search(self, x_values, y_values, num_simulations=None):\n        \"\"\"\n        Run MCTS (Parallel/Batched) to find the best formula.\n        \"\"\"\n        root = MCTSNode(tokens=[])\n        \n        # Initial expansion (single)\n        self._expand_batch([root], x_values, y_values)\n        \n        best_rmse = float('inf')\n        best_formula = None\n        best_tokens = None\n        \n        limit = num_simulations if num_simulations is not None else self.max_simulations\n        \n        # Loop in batches\n        # Ensure we do at least 1 batch\n        num_batches = max(1, (limit + self.batch_size - 1) // self.batch_size)\n        \n        for _ in range(num_batches): \n            leaves = []\n            \n            # 1. Selection (find N leaves)\n            for _ in range(self.batch_size):\n                node = root\n                depth = 0\n                \n                # Selection loop\n                while node.is_expanded and node.children and depth < self.max_depth:\n                    node = max(node.children.values(), key=lambda n: n.ucb_score(self.c_puct))\n                    \n                    # Apply virtual loss to discourage re-selection in same batch\n                    node.virtual_loss += self.v_loss_const\n                    node.virtual_visits += 1\n                    depth += 1\n                \n                # Check if valid leaf to expand\n                if depth < self.max_depth and not node.is_expanded:\n                    # Avoid duplicates in batch (simple check)\n                    if node not in leaves:\n                        leaves.append(node)\n                else:\n                    pass\n            \n            if not leaves:\n                # If no leaves found (tree fully explored or locked), standard MCTS usually continues or stops.\n                # We can just break or continue backprop of terminals.\n                if root.visit_count > limit: break \n                continue\n                \n            # 2. Batch Expansion & Evaluation\n            values = self._expand_batch(leaves, x_values, y_values)\n            \n            # 3. Backpropagation\n            for node, val in zip(leaves, values):\n                # Check for best solution found\n                if self._is_complete_tree(node.tokens):\n                    # For completed formulas, we calculate REAL RMSE\n                    real_rmse = self._evaluate_formula(node.tokens, x_values, y_values)\n                    \n                    # Use real RMSE as value if valid\n                    final_val = 1.0 / (1.0 + real_rmse) # [0, 1] range\n                    \n                    if real_rmse < best_rmse:\n                        best_rmse = real_rmse\n                        best_tokens = node.tokens\n                        best_formula = ExpressionTree(node.tokens).get_infix()\n                else:\n                    final_val = val\n                \n                # Backpropagate\n                curr = node\n                while curr is not None:\n                    curr.visit_count += 1\n                    curr.value_sum += final_val\n                    \n                    # Revert virtual loss for parent and above\n                    # Since we added to PARENT's child (which is curr), \n                    # and we traverse Up...\n                    # Wait, logic: We selected CHILD. Virtual loss was added TO CHILD (curr).\n                    # So we must remove it from curr.\n                    if curr.virtual_visits > 0:\n                        curr.virtual_loss -= self.v_loss_const\n                        curr.virtual_visits -= 1\n                            \n                    curr = curr.parent\n        \n        # After search, force cleanup of any residual virtual loss (safety)\n        # (Not strictly needed if logic is perfect, but good practice in complex async MCTS)\n        \n        return {\n            'tokens': best_tokens,\n            'formula': best_formula,\n            'rmse': best_rmse\n        }\n\n    def _expand_batch(self, nodes, x_values, y_values):\n        \"\"\"\n        Batched expansion. Returns list of values.\n        \"\"\"\n        if not nodes:\n            return []\n            \n        # Prepare inputs\n        x_tensor = torch.tensor(x_values, dtype=torch.float32).unsqueeze(0).to(self.device)\n        y_tensor = torch.tensor(y_values, dtype=torch.float32).unsqueeze(0).to(self.device)\n        \n        # Repeat X/Y for batch\n        batch_size = len(nodes)\n        x_batch = x_tensor.repeat(batch_size, 1, 1).squeeze(1) # [batch, points]\n        y_batch = y_tensor.repeat(batch_size, 1, 1).squeeze(1) # [batch, points]\n        \n        # Prepare sequences\n        # Find max len\n        max_len = 0\n        seqs = []\n        for n in nodes:\n            s = [self.sos_id] + [TOKEN_TO_ID[t] for t in n.tokens]\n            seqs.append(s)\n            max_len = max(max_len, len(s))\n            \n        # Pad and stack\n        input_tensor = torch.full((batch_size, max_len), self.sos_id, dtype=torch.long).to(self.device)\n        for i, s in enumerate(seqs):\n            input_tensor[i, :len(s)] = torch.tensor(s, dtype=torch.long)\n            \n        # Inference\n        with torch.no_grad():\n            logits, value_preds = self.model(x_batch, y_batch, input_tensor)\n            \n        # Process results\n        values = []\n        \n        # To CPU numpy for probability processing\n        probs_batch = torch.softmax(logits[:, -1, :self.vocab_size], dim=1).cpu().numpy()\n        value_preds = value_preds.cpu().numpy().flatten()\n        \n        for i, node in enumerate(nodes):\n            # 1. Store Value\n            val = float(np.clip(value_preds[i], 0.0, 1.0))\n            values.append(val)\n            \n            # 2. Expand children\n            node_probs = probs_batch[i]\n            valid_next = self._get_valid_next_tokens(node.tokens)\n            \n            for idx in valid_next:\n                token = VOCABULARY[idx]\n                prior = node_probs[idx]\n                child = MCTSNode(tokens=node.tokens + [token], parent=node, prior=prior)\n                node.children[token] = child\n            \n            node.is_expanded = True\n            \n        return values\n\n    def _get_valid_next_tokens(self, tokens):\n        \"\"\"Simple grammar check.\"\"\"\n        open_slots = 1\n        for t in tokens:\n            if t in OPERATORS:\n                open_slots += OPERATORS[t] - 1\n            else:\n                open_slots -= 1\n        \n        if open_slots <= 0:\n            return []\n        return list(range(self.vocab_size))\n\n    def _is_complete_tree(self, tokens):\n        if not tokens: return False\n        try:\n            tree = ExpressionTree(tokens)\n            # Basic validation\n            if len(tokens) > self.max_depth * 2: return False\n            return tree.is_valid\n        except:\n            return False\n\n    def _evaluate_formula(self, tokens, x, y):\n        try:\n            tree = ExpressionTree(tokens)\n            _, rmse = optimize_constants(tree, x, y)\n            return rmse\n        except:\n            return 1e9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/pareto.py\n",
        "\"\"\"\nPareto Front Manager for AlphaSymbolic.\nMaintains a set of non-dominated solutions (accuracy vs complexity).\n\"\"\"\nimport numpy as np\nfrom core.grammar import ExpressionTree\n\nclass ParetoSolution:\n    def __init__(self, tokens, rmse, complexity, formula_str, constants=None):\n        self.tokens = tokens\n        self.rmse = rmse  # Lower is better\n        self.complexity = complexity  # Lower is better (number of nodes)\n        self.formula = formula_str\n        self.constants = constants or {}\n        \n    def dominates(self, other):\n        \"\"\"Returns True if self dominates other (better in all objectives).\"\"\"\n        # Self dominates other if:\n        # - Self is at least as good in all objectives\n        # - Self is strictly better in at least one objective\n        at_least_as_good = (self.rmse <= other.rmse) and (self.complexity <= other.complexity)\n        strictly_better = (self.rmse < other.rmse) or (self.complexity < other.complexity)\n        return at_least_as_good and strictly_better\n    \n    def __repr__(self):\n        return f\"ParetoSolution(rmse={self.rmse:.4f}, complexity={self.complexity}, formula='{self.formula}')\"\n\n\nclass ParetoFront:\n    def __init__(self, max_size=50):\n        self.solutions = []\n        self.max_size = max_size\n        \n    def add(self, solution):\n        \"\"\"\n        Attempts to add a solution to the Pareto front.\n        Returns True if added, False if dominated.\n        \"\"\"\n        # Check if new solution is dominated by any existing\n        for existing in self.solutions:\n            if existing.dominates(solution):\n                return False  # New solution is dominated\n        \n        # Remove any solutions dominated by the new one\n        self.solutions = [s for s in self.solutions if not solution.dominates(s)]\n        \n        # Add the new solution\n        self.solutions.append(solution)\n        \n        # Enforce max size by removing worst solutions\n        if len(self.solutions) > self.max_size:\n            # Sort by a combined score and keep top max_size\n            self.solutions.sort(key=lambda s: s.rmse + 0.01 * s.complexity)\n            self.solutions = self.solutions[:self.max_size]\n        \n        return True\n    \n    def add_from_results(self, results_list):\n        \"\"\"\n        Add multiple results from beam search or MCTS.\n        results_list: list of dicts with 'tokens', 'rmse', 'constants', 'formula'\n        \"\"\"\n        added = 0\n        for r in results_list:\n            tree = ExpressionTree(r['tokens'])\n            complexity = len(r['tokens'])  # Simple complexity = token count\n            \n            sol = ParetoSolution(\n                tokens=r['tokens'],\n                rmse=r['rmse'],\n                complexity=complexity,\n                formula_str=r['formula'],\n                constants=r.get('constants', {})\n            )\n            \n            if self.add(sol):\n                added += 1\n        \n        return added\n    \n    def get_best_by_rmse(self):\n        \"\"\"Returns the solution with lowest RMSE.\"\"\"\n        if not self.solutions:\n            return None\n        return min(self.solutions, key=lambda s: s.rmse)\n    \n    def get_simplest(self):\n        \"\"\"Returns the solution with lowest complexity.\"\"\"\n        if not self.solutions:\n            return None\n        return min(self.solutions, key=lambda s: s.complexity)\n    \n    def get_balanced(self, alpha=0.5):\n        \"\"\"\n        Returns a balanced solution.\n        alpha: weight for RMSE (1-alpha for complexity)\n        \"\"\"\n        if not self.solutions:\n            return None\n        \n        # Normalize scores\n        rmse_vals = [s.rmse for s in self.solutions]\n        comp_vals = [s.complexity for s in self.solutions]\n        \n        min_rmse, max_rmse = min(rmse_vals), max(rmse_vals) + 1e-10\n        min_comp, max_comp = min(comp_vals), max(comp_vals) + 1e-10\n        \n        def score(s):\n            norm_rmse = (s.rmse - min_rmse) / (max_rmse - min_rmse)\n            norm_comp = (s.complexity - min_comp) / (max_comp - min_comp)\n            return alpha * norm_rmse + (1 - alpha) * norm_comp\n        \n        return min(self.solutions, key=score)\n    \n    def summary(self):\n        \"\"\"Print a summary of the Pareto front.\"\"\"\n        print(f\"\\n=== Pareto Front ({len(self.solutions)} solutions) ===\")\n        for i, sol in enumerate(sorted(self.solutions, key=lambda s: s.rmse)[:10]):\n            print(f\"  {i+1}. RMSE={sol.rmse:.6f}, Nodes={sol.complexity}, Formula: {sol.formula}\")\n\n\n# Quick test\nif __name__ == \"__main__\":\n    front = ParetoFront()\n    \n    # Add some test solutions\n    solutions = [\n        ParetoSolution(['x'], 10.0, 1, \"x\"),\n        ParetoSolution(['+', 'x', '1'], 5.0, 3, \"(x + 1)\"),\n        ParetoSolution(['*', '2', 'x'], 3.0, 3, \"(2 * x)\"),\n        ParetoSolution(['+', '*', '2', 'x', '3'], 0.5, 5, \"((2 * x) + 3)\"),\n        ParetoSolution(['+', '*', '*', '2', 'x', 'x', '+', 'x', '1'], 0.1, 9, \"complicated\"),\n    ]\n    \n    for sol in solutions:\n        added = front.add(sol)\n        print(f\"Added {sol.formula}: {added}\")\n    \n    front.summary()\n    \n    print(f\"\\nBest by RMSE: {front.get_best_by_rmse()}\")\n    print(f\"Simplest: {front.get_simplest()}\")\n    print(f\"Balanced: {front.get_balanced()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/search_pro.py\n",
        "\"\"\"\nAlphaSymbolic Pro Search - Integrated Full Pipeline\nCombines all improvements:\n- Pattern Detection (initial hints)\n- Beam Search OR MCTS\n- Constant Optimization\n- Simplification\n- Pareto Front\n- Pattern Memory\n\"\"\"\nimport torch\nimport numpy as np\nimport time\nimport argparse\nimport sys\nimport os\n\n# Add project root to sys.path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom core.model import AlphaSymbolicModel\nfrom core.grammar import VOCABULARY, ExpressionTree\nfrom search.beam_search import beam_solve\nfrom search.mcts import MCTS\nfrom utils.optimize_constants import optimize_constants\nfrom utils.simplify import simplify_tree\nfrom search.pareto import ParetoFront\nfrom data.pattern_memory import PatternMemory\nfrom utils.detect_pattern import detect_pattern, summarize_pattern\n\n\ndef solve_pro(target_x, target_y, \n              model_path=\"alpha_symbolic_model.pth\",\n              method=\"beam\",  # \"beam\" or \"mcts\"\n              beam_width=15,\n              mcts_simulations=200,\n              use_memory=True,\n              verbose=True):\n    \"\"\"\n    Professional formula solver with all bells and whistles.\n    \"\"\"\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    VOCAB_SIZE = len(VOCABULARY)\n    \n    if verbose:\n        print(\"=\"*60)\n        print(\"AlphaSymbolic Pro - Full Pipeline\")\n        print(\"=\"*60)\n        print(f\"Device: {DEVICE}\")\n        print(f\"Method: {method.upper()}\")\n        print(f\"Data points: {len(target_x)}\")\n    \n    # --- Phase 0: Pattern Detection ---\n    if verbose:\n        print(\"\\n--- Phase 0: Pattern Detection ---\")\n    pattern_info = detect_pattern(target_x, target_y)\n    if verbose:\n        print(f\"Detected: {pattern_info['type']} (confidence: {pattern_info['confidence']:.1%})\")\n        print(f\"Suggested ops: {pattern_info['suggested_ops']}\")\n    \n    # --- Load Model ---\n    model = AlphaSymbolicModel(vocab_size=VOCAB_SIZE + 1, d_model=128).to(DEVICE)\n    try:\n        model.load_state_dict(torch.load(model_path, map_location=DEVICE, weights_only=True))\n        model.eval()\n        if verbose:\n            print(\"\\n\u2713 Model loaded\")\n    except:\n        if verbose:\n            print(\"\\n\u26a0 Model not found, using random weights\")\n    \n    # --- Load Pattern Memory ---\n    memory = PatternMemory() if use_memory else None\n    \n    # --- Phase 1: Search ---\n    if verbose:\n        print(f\"\\n--- Phase 1: {method.upper()} Search ---\")\n    \n    start_time = time.time()\n    \n    all_results = []\n    \n    if method == \"beam\":\n        results = beam_solve(target_x, target_y, model, DEVICE, \n                            beam_width=beam_width, max_length=25)\n        if results:\n            all_results.extend(results)\n    else:\n        mcts = MCTS(model, DEVICE)\n        best_seq = mcts.search(target_x, target_y, num_simulations=mcts_simulations)\n        tree = ExpressionTree(best_seq)\n        if tree.is_valid:\n            constants, rmse = optimize_constants(tree, target_x, target_y)\n            all_results.append({\n                'tokens': best_seq,\n                'rmse': rmse,\n                'constants': constants,\n                'formula': tree.get_infix()\n            })\n    \n    search_time = time.time() - start_time\n    \n    if verbose:\n        print(f\"Time: {search_time:.2f}s\")\n        print(f\"Candidates found: {len(all_results)}\")\n    \n    # --- Phase 2: Pareto Front ---\n    if verbose:\n        print(\"\\n--- Phase 2: Pareto Analysis ---\")\n    \n    pareto = ParetoFront()\n    pareto.add_from_results(all_results)\n    \n    if verbose:\n        print(f\"Non-dominated solutions: {len(pareto.solutions)}\")\n    \n    # --- Phase 3: Select Best Solutions ---\n    if verbose:\n        print(\"\\n--- Phase 3: Final Selection ---\")\n    \n    best_rmse = pareto.get_best_by_rmse()\n    simplest = pareto.get_simplest()\n    balanced = pareto.get_balanced(alpha=0.6)  # Slight preference for accuracy\n    \n    # --- Phase 4: Simplify Winners ---\n    if verbose:\n        print(\"\\n--- Phase 4: Simplification ---\")\n    \n    final_results = {}\n    \n    if best_rmse:\n        tree = ExpressionTree(best_rmse.tokens)\n        simplified = simplify_tree(tree) \n        final_results['best_accuracy'] = {\n            'formula': best_rmse.formula,\n            'simplified': simplified,\n            'rmse': best_rmse.rmse,\n            'complexity': best_rmse.complexity\n        }\n        \n        # Record in pattern memory\n        if memory:\n            memory.record(best_rmse.tokens, best_rmse.rmse, best_rmse.formula)\n    \n    if simplest and simplest != best_rmse:\n        tree = ExpressionTree(simplest.tokens)\n        simplified = simplify_tree(tree)\n        final_results['simplest'] = {\n            'formula': simplest.formula,\n            'simplified': simplified,\n            'rmse': simplest.rmse,\n            'complexity': simplest.complexity\n        }\n    \n    if balanced and balanced != best_rmse and balanced != simplest:\n        tree = ExpressionTree(balanced.tokens)\n        simplified = simplify_tree(tree)\n        final_results['balanced'] = {\n            'formula': balanced.formula,\n            'simplified': simplified,\n            'rmse': balanced.rmse,\n            'complexity': balanced.complexity\n        }\n    \n    # Save memory\n    if memory:\n        memory.save()\n    \n    # --- Final Report ---\n    if verbose:\n        print(\"\\n\" + \"=\"*60)\n        print(\"FINAL RESULTS\")\n        print(\"=\"*60)\n        \n        for key, res in final_results.items():\n            print(f\"\\n[{key.upper()}]\")\n            print(f\"  Formula: {res['formula']}\")\n            print(f\"  Simplified: {res['simplified']}\")\n            print(f\"  RMSE: {res['rmse']:.6f}\")\n            print(f\"  Complexity: {res['complexity']} nodes\")\n        \n        # Predictions comparison\n        if best_rmse:\n            tree = ExpressionTree(best_rmse.tokens)\n            y_pred = tree.evaluate(target_x, constants=best_rmse.constants)\n            \n            print(f\"\\n--- Predictions (Best Accuracy) ---\")\n            for i in range(min(5, len(target_x))):\n                diff = abs(y_pred[i] - target_y[i])\n                print(f\"x={target_x[i]:8.2f} | Pred={y_pred[i]:12.4f} | Target={target_y[i]:12.4f} | \u0394={diff:.4f}\")\n    \n    return final_results, pareto\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"AlphaSymbolic Pro Solver\")\n    parser.add_argument(\"--method\", choices=[\"beam\", \"mcts\"], default=\"beam\")\n    parser.add_argument(\"--beam-width\", type=int, default=15)\n    parser.add_argument(\"--mcts-sims\", type=int, default=200)\n    args = parser.parse_args()\n    \n    # Test 1: Linear\n    print(\"\\n\" + \"#\"*60)\n    print(\"# TEST 1: y = 2x + 3\")\n    print(\"#\"*60)\n    x1 = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=np.float64)\n    y1 = 2 * x1 + 3\n    solve_pro(x1, y1, method=args.method, beam_width=args.beam_width)\n    \n    # Test 2: Quadratic\n    print(\"\\n\" + \"#\"*60)\n    print(\"# TEST 2: y = x^2 + 1\")\n    print(\"#\"*60)\n    x2 = np.linspace(-5, 5, 15).astype(np.float64)\n    y2 = x2**2 + 1\n    solve_pro(x2, y2, method=args.method, beam_width=args.beam_width)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_benchmark.py\n",
        "import gradio as gr\nfrom utils.benchmark_runner import run_benchmark_suite\nfrom ui.app_core import get_model, DEVICE\n\ndef get_benchmark_tab():\n    with gr.Tab(\"\ud83e\udd47 Benchmark (IQ Test)\"):\n        gr.Markdown(\"### Evaluar Inteligencia del Modelo\")\n        gr.Markdown(\"Ejecuta una bater\u00eda de **10 problemas est\u00e1ndar** para medir qu\u00e9 tanto ha aprendido el modelo.\")\n        \n        run_btn = gr.Button(\"\ud83d\ude80 Iniciar Examen\", variant=\"primary\")\n        \n        progress_bar = gr.HTML(\"\")\n        \n        with gr.Row():\n            score_box = gr.Number(label=\"Puntuaci\u00f3n (/100)\", interactive=False)\n            time_box = gr.Number(label=\"Tiempo Promedio (s)\", interactive=False)\n            \n        results_df = gr.Dataframe(\n            headers=[\"Nivel\", \"Nombre\", \"Formula Encontrada\", \"RMSE\", \"Estado\", \"Tiempo\"],\n            label=\"Resultados Detallados\",\n            interactive=False\n        )\n        \n        def run_bench(progress=gr.Progress()):\n            model_obj, device_obj = get_model()\n            if not model_obj:\n                return \"<div>Error: Modelo no cargado</div>\", 0, 0, []\n            \n            results, summary = run_benchmark_suite(\n                model_obj, \n                device_obj, \n                progress_callback=lambda p, desc: progress(p, desc=desc)\n            )\n            \n            # Format dataframe\n            rows = []\n            for r in results:\n                rows.append([\n                    r['level'],\n                    r['name'],\n                    r['found_formula'],\n                    f\"{r['rmse']:.5f}\",\n                    r['status'],\n                    f\"{r['time']:.2f}s\"\n                ])\n            \n            # Color score\n            color = \"green\" if summary['score'] > 80 else \"orange\" if summary['score'] > 50 else \"red\"\n            header = f\"\"\"\n            <div style=\"background: #1e1e2f; padding: 20px; border-radius: 10px; text-align: center; border: 2px solid {color};\">\n                <h1 style=\"color: {color}; margin: 0;\">Nota Final: {summary['score']:.1f} / 100</h1>\n                <p style=\"color: #ccc;\">Problemas Resueltos: {summary['solved']} / {summary['total']}</p>\n            </div>\n            \"\"\"\n            \n            return header, summary['score'], summary['avg_time'], rows\n            \n        run_btn.click(run_bench, outputs=[progress_bar, score_box, time_box, results_df])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_core.py\n",
        "\"\"\"\nCore state and model management for AlphaSymbolic Gradio App.\n\"\"\"\nimport torch\nimport os\nfrom core.model import AlphaSymbolicModel\nfrom core.grammar import VOCABULARY\n\n# Global state\nMODEL = None\nDEVICE = None\nTRAINING_STATUS = {\"running\": False, \"epoch\": 0, \"loss\": 0, \"message\": \"Listo\"}\n\nMODEL_PRESETS = {\n    'lite': {'d_model': 128, 'nhead': 4, 'num_encoder_layers': 3, 'num_decoder_layers': 3},\n    'pro': {'d_model': 256, 'nhead': 8, 'num_encoder_layers': 6, 'num_decoder_layers': 6}\n}\nCURRENT_PRESET = 'lite'\n\ndef get_device(force_cpu=False):\n    \"\"\"Get the best available device (CUDA > MPS > CPU).\"\"\"\n    if force_cpu:\n        return torch.device(\"cpu\")\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n        return torch.device(\"mps\")\n    return torch.device(\"cpu\")\n\ndef set_device(use_gpu=True):\n    \"\"\"Set the device (GPU or CPU).\"\"\"\n    global DEVICE, MODEL\n    new_device = get_device(force_cpu=not use_gpu)\n    \n    if MODEL is not None and DEVICE != new_device:\n        MODEL = MODEL.to(new_device)\n    \n    DEVICE = new_device\n    return get_device_info()\n\ndef get_device_info():\n    \"\"\"Get device info string.\"\"\"\n    global DEVICE\n    if DEVICE is None:\n        DEVICE = get_device()\n    \n    if DEVICE.type == \"cuda\":\n        return f\"CUDA ({torch.cuda.get_device_name(0)})\"\n    elif DEVICE.type == \"mps\":\n        return \"MPS (Apple Silicon)\"\n    else:\n        return \"CPU\"\n\ndef load_model(force_reload=False, preset_name=None):\n    \"\"\"Load or reload the model.\"\"\"\n    global MODEL, DEVICE, CURRENT_PRESET\n    \n    if preset_name:\n        CURRENT_PRESET = preset_name\n    \n    if DEVICE is None:\n        DEVICE = get_device()\n    \n    VOCAB_SIZE = len(VOCABULARY)\n    config = MODEL_PRESETS[CURRENT_PRESET]\n    \n    print(f\"Loading Model [{CURRENT_PRESET.upper()}]...\")\n    MODEL = AlphaSymbolicModel(\n        vocab_size=VOCAB_SIZE + 1, \n        d_model=config['d_model'], \n        nhead=config['nhead'],\n        num_encoder_layers=config['num_encoder_layers'], \n        num_decoder_layers=config['num_decoder_layers']\n    ).to(DEVICE)\n    \n    try:\n        state_dict = torch.load(\"alpha_symbolic_model.pth\", map_location=DEVICE, weights_only=True)\n        # Check for NaNs\n        has_nans = False\n        for k, v in state_dict.items():\n            if torch.isnan(v).any() or torch.isinf(v).any():\n                has_nans = True\n                break\n        \n        if has_nans:\n            print(\"\u26a0\ufe0f Modelo corrupto detectado (NaNs). Eliminando archivo y reiniciando pesos.\")\n            try:\n                os.remove(\"alpha_symbolic_model.pth\")\n                print(\"\u2705 Archivo corrupto eliminado.\")\n            except OSError as e:\n                print(f\"Error al eliminar archivo: {e}\")\n            status = \"\u26a0\ufe0f Modelo corrupto eliminado y reiniciado\"\n        else:\n            MODEL.load_state_dict(state_dict)\n            MODEL.eval()\n            status = f\"Modelo cargado ({CURRENT_PRESET})\"\n    except RuntimeError as e:\n        print(f\"\u26a0\ufe0f Error de compatibilidad ({e}). Iniciando modelo fresco.\")\n        status = f\"Nuevo modelo ({CURRENT_PRESET})\"\n    except Exception as e:\n        print(f\"Error cargando: {e}\")\n        status = \"Sin modelo pre-entrenado\"\n    \n    return status, get_device_info()\n\ndef get_model():\n    \"\"\"Get the current model, loading if needed.\"\"\"\n    global MODEL, DEVICE\n    if MODEL is None:\n        load_model()\n    return MODEL, DEVICE\n\ndef save_model():\n    \"\"\"Save the current model.\"\"\"\n    global MODEL\n    if MODEL is not None:\n        torch.save(MODEL.state_dict(), \"alpha_symbolic_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_search.py\n",
        "\"\"\"\nSearch/Solve functions for AlphaSymbolic Gradio App.\nSupports both Beam Search and MCTS.\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport gradio as gr\n\nfrom core.grammar import ExpressionTree\nfrom search.beam_search import BeamSearch\nfrom search.mcts import MCTS\nfrom utils.simplify import simplify_tree\nfrom search.pareto import ParetoFront\nfrom utils.detect_pattern import detect_pattern\nfrom utils.optimize_constants import optimize_constants, substitute_constants\nfrom ui.app_core import get_model\n\n\ndef parse_data(x_str, y_str):\n    \"\"\"Parse comma-separated input strings.\"\"\"\n    try:\n        x = np.array([float(v.strip()) for v in x_str.split(',')], dtype=np.float64)\n        y = np.array([float(v.strip()) for v in y_str.split(',')], dtype=np.float64)\n        if len(x) != len(y):\n            return None, None, \"Error: X e Y deben tener igual longitud\"\n        return x, y, None\n    except Exception as e:\n        return None, None, f\"Error: {str(e)}\"\n\n\ndef create_fit_plot(x, y, y_pred, formula):\n    \"\"\"Create a plot showing data vs prediction.\"\"\"\n    fig, ax = plt.subplots(figsize=(8, 5), facecolor='#1a1a2e')\n    ax.set_facecolor('#1a1a2e')\n    \n    ax.scatter(x, y, color='#00d4ff', s=100, label='Datos Reales', zorder=3, edgecolors='white', linewidth=1)\n    \n    sort_idx = np.argsort(x)\n    ax.plot(x[sort_idx], y_pred[sort_idx], color='#ff6b6b', linewidth=3, label='Prediccion', zorder=2)\n    \n    ax.set_xlabel('X', color='white', fontsize=12)\n    ax.set_ylabel('Y', color='white', fontsize=12)\n    ax.set_title('Ajuste de la Formula', color='white', fontsize=14, fontweight='bold')\n    ax.legend(facecolor='#16213e', edgecolor='#00d4ff', labelcolor='white')\n    ax.tick_params(colors='white')\n    ax.grid(True, alpha=0.2, color='white')\n    \n    for spine in ax.spines.values():\n        spine.set_color('#00d4ff')\n    \n    plt.tight_layout()\n    return fig\n\n\ndef solve_formula(x_str, y_str, beam_width, search_method, progress=gr.Progress()):\n    \"\"\"Main solving function with search method selection.\"\"\"\n    x, y, error = parse_data(x_str, y_str)\n    if error:\n        return error, None, \"\", \"\", \"\"\n    \n    MODEL, DEVICE = get_model()\n    \n    progress(0.1, desc=f\"Analizando patron... [{DEVICE.type.upper()}]\")\n    pattern = detect_pattern(x, y)\n    \n    progress(0.3, desc=f\"Buscando formulas ({search_method})... [{DEVICE.type.upper()}]\")\n    start_time = time.time()\n    \n    results = []\n    \n    if search_method == \"Beam Search\":\n        searcher = BeamSearch(MODEL, DEVICE, beam_width=int(beam_width), max_length=25)\n        results = searcher.search(x, y)\n    else:  # MCTS\n        mcts = MCTS(MODEL, DEVICE, max_simulations=int(beam_width) * 10)\n        result = mcts.search(x, y)\n        if result and result.get('tokens'):\n            tokens = result['tokens']\n            tree = ExpressionTree(tokens)\n            if tree.is_valid:\n                constants, rmse = optimize_constants(tree, x, y)\n                results = [{\n                    'tokens': tokens,\n                    'formula': tree.get_infix(),\n                    'rmse': rmse,\n                    'constants': constants\n                }]\n    \n    search_time = time.time() - start_time\n    \n    if not results:\n        return \"No se encontraron formulas validas\", None, \"\", \"\", \"\"\n    \n    progress(0.7, desc=\"Optimizando constantes...\")\n    pareto = ParetoFront()\n    pareto.add_from_results(results)\n    best = pareto.get_best_by_rmse()\n    \n    if not best:\n        return \"Error en optimizacion\", None, \"\", \"\", \"\"\n    \n    progress(0.9, desc=\"Simplificando...\")\n    tree = ExpressionTree(best.tokens)\n    simplified = simplify_tree(tree)\n    y_pred = tree.evaluate(x, constants=best.constants)\n    \n    # Substitute constants for display\n    substituted_formula = simplified\n    if best.constants:\n        try:\n            positions = tree.root.get_constant_positions()\n            # We use the raw infix for substitution to ensure matching C positions\n            raw_infix = tree.get_infix()\n            substituted_formula = substitute_constants(raw_infix, best.constants, positions)\n        except:\n            substituted_formula = simplified\n    \n    fig = create_fit_plot(x, y, y_pred, simplified)\n    \n    # Format results\n    result_html = f\"\"\"\n    <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #00d4ff;\">\n        <h2 style=\"color: #00d4ff; margin: 0; font-size: 24px;\">Formula Encontrada</h2>\n        <div style=\"background: #0f0f23; padding: 15px; border-radius: 10px; margin: 15px 0; border-left: 4px solid #ff6b6b;\">\n            <code style=\"color: #ff6b6b; font-size: 28px; font-weight: bold;\">{substituted_formula}</code>\n        </div>\n        <div style=\"display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px;\">\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">RMSE</span><br>\n                <span style=\"color: #00d4ff; font-size: 16px; font-weight: bold;\">{best.rmse:.6f}</span>\n            </div>\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">Nodos</span><br>\n                <span style=\"color: #00d4ff; font-size: 16px; font-weight: bold;\">{best.complexity}</span>\n            </div>\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">Tiempo</span><br>\n                <span style=\"color: #00d4ff; font-size: 16px; font-weight: bold;\">{search_time:.2f}s</span>\n            </div>\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">Metodo</span><br>\n                <span style=\"color: #4ade80; font-size: 16px; font-weight: bold;\">{search_method}</span>\n            </div>\n        </div>\n        <div style=\"margin-top: 15px; padding: 10px; background: #0f0f23; border-radius: 8px;\">\n            <span style=\"color: #888;\">Patron:</span> \n            <span style=\"color: #ffd93d;\">{pattern['type']}</span> \n            <span style=\"color: #666;\">({pattern['confidence']:.0%})</span>\n            <span style=\"color: #888; margin-left: 20px;\">Device:</span>\n            <span style=\"color: #4ade80;\">{DEVICE.type.upper()}</span>\n        </div>\n    \"\"\"\n    \n    # Add constants if any\n    # Add constants if any\n    if best.constants:\n        # Sort and format cleanly\n        sorted_items = sorted(best.constants.items(), key=lambda x: str(x[0]))\n        clean_consts = []\n        for i, (k, v) in enumerate(sorted_items):\n            clean_consts.append(f\"C_{i+1}: {v:.4f}\")\n        const_str = \"  |  \".join(clean_consts)\n        \n        result_html += f\"\"\"\n        <div style=\"margin-top: 10px; padding: 10px; background: #0f0f23; border-radius: 8px; border-left: 3px solid #ffd93d;\">\n            <span style=\"color: #888;\">Constantes:</span>\n            <span style=\"color: #fff; font-family: monospace; margin-left: 10px;\">{const_str}</span>\n        </div>\n        \"\"\"\n        \n    result_html += \"</div>\"\n    \n    # Predictions table\n    pred_html = '<table style=\"width: 100%; border-collapse: collapse; background: #1a1a2e; border-radius: 10px; overflow: hidden;\">'\n    pred_html += '<tr style=\"background: #16213e;\"><th style=\"padding: 10px; color: #00d4ff;\">X</th><th style=\"color: #00d4ff;\">Pred</th><th style=\"color: #00d4ff;\">Real</th><th style=\"color: #00d4ff;\">Delta</th></tr>'\n    for i in range(min(50, len(x))):\n        delta = abs(y_pred[i] - y[i])\n        color = \"#4ade80\" if delta < 0.1 else \"#fbbf24\" if delta < 1 else \"#ef4444\"\n        pred_html += f'<tr style=\"border-bottom: 1px solid #333;\"><td style=\"padding: 8px; color: white; text-align: center;\">{x[i]:.2f}</td><td style=\"color: white; text-align: center;\">{y_pred[i]:.4f}</td><td style=\"color: white; text-align: center;\">{y[i]:.4f}</td><td style=\"color: {color}; text-align: center; font-weight: bold;\">{delta:.4f}</td></tr>'\n    pred_html += '</table>'\n    \n    # Alternatives\n    alt_html = '<div style=\"background: #1a1a2e; padding: 15px; border-radius: 10px;\">'\n    alt_html += '<h4 style=\"color: #00d4ff; margin-top: 0;\">Alternativas</h4>'\n    for i, sol in enumerate(pareto.solutions[:4]):\n        alt_html += f'<div style=\"padding: 5px 10px; margin: 5px 0; background: #0f0f23; border-radius: 5px; border-left: 3px solid {\"#00d4ff\" if i == 0 else \"#666\"};\"><code style=\"color: {\"#ff6b6b\" if i == 0 else \"#888\"};\">{sol.formula}</code> <span style=\"color: #666; font-size: 12px;\">RMSE: {sol.rmse:.4f}</span></div>'\n    alt_html += '</div>'\n    \n    return result_html, fig, pred_html, alt_html, simplified\n\n\ndef generate_example(tipo):\n    \"\"\"Generate example data.\"\"\"\n    if tipo == \"lineal\":\n        x = np.linspace(1, 10, 10)\n        y = 2 * x + 3\n    elif tipo == \"cuadratico\":\n        x = np.linspace(-5, 5, 11)\n        y = x**2 + 1\n    elif tipo == \"trig\":\n        x = np.linspace(0, 6.28, 20)\n        y = np.sin(x)\n    elif tipo == \"exp\":\n        x = np.linspace(0, 5, 15)\n        y = 2 * np.exp(0.5 * x)\n    else:\n        x = np.linspace(1, 10, 10)\n        y = 2 * x + 3\n    \n    return \", \".join([f\"{v:.2f}\" for v in x]), \", \".join([f\"{v:.4f}\" for v in y])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_training.py\n",
        "\"\"\"\nTraining functions for AlphaSymbolic Gradio App.\nWith proper data normalization.\n\"\"\"\nimport os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport gradio as gr\nfrom collections import deque\nimport random\n\nfrom core.grammar import VOCABULARY, TOKEN_TO_ID\nfrom data.synthetic_data import DataGenerator\nfrom ui.app_core import get_model, save_model, TRAINING_STATUS\n\n\ndef normalize_batch(x_list, y_list):\n    \"\"\"Normalize X and Y values to prevent numerical instability.\"\"\"\n    normalized_x = []\n    normalized_y = []\n    \n    for x, y in zip(x_list, y_list):\n        # Normalize X to [-1, 1]\n        x_min, x_max = x.min(), x.max()\n        if x_max - x_min > 1e-6:\n            x_norm = 2 * (x - x_min) / (x_max - x_min) - 1\n        else:\n            x_norm = np.zeros_like(x)\n        \n        # Normalize Y to [-1, 1] \n        y_min, y_max = y.min(), y.max()\n        if y_max - y_min > 1e-6:\n            y_norm = 2 * (y - y_min) / (y_max - y_min) - 1\n        else:\n            y_norm = np.zeros_like(y)\n        \n        normalized_x.append(x_norm)\n        normalized_y.append(y_norm)\n    \n    return normalized_x, normalized_y\n\n\ndef train_basic(epochs, batch_size, point_count=10, progress=gr.Progress()):\n    \"\"\"Basic training with synthetic data.\"\"\"\n    global TRAINING_STATUS\n    \n    if TRAINING_STATUS[\"running\"]:\n        return \"Entrenamiento ya en progreso\", None\n    \n    TRAINING_STATUS[\"running\"] = True\n    \n    try:\n        MODEL, DEVICE = get_model()\n        \n        MODEL.train()\n        optimizer = torch.optim.AdamW(MODEL.parameters(), lr=1e-4, weight_decay=0.01)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(epochs), eta_min=1e-6)\n        ce_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        \n        VOCAB_SIZE = len(VOCABULARY)\n        SOS_ID = VOCAB_SIZE\n        \n        data_gen = DataGenerator(max_depth=4)\n        losses = []\n        \n        for epoch in range(int(epochs)):\n            progress((epoch + 1) / epochs, desc=f\"Epoca {epoch+1}/{int(epochs)} [{DEVICE.type.upper()}]\")\n            \n            # Mix of inverse (known formulas) + random data (AlphaTensor-style)\n            half_batch = int(batch_size) // 2\n            batch_inverse = data_gen.generate_inverse_batch(half_batch, point_count=int(point_count))\n            batch_random = data_gen.generate_batch(int(batch_size) - half_batch, point_count=int(point_count))\n            batch = batch_inverse + batch_random\n            if len(batch) < 2:\n                continue\n            \n            x_list = [d['x'] for d in batch]\n            y_list = [d['y'] for d in batch]\n            \n            # Normalize data\n            x_list, y_list = normalize_batch(x_list, y_list)\n            \n            token_lists = [[TOKEN_TO_ID[t] for t in d['tokens']] for d in batch]\n            \n            max_len = max(len(s) for s in token_lists)\n            decoder_input = torch.full((len(batch), max_len + 1), SOS_ID, dtype=torch.long)\n            targets = torch.full((len(batch), max_len + 1), -1, dtype=torch.long)\n            \n            for i, seq in enumerate(token_lists):\n                decoder_input[i, 1:len(seq)+1] = torch.tensor(seq, dtype=torch.long)\n                targets[i, :len(seq)] = torch.tensor(seq, dtype=torch.long)\n            \n            x_tensor = torch.tensor(np.array(x_list), dtype=torch.float32).to(DEVICE)\n            y_tensor = torch.tensor(np.array(y_list), dtype=torch.float32).to(DEVICE)\n            decoder_input = decoder_input.to(DEVICE)\n            targets = targets.to(DEVICE)\n            \n            # Forward\n            optimizer.zero_grad()\n            logits, _ = MODEL(x_tensor, y_tensor, decoder_input)\n            loss = ce_loss(logits.view(-1, VOCAB_SIZE + 1), targets.view(-1))\n            \n            # Skip if loss is NaN\n            if torch.isnan(loss) or torch.isinf(loss):\n                continue\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(MODEL.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            losses.append(loss.item())\n        \n        save_model()\n        MODEL.eval()\n        TRAINING_STATUS[\"running\"] = False\n        \n        if not losses:\n            return \"Error: No se pudo calcular loss (revisar datos)\", None\n        \n        fig = create_loss_plot(losses, \"Entrenamiento Basico\")\n        \n        result = f\"\"\"\n        <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #4ade80;\">\n            <h2 style=\"color: #4ade80; margin: 0;\">Entrenamiento Completado</h2>\n            <p style=\"color: white;\">Epocas: {int(epochs)} | Loss Final: {losses[-1]:.4f}</p>\n            <p style=\"color: #00d4ff;\">Dispositivo: {DEVICE.type.upper()}</p>\n        </div>\n        \"\"\"\n        return result, fig\n        \n    except Exception as e:\n        TRAINING_STATUS[\"running\"] = False\n        return f\"Error: {str(e)}\", None\n\n\ndef train_curriculum(epochs, batch_size, point_count=10, progress=gr.Progress()):\n    \"\"\"Curriculum Learning - starts simple, increases difficulty gradually.\"\"\"\n    global TRAINING_STATUS\n    \n    if TRAINING_STATUS[\"running\"]:\n        return \"Entrenamiento ya en progreso\", None\n    \n    TRAINING_STATUS[\"running\"] = True\n    \n    try:\n        MODEL, DEVICE = get_model()\n        \n        MODEL.train()\n        optimizer = torch.optim.AdamW(MODEL.parameters(), lr=5e-5, weight_decay=0.01)  # Lower LR\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2)\n        ce_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        \n        VOCAB_SIZE = len(VOCABULARY)\n        SOS_ID = VOCAB_SIZE\n        losses = []\n        \n        for epoch in range(int(epochs)):\n            # Curriculum: slow progression\n            # Stage 1 (0-50%): depth 2-3, 80% inverse data\n            # Stage 2 (50-80%): depth 3-4, 50% inverse data  \n            # Stage 3 (80-100%): depth 4-5, 20% inverse data\n            progress_pct = epoch / epochs\n            \n            if progress_pct < 0.5:\n                current_depth = 2 + int(progress_pct * 2)  # 2-3\n                inverse_ratio = 0.8\n            elif progress_pct < 0.8:\n                current_depth = 3 + int((progress_pct - 0.5) * 3.3)  # 3-4\n                inverse_ratio = 0.5\n            else:\n                current_depth = 4 + int((progress_pct - 0.8) * 5)  # 4-5\n                inverse_ratio = 0.2\n            \n            progress((epoch + 1) / epochs, desc=f\"Epoca {epoch+1}/{int(epochs)} (prof: {current_depth}, inv: {inverse_ratio:.0%}) [{DEVICE.type.upper()}]\")\n            \n            data_gen = DataGenerator(max_depth=current_depth)\n            \n            # Mix inverse + random based on curriculum stage\n            n_inverse = int(batch_size * inverse_ratio)\n            n_random = int(batch_size) - n_inverse\n            \n            batch_inverse = data_gen.generate_inverse_batch(max(1, n_inverse), point_count=int(point_count)) if n_inverse > 0 else []\n            batch_random = data_gen.generate_batch(max(1, n_random), point_count=int(point_count)) if n_random > 0 else []\n            batch = batch_inverse + batch_random\n            if len(batch) < 2:\n                continue\n            \n            x_list = [d['x'] for d in batch]\n            y_list = [d['y'] for d in batch]\n            x_list, y_list = normalize_batch(x_list, y_list)\n            \n            token_lists = [[TOKEN_TO_ID[t] for t in d['tokens']] for d in batch]\n            \n            max_len = max(len(s) for s in token_lists)\n            decoder_input = torch.full((len(batch), max_len + 1), SOS_ID, dtype=torch.long)\n            targets = torch.full((len(batch), max_len + 1), -1, dtype=torch.long)\n            \n            for i, seq in enumerate(token_lists):\n                decoder_input[i, 1:len(seq)+1] = torch.tensor(seq, dtype=torch.long)\n                targets[i, :len(seq)] = torch.tensor(seq, dtype=torch.long)\n            \n            x_tensor = torch.tensor(np.array(x_list), dtype=torch.float32).to(DEVICE)\n            y_tensor = torch.tensor(np.array(y_list), dtype=torch.float32).to(DEVICE)\n            decoder_input = decoder_input.to(DEVICE)\n            targets = targets.to(DEVICE)\n            \n            optimizer.zero_grad()\n            logits, _ = MODEL(x_tensor, y_tensor, decoder_input)\n            loss = ce_loss(logits.view(-1, VOCAB_SIZE + 1), targets.view(-1))\n            \n            if torch.isnan(loss) or torch.isinf(loss):\n                continue\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(MODEL.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            losses.append(loss.item())\n        \n        save_model()\n        MODEL.eval()\n        TRAINING_STATUS[\"running\"] = False\n        \n        if not losses:\n            return \"Error: No se pudo calcular loss\", None\n        \n        fig = create_loss_plot(losses, \"Curriculum Learning\")\n        \n        result = f\"\"\"\n        <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #00d4ff;\">\n            <h2 style=\"color: #00d4ff; margin: 0;\">Curriculum Learning Completado</h2>\n            <p style=\"color: white;\">Epocas: {int(epochs)} | Loss Final: {losses[-1]:.4f}</p>\n            <p style=\"color: #888;\">Profundidad maxima: 6 | Dispositivo: {DEVICE.type.upper()}</p>\n        </div>\n        \"\"\"\n        return result, fig\n        \n    except Exception as e:\n        TRAINING_STATUS[\"running\"] = False\n        return f\"Error: {str(e)}\", None\n\n\ndef train_self_play(iterations, problems_per_iter, point_count=10, progress=gr.Progress()):\n    \"\"\"AlphaZero Self-Play loop.\"\"\"\n    global TRAINING_STATUS\n    \n    if TRAINING_STATUS[\"running\"]:\n        return \"Entrenamiento ya en progreso\", None\n    \n    TRAINING_STATUS[\"running\"] = True\n    \n    try:\n        MODEL, DEVICE = get_model()\n        \n        from search.mcts import MCTS\n        \n        optimizer = torch.optim.AdamW(MODEL.parameters(), lr=1e-4, weight_decay=0.01)\n        ce_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        \n        VOCAB_SIZE = len(VOCABULARY)\n        SOS_ID = VOCAB_SIZE\n        \n        replay_buffer = deque(maxlen=10000)\n        data_gen = DataGenerator(max_depth=5)\n        # Use MCTS for self-play as per AlphaZero\n        searcher = MCTS(MODEL, DEVICE, max_simulations=50)\n        \n        rmses = []\n        losses = []\n        \n        for iteration in range(int(iterations)):\n            progress((iteration + 1) / iterations, desc=f\"Iter {iteration+1}/{int(iterations)} [{DEVICE.type.upper()}]\")\n            \n            # Self-play phase\n            MODEL.eval()\n            \n            # Generate mix of problems: 50% inverse (solvable), 50% random\n            n_inverse = int(problems_per_iter) // 2\n            n_random = int(problems_per_iter) - n_inverse\n            \n            probs_inv = data_gen.generate_inverse_batch(n_inverse, point_count=int(point_count))\n            probs_rnd = data_gen.generate_batch(n_random, point_count=int(point_count))\n            problems = probs_inv + probs_rnd\n            \n            for prob in problems:\n                x_data = prob['x'].astype(np.float64)\n                y_data = prob['y'].astype(np.float64)\n                \n                try:\n                    result = searcher.search(x_data, y_data)\n                    if result and result.get('tokens'):\n                        replay_buffer.append({\n                            'x': x_data, 'y': y_data,\n                            'tokens': result['tokens'],\n                            'rmse': result['rmse']\n                        })\n                        rmses.append(result['rmse'])\n                except Exception as e:\n                    print(f\"Self-play error: {e}\")\n                    continue\n            \n            # Training phase\n            if len(replay_buffer) >= 16:\n                MODEL.train()\n                batch = random.sample(list(replay_buffer), min(32, len(replay_buffer)))\n                \n                x_list = [exp['x'] for exp in batch]\n                y_list = [exp['y'] for exp in batch]\n                x_list, y_list = normalize_batch(x_list, y_list)\n                \n                token_lists = [[TOKEN_TO_ID[t] for t in exp['tokens']] for exp in batch]\n                \n                max_len = max(len(s) for s in token_lists)\n                decoder_input = torch.full((len(batch), max_len + 1), SOS_ID, dtype=torch.long)\n                targets = torch.full((len(batch), max_len + 1), -1, dtype=torch.long)\n                \n                for i, seq in enumerate(token_lists):\n                    decoder_input[i, 1:len(seq)+1] = torch.tensor(seq, dtype=torch.long)\n                    targets[i, :len(seq)] = torch.tensor(seq, dtype=torch.long)\n                \n                x_tensor = torch.tensor(np.array(x_list), dtype=torch.float32).to(DEVICE)\n                y_tensor = torch.tensor(np.array(y_list), dtype=torch.float32).to(DEVICE)\n                decoder_input = decoder_input.to(DEVICE)\n                targets = targets.to(DEVICE)\n                \n                # Prepare value targets based on RMSE\n                # Transform RMSE -> Value [0, 1] (1 = perfect match)\n                rmses_batch = [exp['rmse'] for exp in batch]\n                value_targets = torch.tensor([1.0 / (1.0 + r) for r in rmses_batch], dtype=torch.float32).unsqueeze(1).to(DEVICE)\n                \n                optimizer.zero_grad()\n                logits, value_pred = MODEL(x_tensor, y_tensor, decoder_input)\n                \n                # Policy Loss (Cross Entropy)\n                loss_policy = ce_loss(logits.view(-1, VOCAB_SIZE + 1), targets.view(-1))\n                \n                # Value Loss (MSE)\n                # We want value_pred to match the \"quality\" of the formula associated with this state\n                # Note: value_pred corresponds to the LAST token in sequence\n                value_pred_last = value_pred  # It's already [batch, 1] from just the last token in model.py\n                loss_value = torch.nn.functional.mse_loss(value_pred, value_targets)\n                \n                # Total Loss = Policy + Value\n                loss = loss_policy + loss_value\n                \n                if not (torch.isnan(loss) or torch.isinf(loss)):\n                    loss.backward()\n                    torch.nn.utils.clip_grad_norm_(MODEL.parameters(), 1.0)\n                    optimizer.step()\n                    losses.append(loss.item())\n            \n            # Periodic save\n            if (iteration + 1) % 10 == 0:\n                save_model()\n        \n        save_model()\n        MODEL.eval()\n        TRAINING_STATUS[\"running\"] = False\n        \n        fig = create_selfplay_plot(losses, rmses)\n        \n        avg_rmse = np.mean(rmses[-50:]) if rmses else 0\n        result = f\"\"\"\n        <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #ff6b6b;\">\n            <h2 style=\"color: #ff6b6b; margin: 0;\">Self-Play Completado</h2>\n            <p style=\"color: white;\">Iteraciones: {int(iterations)} | Problemas: {len(rmses)}</p>\n            <p style=\"color: #888;\">RMSE Promedio: {avg_rmse:.4f} | Dispositivo: {DEVICE.type.upper()}</p>\n        </div>\n        \"\"\"\n        return result, fig\n        \n    except Exception as e:\n        TRAINING_STATUS[\"running\"] = False\n        return f\"Error: {str(e)}\", None\n\n\ndef create_loss_plot(losses, title):\n    \"\"\"Create a loss plot with dark theme.\"\"\"\n    fig, ax = plt.subplots(figsize=(8, 4), facecolor='#1a1a2e')\n    ax.set_facecolor('#1a1a2e')\n    ax.plot(losses, color='#00d4ff', linewidth=2)\n    ax.set_xlabel('Epoca', color='white')\n    ax.set_ylabel('Loss', color='white')\n    ax.set_title(title, color='white', fontweight='bold')\n    ax.tick_params(colors='white')\n    ax.grid(True, alpha=0.2)\n    for spine in ax.spines.values():\n        spine.set_color('#00d4ff')\n    plt.tight_layout()\n    return fig\n\n\ndef create_selfplay_plot(losses, rmses):\n    \"\"\"Create dual plot for self-play results.\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4), facecolor='#1a1a2e')\n    \n    ax1.set_facecolor('#1a1a2e')\n    if losses:\n        ax1.plot(losses, color='#00d4ff', linewidth=2)\n    ax1.set_xlabel('Step', color='white')\n    ax1.set_ylabel('Loss', color='white')\n    ax1.set_title('Policy Loss', color='white', fontweight='bold')\n    ax1.tick_params(colors='white')\n    ax1.grid(True, alpha=0.2)\n    \n    ax2.set_facecolor('#1a1a2e')\n    if rmses:\n        ax2.plot(rmses, color='#ff6b6b', linewidth=1, alpha=0.5)\n        if len(rmses) > 10:\n            ma = np.convolve(rmses, np.ones(10)/10, mode='valid')\n            ax2.plot(range(9, len(rmses)), ma, color='#ff6b6b', linewidth=2)\n    ax2.set_xlabel('Problema', color='white')\n    ax2.set_ylabel('RMSE', color='white')\n    ax2.set_title('RMSE', color='white', fontweight='bold')\n    ax2.tick_params(colors='white')\n    ax2.grid(True, alpha=0.2)\n    \n    for ax in [ax1, ax2]:\n        for spine in ax.spines.values():\n            spine.set_color('#00d4ff')\n    \n    plt.tight_layout()\n    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/benchmark_runner.py\n",
        "import torch\nimport numpy as np\nimport time\nimport traceback\nfrom search.mcts import MCTS\nfrom data.benchmark_data import BENCHMARK_SUITE, get_benchmark_data\nfrom utils.optimize_constants import optimize_constants\n\ndef run_benchmark_suite(model, device, progress_callback=None):\n    \"\"\"\n    Runs the full benchmark suite.\n    Args:\n        model: Loaded AlphaSymbolic model\n        device: Torch device\n        progress_callback: Function(float, string) to update UI\n        \n    Returns:\n        results: List of result dicts\n        summary: Dict with aggregated stats\n    \"\"\"\n    results = []\n    \n    # Configure MCTS for benchmark (balanced speed/accuracy)\n    # 500 simulations is decent for benchmarking\n    mcts = MCTS(model, device, max_simulations=500, lambda_mix=0.5, batch_size=32)\n    \n    total = len(BENCHMARK_SUITE)\n    solved_count = 0\n    \n    for i, problem in enumerate(BENCHMARK_SUITE):\n        if progress_callback:\n            progress_callback(i / total, f\"Testing: {problem['name']}...\")\n            \n        x, y, _ = get_benchmark_data(problem['id'])\n        \n        start_time = time.time()\n        \n        # Run Search\n        try:\n            search_result = mcts.search(x, y)\n             # Determine success\n            # Success threshold: RMSE < 0.01 (or 1% relative error)\n            rmse = search_result['rmse']\n            is_solved = rmse < 0.05 # Looser threshold for general regression\n            \n            # Special check for exact integer symbolic match? No, RMSE is ground truth.\n            \n            elapsed = time.time() - start_time\n            \n            if is_solved:\n                solved_count += 1\n                status = \"\u2705 SOLVED\"\n            else:\n                status = \"\u274c FAILED\"\n                \n            results.append({\n                'id': problem['id'],\n                'name': problem['name'],\n                'level': problem['level'],\n                'rmse': rmse,\n                'time': elapsed,\n                'status': status,\n                'found_formula': search_result.get('formula', '???'),\n                'is_solved': is_solved\n            })\n            \n        except Exception as e:\n            print(f\"Error in benchmark {problem['name']}:\")\n            traceback.print_exc()\n            results.append({\n                'id': problem['id'],\n                'name': problem['name'],\n                'level': problem['level'],\n                'rmse': 1e9,\n                'time': 0,\n                'status': \"\u26a0\ufe0f ERROR\",\n                'found_formula': \"Error\",\n                'is_solved': False\n            })\n\n    # Summary\n    if progress_callback:\n        progress_callback(1.0, \"Done!\")\n        \n    score = (solved_count / total) * 100\n    summary = {\n        'total': total,\n        'solved': solved_count,\n        'score': score,\n        'avg_time': np.mean([r['time'] for r in results]) if results else 0\n    }\n    \n    return results, summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/check_model.py\n",
        "\nimport torch\nimport os\n\ndef check_model():\n    # Model is in the root directory (parent of utils)\n    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n    path = os.path.join(root_dir, \"alpha_symbolic_model.pth\")\n    if not os.path.exists(path):\n        print(f\"File {path} does not exist.\")\n        return\n\n    try:\n        state_dict = torch.load(path, map_location='cpu', weights_only=True)\n        print(f\"Loaded {len(state_dict)} keys.\")\n        \n        has_nan = False\n        for k, v in state_dict.items():\n            if torch.isnan(v).any() or torch.isinf(v).any():\n                print(f\"\u274c Parameter {k} has NaN/Inf!\")\n                has_nan = True\n        \n        if has_nan:\n            print(\"\u26a0\ufe0f Model is CORRUPTED with NaNs.\")\n            print(\"Deleting corrupted model file...\")\n            os.remove(path)\n            print(\"Deleted.\")\n        else:\n            print(\"\u2705 Model weights look clean.\")\n            \n    except Exception as e:\n        print(f\"Error checking model: {e}\")\n\nif __name__ == \"__main__\":\n    check_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/cpp_binding.py\n",
        "\"\"\"\nC++ Binding for AlphaSymbolic.\nUses pybind11 to connect Python with C++ evaluator for maximum speed.\n\nTo build:\n1. Install pybind11: pip install pybind11\n2. Compile: python cpp_binding.py build_ext --inplace\n\"\"\"\n\n# This file creates the Python bindings. The actual C++ code is separate.\n\nCPP_SOURCE = '''\n// cpp_evaluator.cpp\n// Fast C++ expression evaluator for AlphaSymbolic\n\n#include <pybind11/pybind11.h>\n#include <pybind11/numpy.h>\n#include <pybind11/stl.h>\n#include <cmath>\n#include <vector>\n#include <string>\n#include <stack>\n#include <unordered_map>\n\nnamespace py = pybind11;\n\n// Operator lookup\nstd::unordered_map<std::string, int> OP_ARITY = {\n    {\"+\", 2}, {\"-\", 2}, {\"*\", 2}, {\"/\", 2}, {\"pow\", 2}, {\"mod\", 2},\n    {\"sin\", 1}, {\"cos\", 1}, {\"tan\", 1}, {\"exp\", 1}, {\"log\", 1},\n    {\"sqrt\", 1}, {\"abs\", 1}, {\"floor\", 1}, {\"ceil\", 1}, {\"neg\", 1}\n};\n\nclass ExpressionEvaluator {\npublic:\n    py::array_t<double> evaluate(\n        const std::vector<std::string>& tokens,\n        py::array_t<double> x_values,\n        const std::unordered_map<std::string, double>& constants = {}\n    ) {\n        auto x = x_values.unchecked<1>();\n        size_t n = x.shape(0);\n        \n        py::array_t<double> result(n);\n        auto r = result.mutable_unchecked<1>();\n        \n        for (size_t i = 0; i < n; i++) {\n            r(i) = eval_at_point(tokens, x(i), constants);\n        }\n        \n        return result;\n    }\n    \nprivate:\n    double eval_at_point(\n        const std::vector<std::string>& tokens,\n        double x_val,\n        const std::unordered_map<std::string, double>& constants\n    ) {\n        std::stack<double> stack;\n        \n        // Process tokens in reverse (for prefix notation)\n        for (int i = tokens.size() - 1; i >= 0; i--) {\n            const std::string& token = tokens[i];\n            \n            auto it = OP_ARITY.find(token);\n            \n            if (it != OP_ARITY.end()) {\n                // Operator\n                int arity = it->second;\n                \n                if (arity == 1 && !stack.empty()) {\n                    double a = stack.top(); stack.pop();\n                    stack.push(apply_unary(token, a));\n                } else if (arity == 2 && stack.size() >= 2) {\n                    double a = stack.top(); stack.pop();\n                    double b = stack.top(); stack.pop();\n                    stack.push(apply_binary(token, a, b));\n                }\n            } else if (token == \"x\") {\n                stack.push(x_val);\n            } else if (token == \"pi\") {\n                stack.push(M_PI);\n            } else if (token == \"e\") {\n                stack.push(M_E);\n            } else if (token == \"C\") {\n                auto cit = constants.find(\"C\");\n                stack.push(cit != constants.end() ? cit->second : 1.0);\n            } else {\n                // Try to parse as number\n                try {\n                    stack.push(std::stod(token));\n                } catch (...) {\n                    stack.push(0.0);\n                }\n            }\n        }\n        \n        return stack.empty() ? 0.0 : stack.top();\n    }\n    \n    double apply_unary(const std::string& op, double a) {\n        if (op == \"sin\") return std::sin(a);\n        if (op == \"cos\") return std::cos(a);\n        if (op == \"tan\") return std::tan(a);\n        if (op == \"exp\") return std::exp(std::min(100.0, std::max(-100.0, a)));\n        if (op == \"log\") return std::log(std::abs(a) + 1e-10);\n        if (op == \"sqrt\") return std::sqrt(std::abs(a));\n        if (op == \"abs\") return std::abs(a);\n        if (op == \"floor\") return std::floor(a);\n        if (op == \"ceil\") return std::ceil(a);\n        if (op == \"neg\") return -a;\n        return a;\n    }\n    \n    double apply_binary(const std::string& op, double a, double b) {\n        if (op == \"+\") return a + b;\n        if (op == \"-\") return a - b;\n        if (op == \"*\") return a * b;\n        if (op == \"/\") return b != 0 ? a / b : 0.0;\n        if (op == \"pow\") return std::pow(std::abs(a) + 1e-10, std::min(10.0, std::max(-10.0, b)));\n        if (op == \"mod\") return std::fmod(a, b + 1e-10);\n        return 0.0;\n    }\n};\n\nPYBIND11_MODULE(cpp_evaluator, m) {\n    m.doc() = \"Fast C++ expression evaluator for AlphaSymbolic\";\n    \n    py::class_<ExpressionEvaluator>(m, \"ExpressionEvaluator\")\n        .def(py::init<>())\n        .def(\"evaluate\", &ExpressionEvaluator::evaluate,\n             py::arg(\"tokens\"),\n             py::arg(\"x_values\"),\n             py::arg(\"constants\") = std::unordered_map<std::string, double>());\n}\n'''\n\ndef write_cpp_source():\n    \"\"\"Write the C++ source file.\"\"\"\n    with open(\"cpp_evaluator.cpp\", \"w\") as f:\n        f.write(CPP_SOURCE)\n    print(\"Written cpp_evaluator.cpp\")\n\ndef get_setup_script():\n    \"\"\"Return the setup.py content for building the extension.\"\"\"\n    return '''\nfrom setuptools import setup, Extension\nimport pybind11\n\next_modules = [\n    Extension(\n        'cpp_evaluator',\n        sources=['cpp_evaluator.cpp'],\n        include_dirs=[pybind11.get_include()],\n        language='c++',\n        extra_compile_args=['-std=c++14', '-O3', '-fPIC'],\n    ),\n]\n\nsetup(\n    name='cpp_evaluator',\n    ext_modules=ext_modules,\n)\n'''\n\ndef build_extension():\n    \"\"\"Build the C++ extension.\"\"\"\n    import subprocess\n    import sys\n    \n    # Write source\n    write_cpp_source()\n    \n    # Write setup.py\n    with open(\"setup_cpp.py\", \"w\") as f:\n        f.write(get_setup_script())\n    \n    # Build\n    result = subprocess.run([sys.executable, \"setup_cpp.py\", \"build_ext\", \"--inplace\"])\n    return result.returncode == 0\n\n\n# Fallback Python evaluator if C++ not available\nclass PythonEvaluator:\n    \"\"\"Pure Python fallback evaluator.\"\"\"\n    \n    def evaluate(self, tokens, x_values, constants=None):\n        from grammar import ExpressionTree\n        tree = ExpressionTree(tokens)\n        return tree.evaluate(x_values, constants)\n\n\ndef get_evaluator():\n    \"\"\"Get the fastest available evaluator.\"\"\"\n    try:\n        from cpp_evaluator import ExpressionEvaluator\n        print(\"Using C++ evaluator (fast)\")\n        return ExpressionEvaluator()\n    except ImportError:\n        print(\"C++ evaluator not built, using Python fallback\")\n        return PythonEvaluator()\n\n\nif __name__ == \"__main__\":\n    import argparse\n    \n    parser = argparse.ArgumentParser(description=\"C++ Binding Manager\")\n    parser.add_argument(\"--build\", action=\"store_true\", help=\"Build the C++ extension\")\n    parser.add_argument(\"--test\", action=\"store_true\", help=\"Test the evaluator\")\n    args = parser.parse_args()\n    \n    if args.build:\n        print(\"Building C++ extension...\")\n        if build_extension():\n            print(\"Build successful!\")\n        else:\n            print(\"Build failed. Make sure pybind11 is installed: pip install pybind11\")\n    \n    if args.test:\n        import numpy as np\n        \n        evaluator = get_evaluator()\n        \n        x = np.linspace(-5, 5, 100)\n        tokens = ['+', '*', '2', 'x', '3']  # 2*x + 3\n        \n        result = evaluator.evaluate(tokens, x)\n        expected = 2 * x + 3\n        \n        error = np.max(np.abs(result - expected))\n        print(f\"Max error: {error}\")\n        print(\"Test passed!\" if error < 1e-10 else \"Test failed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/detect_pattern.py\n",
        "\"\"\"\nTarget Pattern Detection for AlphaSymbolic.\nAnalyzes target Y values to detect patterns (polynomial, exponential, periodic, etc.)\nand suggests initial search biases.\n\"\"\"\nimport numpy as np\nfrom scipy import stats\nfrom scipy.fft import fft\nfrom core.grammar import ExpressionTree\n\ndef detect_pattern(x_values, y_values):\n    \"\"\"\n    Analyze (x, y) data to detect patterns.\n    Returns a dict with pattern type probabilities and suggested operators.\n    \"\"\"\n    x = np.array(x_values, dtype=np.float64)\n    y = np.array(y_values, dtype=np.float64)\n    \n    results = {\n        'type': 'unknown',\n        'confidence': 0.0,\n        'suggested_ops': [],\n        'details': {}\n    }\n    \n    if len(x) < 3:\n        return results\n    \n    scores = {}\n    \n    # 1. Check for linear pattern (y = ax + b)\n    if len(x) >= 2:\n        slope, intercept, r_value, _, _ = stats.linregress(x, y)\n        scores['linear'] = r_value ** 2\n        results['details']['linear'] = {\n            'slope': slope,\n            'intercept': intercept,\n            'r_squared': r_value ** 2\n        }\n    \n    # 2. Check for quadratic pattern (y = ax^2 + bx + c)\n    if len(x) >= 3:\n        try:\n            coeffs = np.polyfit(x, y, 2)\n            y_pred = np.polyval(coeffs, x)\n            ss_res = np.sum((y - y_pred) ** 2)\n            ss_tot = np.sum((y - np.mean(y)) ** 2)\n            r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n            scores['quadratic'] = r2\n            results['details']['quadratic'] = {\n                'coefficients': coeffs.tolist(),\n                'r_squared': r2\n            }\n        except:\n            pass\n    \n    # 3. Check for exponential pattern (y = a * e^(bx))\n    if np.all(y > 0):  # Exponential only for positive y\n        try:\n            log_y = np.log(y)\n            slope, intercept, r_value, _, _ = stats.linregress(x, log_y)\n            scores['exponential'] = r_value ** 2\n            results['details']['exponential'] = {\n                'a': np.exp(intercept),\n                'b': slope,\n                'r_squared': r_value ** 2\n            }\n        except:\n            pass\n    \n    # 4. Check for periodic/sinusoidal pattern\n    if len(y) >= 4:\n        try:\n            # Simple FFT analysis\n            y_centered = y - np.mean(y)\n            fft_vals = np.abs(fft(y_centered))\n            \n            # Check if there's a dominant frequency\n            if len(fft_vals) > 1:\n                max_idx = np.argmax(fft_vals[1:len(fft_vals)//2]) + 1\n                max_power = fft_vals[max_idx]\n                total_power = np.sum(fft_vals[1:len(fft_vals)//2])\n                \n                if total_power > 0:\n                    periodicity = max_power / total_power\n                    scores['periodic'] = periodicity\n                    results['details']['periodic'] = {\n                        'dominant_freq_idx': int(max_idx),\n                        'periodicity_score': periodicity\n                    }\n        except:\n            pass\n    \n    # 5. Check for power law (y = a * x^b)\n    if np.all(x > 0) and np.all(y > 0):\n        try:\n            log_x = np.log(x)\n            log_y = np.log(y)\n            slope, intercept, r_value, _, _ = stats.linregress(log_x, log_y)\n            scores['power'] = r_value ** 2\n            results['details']['power'] = {\n                'a': np.exp(intercept),\n                'b': slope,\n                'r_squared': r_value ** 2\n            }\n        except:\n            pass\n    \n    # 6. Check for factorial/gamma pattern (for integer-like x)\n    if np.all(x > 0) and np.all(x == np.floor(x)):\n        try:\n            from scipy.special import gamma\n            x_int = x.astype(int)\n            y_gamma = gamma(x_int + 1)  # gamma(n+1) = n!\n            \n            # Simple linear fit between y and gamma\n            if not np.any(np.isinf(y_gamma)):\n                slope, intercept, r_value, _, _ = stats.linregress(y_gamma, y)\n                scores['factorial'] = r_value ** 2\n                results['details']['factorial'] = {\n                    'r_squared': r_value ** 2\n                }\n        except:\n            pass\n    \n    # Determine best pattern\n    if scores:\n        best_pattern = max(scores.items(), key=lambda x: x[1])\n        results['type'] = best_pattern[0]\n        results['confidence'] = best_pattern[1]\n        \n        # Suggest operators based on pattern\n        op_suggestions = {\n            'linear': ['+', '-', '*', 'x', 'C'],\n            'quadratic': ['pow', '+', '*', 'x', 'C', '2'],\n            'exponential': ['exp', '*', '+', 'x', 'C'],\n            'periodic': ['sin', 'cos', '*', '+', 'x', 'C'],\n            'power': ['pow', '*', 'x', 'C'],\n            'factorial': ['gamma', '*', '+', 'x', 'C']\n        }\n        results['suggested_ops'] = op_suggestions.get(best_pattern[0], [])\n    \n    return results\n\n\ndef summarize_pattern(result):\n    \"\"\"Pretty-print pattern detection result.\"\"\"\n    print(f\"\\n=== Pattern Detection ===\")\n    print(f\"Detected Type: {result['type']} (confidence: {result['confidence']:.2%})\")\n    print(f\"Suggested Operators: {', '.join(result['suggested_ops'])}\")\n    \n    if result['type'] in result['details']:\n        print(f\"Details: {result['details'][result['type']]}\")\n\n\nif __name__ == \"__main__\":\n    # Test with different patterns\n    \n    # Linear: y = 2x + 3\n    print(\"\\n--- Test: Linear ---\")\n    x1 = np.linspace(0, 10, 20)\n    y1 = 2 * x1 + 3 + np.random.normal(0, 0.1, 20)\n    result1 = detect_pattern(x1, y1)\n    summarize_pattern(result1)\n    \n    # Quadratic: y = x^2 + 1\n    print(\"\\n--- Test: Quadratic ---\")\n    x2 = np.linspace(-5, 5, 20)\n    y2 = x2**2 + 1\n    result2 = detect_pattern(x2, y2)\n    summarize_pattern(result2)\n    \n    # Exponential: y = 2 * e^(0.5x)\n    print(\"\\n--- Test: Exponential ---\")\n    x3 = np.linspace(0, 5, 20)\n    y3 = 2 * np.exp(0.5 * x3)\n    result3 = detect_pattern(x3, y3)\n    summarize_pattern(result3)\n    \n    # Periodic: y = sin(x)\n    print(\"\\n--- Test: Periodic ---\")\n    x4 = np.linspace(0, 4*np.pi, 50)\n    y4 = np.sin(x4)\n    result4 = detect_pattern(x4, y4)\n    summarize_pattern(result4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/gpu_eval.py\n",
        "\"\"\"\nGPU Batched Formula Evaluation for AlphaSymbolic.\nEvaluates multiple formulas simultaneously on GPU using PyTorch.\n\"\"\"\nimport torch\nimport numpy as np\nfrom core.grammar import VOCABULARY, OPERATORS, TOKEN_TO_ID, ExpressionTree\n\n# Create operation lookup for vectorized evaluation\nOP_FUNCS = {\n    '+': lambda a, b: a + b,\n    '-': lambda a, b: a - b,\n    '*': lambda a, b: a * b,\n    '/': lambda a, b: torch.where(b != 0, a / b, torch.zeros_like(a)),\n    'pow': lambda a, b: torch.pow(torch.abs(a) + 1e-8, torch.clamp(b, -10, 10)),\n    'mod': lambda a, b: torch.fmod(a, b + 1e-8),\n    'sin': lambda a: torch.sin(a),\n    'cos': lambda a: torch.cos(a),\n    'tan': lambda a: torch.tan(a),\n    'exp': lambda a: torch.exp(torch.clamp(a, -100, 100)),\n    'log': lambda a: torch.log(torch.abs(a) + 1e-8),\n    'sqrt': lambda a: torch.sqrt(torch.abs(a)),\n    'abs': lambda a: torch.abs(a),\n    'floor': lambda a: torch.floor(a),\n    'ceil': lambda a: torch.ceil(a),\n    'gamma': lambda a: torch.lgamma(torch.clamp(a, 1e-8, 50)).exp(),  # Approximate\n    'neg': lambda a: -a,\n}\n\n\nclass GPUEvaluator:\n    \"\"\"Batch evaluator for formulas on GPU.\"\"\"\n    \n    def __init__(self, device=None):\n        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    def evaluate_single(self, tokens, x_values, constants=None):\n        \"\"\"\n        Evaluate a single formula on GPU.\n        tokens: list of tokens in prefix notation\n        x_values: numpy array or tensor of x values\n        constants: dict mapping positions to constant values\n        \"\"\"\n        if isinstance(x_values, np.ndarray):\n            x_tensor = torch.tensor(x_values, dtype=torch.float32, device=self.device)\n        else:\n            x_tensor = x_values.to(self.device)\n        \n        try:\n            result = self._eval_prefix(tokens, x_tensor, constants or {})\n            return result.cpu().numpy() if isinstance(result, torch.Tensor) else result\n        except Exception as e:\n            return np.full(len(x_values), np.nan)\n    \n    def _eval_prefix(self, tokens, x, constants, idx=0, path=None):\n        \"\"\"Recursively evaluate prefix notation on GPU.\"\"\"\n        if path is None:\n            path = []\n        \n        if idx >= len(tokens):\n            return torch.zeros_like(x), idx\n        \n        token = tokens[idx]\n        \n        # Terminal nodes\n        if token == 'x':\n            return x, idx + 1\n        if token == 'pi':\n            return torch.full_like(x, np.pi), idx + 1\n        if token == 'e':\n            return torch.full_like(x, np.e), idx + 1\n        if token == 'C':\n            val = constants.get(tuple(path), 1.0)\n            return torch.full_like(x, val), idx + 1\n        \n        # Try numeric constant\n        try:\n            val = float(token)\n            return torch.full_like(x, val), idx + 1\n        except:\n            pass\n        \n        # Operators\n        if token in OPERATORS:\n            arity = OPERATORS[token]\n            \n            if arity == 1:\n                arg, next_idx = self._eval_prefix(tokens, x, constants, idx + 1, path + [0])\n                return OP_FUNCS[token](arg), next_idx\n            elif arity == 2:\n                arg1, mid_idx = self._eval_prefix(tokens, x, constants, idx + 1, path + [0])\n                arg2, next_idx = self._eval_prefix(tokens, x, constants, mid_idx, path + [1])\n                return OP_FUNCS[token](arg1, arg2), next_idx\n        \n        return torch.zeros_like(x), idx + 1\n    \n    def evaluate_batch(self, formulas, x_values, constants_list=None):\n        \"\"\"\n        Evaluate multiple formulas on the same x values.\n        formulas: list of token lists\n        x_values: shared x values\n        constants_list: list of constant dicts (one per formula)\n        \n        Returns: numpy array of shape [num_formulas, num_points]\n        \"\"\"\n        if isinstance(x_values, np.ndarray):\n            x_tensor = torch.tensor(x_values, dtype=torch.float32, device=self.device)\n        else:\n            x_tensor = x_values.to(self.device)\n        \n        results = []\n        \n        for i, tokens in enumerate(formulas):\n            constants = constants_list[i] if constants_list else {}\n            try:\n                result, _ = self._eval_prefix(tokens, x_tensor, constants, 0, [])\n                # Handle potential issues\n                result = torch.where(torch.isfinite(result), result, torch.zeros_like(result))\n                results.append(result)\n            except:\n                results.append(torch.full_like(x_tensor, np.nan))\n        \n        # Stack results\n        stacked = torch.stack(results, dim=0)\n        return stacked.cpu().numpy()\n    \n    def compute_rmse_batch(self, formulas, x_values, y_target, constants_list=None):\n        \"\"\"\n        Compute RMSE for multiple formulas at once.\n        Returns: numpy array of RMSEs [num_formulas]\n        \"\"\"\n        y_preds = self.evaluate_batch(formulas, x_values, constants_list)\n        \n        # Compute RMSE for each formula\n        y_target_np = np.array(y_target)\n        \n        rmses = []\n        for y_pred in y_preds:\n            if np.any(np.isnan(y_pred)):\n                rmses.append(float('inf'))\n            else:\n                rmse = np.sqrt(np.mean((y_pred - y_target_np) ** 2))\n                rmses.append(rmse)\n        \n        return np.array(rmses)\n\n\nclass BatchOptimizer:\n    \"\"\"Optimize constants for multiple formulas in parallel.\"\"\"\n    \n    def __init__(self, device=None):\n        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.evaluator = GPUEvaluator(device)\n    \n    def optimize_batch(self, formulas, x_values, y_target, steps=100, lr=0.1):\n        \"\"\"\n        Optimize constants for multiple formulas using gradient descent.\n        \n        Returns: list of (optimized_constants_dict, final_rmse) tuples\n        \"\"\"\n        x_tensor = torch.tensor(x_values, dtype=torch.float32, device=self.device)\n        y_tensor = torch.tensor(y_target, dtype=torch.float32, device=self.device)\n        \n        results = []\n        \n        for tokens in formulas:\n            tree = ExpressionTree(tokens)\n            if not tree.is_valid:\n                results.append(({}, float('inf')))\n                continue\n            \n            # Count constants\n            positions = tree.root.get_constant_positions() if tree.root else []\n            n_constants = len(positions)\n            \n            if n_constants == 0:\n                # No constants to optimize\n                y_pred = self.evaluator.evaluate_single(tokens, x_values)\n                rmse = np.sqrt(np.mean((y_pred - y_target) ** 2))\n                results.append(({}, rmse))\n                continue\n            \n            # Create trainable parameters\n            params = torch.ones(n_constants, requires_grad=True, device=self.device)\n            optimizer = torch.optim.Adam([params], lr=lr)\n            \n            for _ in range(steps):\n                optimizer.zero_grad()\n                \n                # Build constants dict\n                constants = {tuple(pos): params[i].item() for i, pos in enumerate(positions)}\n                \n                # Evaluate\n                y_pred, _ = self.evaluator._eval_prefix(tokens, x_tensor, constants, 0, [])\n                \n                # Loss\n                loss = torch.mean((y_pred - y_tensor) ** 2)\n                \n                if not torch.isfinite(loss):\n                    break\n                \n                loss.backward()\n                optimizer.step()\n            \n            # Final result\n            final_constants = {tuple(pos): params[i].item() for i, pos in enumerate(positions)}\n            final_rmse = np.sqrt(loss.item()) if torch.isfinite(loss) else float('inf')\n            results.append((final_constants, final_rmse))\n        \n        return results\n\n\n# Quick test\nif __name__ == \"__main__\":\n    evaluator = GPUEvaluator()\n    \n    # Test single evaluation\n    x = np.linspace(-5, 5, 100)\n    \n    # Test: x^2 + 1\n    tokens = ['+', 'pow', 'x', '2', '1']\n    result = evaluator.evaluate_single(tokens, x)\n    expected = x**2 + 1\n    print(f\"Single eval error: {np.max(np.abs(result - expected)):.6f}\")\n    \n    # Test batch evaluation\n    formulas = [\n        ['+', 'x', '1'],          # x + 1\n        ['*', '2', 'x'],          # 2 * x\n        ['+', 'pow', 'x', '2', '1'],  # x^2 + 1\n    ]\n    \n    results = evaluator.evaluate_batch(formulas, x)\n    print(f\"Batch results shape: {results.shape}\")  # Should be [3, 100]\n    \n    # Test RMSE batch\n    y_target = 2 * x + 3\n    rmses = evaluator.compute_rmse_batch(formulas, x, y_target)\n    print(f\"RMSEs: {rmses}\")\n    \n    print(\"\\nGPU batch evaluation working!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/multivar.py\n",
        "\"\"\"\nMulti-Variable Support for AlphaSymbolic.\nExtends the grammar to support multiple input variables: x1, x2, x3, etc.\n\"\"\"\nimport numpy as np\nimport torch\nfrom scipy.special import gamma as scipy_gamma\n\n# Multi-variable operators (same as single variable)\nOPERATORS = {\n    '+': 2, '-': 2, '*': 2, '/': 2, 'pow': 2, 'mod': 2,\n    'sin': 1, 'cos': 1, 'tan': 1, 'exp': 1, 'log': 1,\n    'sqrt': 1, 'abs': 1, 'floor': 1, 'ceil': 1, 'gamma': 1, 'neg': 1,\n}\n\n# Constants\nCONSTANTS = ['C', '0', '1', '2', '3', '5', '10', 'pi', 'e']\n\n\ndef build_vocabulary(num_variables):\n    \"\"\"Build vocabulary for N input variables.\"\"\"\n    variables = [f'x{i}' for i in range(num_variables)]\n    vocab = list(OPERATORS.keys()) + variables + CONSTANTS\n    token_to_id = {token: i for i, token in enumerate(vocab)}\n    id_to_token = {i: token for token, i in token_to_id.items()}\n    return vocab, variables, token_to_id, id_to_token\n\n\nclass MultiVarNode:\n    def __init__(self, value, children=None):\n        self.value = value\n        self.children = children if children else []\n    \n    def to_infix(self):\n        if not self.children:\n            return str(self.value)\n        op = self.value\n        if len(self.children) == 1:\n            return f\"{op}({self.children[0].to_infix()})\"\n        elif len(self.children) == 2:\n            if op == 'pow':\n                return f\"({self.children[0].to_infix()} ^ {self.children[1].to_infix()})\"\n            return f\"({self.children[0].to_infix()} {op} {self.children[1].to_infix()})\"\n        return str(self.value)\n    \n    def count_constants(self):\n        count = 1 if self.value == 'C' else 0\n        for child in self.children:\n            count += child.count_constants()\n        return count\n\n\nclass MultiVarExpressionTree:\n    \"\"\"Expression tree that supports multiple variables.\"\"\"\n    \n    def __init__(self, token_list, num_variables=2):\n        self.tokens = token_list\n        self.num_variables = num_variables\n        self.variables = [f'x{i}' for i in range(num_variables)]\n        \n        try:\n            self.root, remaining = self._build_tree(token_list)\n            if remaining:\n                raise ValueError(\"Tokens remained\")\n            self.is_valid = True\n        except:\n            self.root = None\n            self.is_valid = False\n    \n    def _build_tree(self, tokens):\n        if not tokens:\n            raise ValueError(\"Empty\")\n        \n        token = tokens[0]\n        remaining = tokens[1:]\n        \n        if token in OPERATORS:\n            arity = OPERATORS[token]\n            children = []\n            for _ in range(arity):\n                child, remaining = self._build_tree(remaining)\n                children.append(child)\n            return MultiVarNode(token, children), remaining\n        elif token in self.variables or token in CONSTANTS:\n            return MultiVarNode(token), remaining\n        else:\n            try:\n                float(token)\n                return MultiVarNode(token), remaining\n            except:\n                raise ValueError(f\"Unknown token: {token}\")\n    \n    def evaluate(self, x_values_dict, constants=None):\n        \"\"\"\n        Evaluate with multiple variables.\n        x_values_dict: {'x0': array, 'x1': array, ...}\n        \"\"\"\n        if not self.is_valid:\n            n = len(list(x_values_dict.values())[0]) if x_values_dict else 1\n            return np.full(n, np.nan)\n        return self._eval_node(self.root, x_values_dict, constants or {}, [])\n    \n    def _eval_node(self, node, x_dict, constants, path):\n        val = node.value\n        \n        # Check if it's a variable\n        if val in x_dict:\n            return x_dict[val].astype(np.float64)\n        if val == 'pi':\n            n = len(list(x_dict.values())[0])\n            return np.full(n, np.pi)\n        if val == 'e':\n            n = len(list(x_dict.values())[0])\n            return np.full(n, np.e)\n        if val == 'C':\n            n = len(list(x_dict.values())[0])\n            c_val = constants.get(tuple(path), 1.0)\n            return np.full(n, c_val)\n        \n        try:\n            n = len(list(x_dict.values())[0])\n            return np.full(n, float(val))\n        except:\n            pass\n        \n        # Operators\n        args = []\n        for i, c in enumerate(node.children):\n            args.append(self._eval_node(c, x_dict, constants, path + [i]))\n        \n        with np.errstate(all='ignore'):\n            if val == '+': return args[0] + args[1]\n            if val == '-': return args[0] - args[1]\n            if val == '*': return args[0] * args[1]\n            if val == '/': return np.divide(args[0], args[1], out=np.zeros_like(args[0]), where=args[1]!=0)\n            if val == 'pow': return np.power(np.abs(args[0]) + 1e-10, np.clip(args[1], -10, 10))\n            if val == 'mod': return np.mod(args[0], args[1] + 1e-10)\n            if val == 'sin': return np.sin(args[0])\n            if val == 'cos': return np.cos(args[0])\n            if val == 'tan': return np.tan(args[0])\n            if val == 'exp': return np.exp(np.clip(args[0], -100, 100))\n            if val == 'log': return np.log(np.abs(args[0]) + 1e-10)\n            if val == 'sqrt': return np.sqrt(np.abs(args[0]))\n            if val == 'abs': return np.abs(args[0])\n            if val == 'floor': return np.floor(args[0])\n            if val == 'ceil': return np.ceil(args[0])\n            if val == 'gamma': \n                clipped = np.clip(args[0], 0.1, 50)\n                return scipy_gamma(clipped)\n            if val == 'neg': return -args[0]\n        \n        return np.zeros_like(args[0]) if args else np.zeros(1)\n    \n    def get_infix(self):\n        if not self.is_valid:\n            return \"Invalid\"\n        return self.root.to_infix()\n\n\nclass MultiVarDataGenerator:\n    \"\"\"Generate synthetic data for multi-variable regression.\"\"\"\n    \n    def __init__(self, num_variables=2, max_depth=4):\n        self.num_variables = num_variables\n        self.max_depth = max_depth\n        self.vocab, self.variables, self.token_to_id, _ = build_vocabulary(num_variables)\n        self.operators = list(OPERATORS.keys())\n        self.terminals = self.variables + CONSTANTS\n    \n    def generate_random_tree(self, max_depth, current_depth=0):\n        import random\n        \n        if current_depth >= max_depth:\n            return [random.choice(self.terminals)]\n        \n        if random.random() < 0.7:\n            op = random.choice(self.operators)\n            arity = OPERATORS[op]\n            tokens = [op]\n            for _ in range(arity):\n                tokens.extend(self.generate_random_tree(max_depth, current_depth + 1))\n            return tokens\n        else:\n            return [random.choice(self.terminals)]\n    \n    def generate_batch(self, batch_size, points_per_dim=10, x_range=(-5, 5)):\n        \"\"\"Generate batch with multi-variable data.\"\"\"\n        data = []\n        \n        while len(data) < batch_size:\n            tokens = self.generate_random_tree(self.max_depth)\n            tree = MultiVarExpressionTree(tokens, self.num_variables)\n            \n            if not tree.is_valid:\n                continue\n            \n            # Generate input points\n            x_dict = {}\n            for i in range(self.num_variables):\n                x_dict[f'x{i}'] = np.random.uniform(x_range[0], x_range[1], points_per_dim)\n            \n            y_values = tree.evaluate(x_dict)\n            \n            if np.any(np.isnan(y_values)) or np.any(np.isinf(y_values)):\n                continue\n            if np.max(np.abs(y_values)) > 1e6:\n                continue\n            \n            data.append({\n                'tokens': tokens,\n                'infix': tree.get_infix(),\n                'x': x_dict,\n                'y': y_values\n            })\n        \n        return data\n\n\n# Quick test\nif __name__ == \"__main__\":\n    # Build vocabulary for 3 variables\n    vocab, variables, t2i, i2t = build_vocabulary(3)\n    print(f\"Variables: {variables}\")\n    print(f\"Vocabulary size: {len(vocab)}\")\n    \n    # Test expression: x0 + x1 * x2\n    tokens = ['+', 'x0', '*', 'x1', 'x2']\n    tree = MultiVarExpressionTree(tokens, num_variables=3)\n    print(f\"Formula: {tree.get_infix()}\")\n    \n    # Evaluate\n    x_dict = {\n        'x0': np.array([1, 2, 3]),\n        'x1': np.array([2, 3, 4]),\n        'x2': np.array([3, 4, 5])\n    }\n    result = tree.evaluate(x_dict)\n    expected = x_dict['x0'] + x_dict['x1'] * x_dict['x2']\n    print(f\"Result: {result}\")\n    print(f\"Expected: {expected}\")\n    print(f\"Match: {np.allclose(result, expected)}\")\n    \n    # Test data generator\n    gen = MultiVarDataGenerator(num_variables=2, max_depth=3)\n    batch = gen.generate_batch(3)\n    for item in batch:\n        print(f\"\\nFormula: {item['infix']}\")\n        print(f\"Y sample: {item['y'][:3]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/optimize_constants.py\n",
        "\"\"\"\nConstant Optimization Module for AlphaSymbolic.\nUses scipy.optimize to find optimal values for 'C' placeholders.\n\"\"\"\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom core.grammar import ExpressionTree\n\ndef optimize_constants(tree, x_data, y_data, method='L-BFGS-B'):\n    \"\"\"\n    Given an ExpressionTree with 'C' placeholders, find optimal constant values.\n    \n    Args:\n        tree: ExpressionTree object\n        x_data: numpy array of x values\n        y_data: numpy array of target y values\n        method: optimization method ('L-BFGS-B', 'SLSQP', 'Nelder-Mead')\n        \n    Returns:\n        dict: mapping of path tuples to optimized constant values\n        float: final RMSE\n    \"\"\"\n    if not tree.is_valid:\n        return {}, float('inf')\n    \n    # Get positions of all constants\n    positions = tree.root.get_constant_positions()\n    n_constants = len(positions)\n    \n    if n_constants == 0:\n        # No constants to optimize, just evaluate\n        y_pred = tree.evaluate(x_data)\n        mse = np.mean((y_pred - y_data)**2)\n        return {}, np.sqrt(mse)\n    \n    def objective(params):\n        \"\"\"Objective function: RMSE given constant values.\"\"\"\n        # Build constants dict\n        constants = {tuple(pos): params[i] for i, pos in enumerate(positions)}\n        \n        # Evaluate\n        y_pred = tree.evaluate(x_data, constants=constants)\n        \n        # Handle invalid predictions\n        if np.any(np.isnan(y_pred)) or np.any(np.isinf(y_pred)):\n            return 1e10\n        \n        if not np.all(np.isfinite(y_pred)):\n            return 1e9\n        \n        # Clip huge values to prevent overflow in MSE\n        y_pred = np.clip(y_pred, -1e9, 1e9)\n        \n        mse = np.mean((y_pred - y_data)**2)\n        return mse\n    \n    # Initial guess: all 1s\n    x0 = np.ones(n_constants)\n    \n    # Bounds: reasonable range for constants\n    bounds = [(-1000, 1000)] * n_constants\n    \n    try:\n        result = minimize(\n            objective,\n            x0,\n            method=method,\n            bounds=bounds if method in ['L-BFGS-B', 'SLSQP'] else None,\n            options={'maxiter': 1000, 'disp': False}\n        )\n        \n        # Build final constants dict\n        optimized_constants = {tuple(pos): result.x[i] for i, pos in enumerate(positions)}\n        final_rmse = np.sqrt(result.fun) if result.fun > 0 else 0.0\n        \n        return optimized_constants, final_rmse\n        \n    except Exception as e:\n        return {}, float('inf')\n\ndef substitute_constants(infix_str, constants_dict, positions):\n    \"\"\"\n    Replace 'C' in the infix string with optimized values.\n    Simple approach: replace each C with optimized value.\n    \"\"\"\n    # For proper substitution, we'd need to track positions properly\n    # This is a simplified version that replaces all C with the first constant\n    result = infix_str\n    for i, pos in enumerate(positions):\n        if tuple(pos) in constants_dict:\n            val = constants_dict[tuple(pos)]\n            # Format nicely\n            if abs(val - round(val)) < 1e-6:\n                val_str = str(int(round(val)))\n            else:\n                val_str = f\"{val:.4f}\"\n            # Replace first occurrence of C\n            result = result.replace('C', val_str, 1)\n    return result\n\n\n# Quick test\nif __name__ == \"__main__\":\n    # Test: C * x + C should be optimized to fit y = 2*x + 3\n    x_test = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n    y_test = 2 * x_test + 3  # y = 2x + 3\n    \n    tokens = ['+', '*', 'C', 'x', 'C']  # C*x + C\n    tree = ExpressionTree(tokens)\n    \n    print(f\"Formula structure: {tree.get_infix()}\")\n    print(f\"Target: y = 2x + 3\")\n    \n    constants, rmse = optimize_constants(tree, x_test, y_test)\n    print(f\"Optimized constants: {constants}\")\n    print(f\"Final RMSE: {rmse:.6f}\")\n    \n    # Verify\n    y_pred = tree.evaluate(x_test, constants=constants)\n    print(f\"Predictions: {y_pred}\")\n    print(f\"Targets: {y_test}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/simplify.py\n",
        "\"\"\"\nAlgebraic Simplification Module for AlphaSymbolic.\nUses SymPy for symbolic math simplification.\n\"\"\"\nimport sympy as sp\nfrom core.grammar import Node, ExpressionTree, OPERATORS\n\n# SymPy symbol for x\nx_sym = sp.Symbol('x')\n\ndef tree_to_sympy(node):\n    \"\"\"Convert an ExpressionTree Node to a SymPy expression.\"\"\"\n    if node is None:\n        return sp.Integer(0)\n    \n    val = node.value\n    \n    # Terminals\n    if val == 'x':\n        return x_sym\n    if val == 'pi':\n        return sp.pi\n    if val == 'e':\n        return sp.E\n    if val == 'C':\n        # Keep C as symbol for now\n        return sp.Symbol('C')\n    \n    # Try numeric\n    try:\n        return sp.Float(float(val))\n    except:\n        pass\n    \n    # Operators\n    args = [tree_to_sympy(c) for c in node.children]\n    \n    if val == '+': return args[0] + args[1]\n    if val == '-': return args[0] - args[1]\n    if val == '*': return args[0] * args[1]\n    if val == '/': return args[0] / args[1]\n    if val == 'pow': return sp.Pow(args[0], args[1])\n    if val == 'mod': return sp.Mod(args[0], args[1])\n    if val == 'sin': return sp.sin(args[0])\n    if val == 'cos': return sp.cos(args[0])\n    if val == 'tan': return sp.tan(args[0])\n    if val == 'exp': return sp.exp(args[0])\n    if val == 'log': return sp.log(args[0])\n    if val == 'sqrt': return sp.sqrt(args[0])\n    if val == 'abs': return sp.Abs(args[0])\n    if val == 'floor': return sp.floor(args[0])\n    if val == 'ceil': return sp.ceiling(args[0])\n    if val == 'gamma': return sp.gamma(args[0])\n    if val == 'neg': return -args[0]\n    \n    return sp.Integer(0)\n\ndef sympy_to_infix(expr):\n    \"\"\"Convert SymPy expression back to a readable string.\"\"\"\n    return str(expr)\n\ndef simplify_tree(tree):\n    \"\"\"\n    Takes an ExpressionTree and returns a simplified infix string.\n    \"\"\"\n    if not tree.is_valid:\n        return \"Invalid\"\n    \n    try:\n        sympy_expr = tree_to_sympy(tree.root)\n        simplified = sp.simplify(sympy_expr)\n        return str(simplified)\n    except Exception as e:\n        # If simplification fails, return original\n        return tree.get_infix()\n\ndef simplify_infix(infix_str):\n    \"\"\"\n    Takes an infix string and returns a simplified version.\n    \"\"\"\n    try:\n        expr = sp.sympify(infix_str)\n        simplified = sp.simplify(expr)\n        return str(simplified)\n    except:\n        return infix_str\n\n# Quick test\nif __name__ == \"__main__\":\n    from core.grammar import ExpressionTree\n    \n    # Test: x + 0 should simplify to x\n    tokens = ['+', 'x', '0']\n    tree = ExpressionTree(tokens)\n    print(f\"Original: {tree.get_infix()}\")\n    print(f\"Simplified: {simplify_tree(tree)}\")\n    \n    # Test: x * 1 should simplify to x\n    tokens2 = ['*', 'x', '1']\n    tree2 = ExpressionTree(tokens2)\n    print(f\"Original: {tree2.get_infix()}\")\n    print(f\"Simplified: {simplify_tree(tree2)}\")\n    \n    # Test: x - x should simplify to 0\n    tokens3 = ['-', 'x', 'x']\n    tree3 = ExpressionTree(tokens3)\n    print(f\"Original: {tree3.get_infix()}\")\n    print(f\"Simplified: {simplify_tree(tree3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"\nAlphaSymbolic - Gradio Web Interface\nWith GPU/CPU toggle and search method selection.\n\"\"\"\nimport gradio as gr\nimport torch\n\nfrom ui.app_core import load_model, get_device, get_device_info, set_device\nfrom ui.app_training import train_basic, train_curriculum, train_self_play\nfrom ui.app_search import solve_formula, generate_example\nfrom ui.app_benchmark import get_benchmark_tab\n\n\ndef toggle_device(use_gpu):\n    \"\"\"Toggle between GPU and CPU.\"\"\"\n    device_info = set_device(use_gpu)\n    color = \"#4ade80\" if \"CUDA\" in device_info else \"#fbbf24\" if \"MPS\" in device_info else \"#888\"\n    return f'<div style=\"padding: 10px; background: #0f0f23; border-radius: 8px; border-left: 3px solid {color};\"><span style=\"color: {color}; font-weight: bold;\">{device_info}</span></div>'\n\n\ndef create_app():\n    \"\"\"Create the Gradio app.\"\"\"\n    \n    with gr.Blocks(title=\"AlphaSymbolic\") as demo:\n        \n        # Header\n        device_info = get_device_info()\n        device_color = \"#4ade80\" if \"CUDA\" in device_info else \"#fbbf24\" if \"MPS\" in device_info else \"#888\"\n        \n        gr.HTML(f\"\"\"\n        <div style=\"text-align: center; padding: 20px; background: linear-gradient(90deg, #00d4ff22, transparent, #ff6b6b22); border-radius: 15px; margin-bottom: 20px;\">\n            <h1 style=\"color: #00d4ff; font-size: 42px; margin: 0;\">AlphaSymbolic</h1>\n            <p style=\"color: #888; font-size: 18px; margin: 5px 0;\">Deep Reinforcement Learning para Regresion Simbolica</p>\n        </div>\n        \"\"\")\n        \n        # System Controls\n        with gr.Row():\n            with gr.Column(scale=1):\n                model_selector = gr.Dropdown(choices=[\"lite\", \"pro\"], value=\"lite\", label=\"Arquitectura (Cerebro)\", interactive=True)\n            with gr.Column(scale=3):\n                model_status = gr.Textbox(label=\"Estado del Modelo\", value=\"Lite (Laptop Optimized) - Vocabulario Extendido\", interactive=False)\n        \n        def on_model_change(preset):\n            status, _ = load_model(preset_name=preset)\n            return status\n\n        model_selector.change(on_model_change, model_selector, model_status)\n        \n        with gr.Tabs():\n            # TAB 1: Search\n            with gr.Tab(\"Buscar Formula\"):\n                with gr.Row():\n                    with gr.Column(scale=1):\n                        gr.HTML('<h3 style=\"color: #00d4ff;\">Datos de Entrada</h3>')\n                        x_input = gr.Textbox(label=\"Valores X\", placeholder=\"1, 2, 3, 4, 5...\", lines=2)\n                        y_input = gr.Textbox(label=\"Valores Y\", placeholder=\"5, 7, 9, 11, 13...\", lines=2)\n                        \n                        with gr.Row():\n                            search_method = gr.Radio(\n                                choices=[\"Beam Search\", \"MCTS\"],\n                                value=\"Beam Search\",\n                                label=\"Metodo de Busqueda\"\n                            )\n                        \n                        beam_slider = gr.Slider(5, 50, value=15, step=5, label=\"Beam Width / Simulaciones\")\n                        \n                        solve_btn = gr.Button(\"Buscar Formula\", variant=\"primary\", size=\"lg\")\n                        \n                        with gr.Row():\n                            gr.Button(\"Lineal\", size=\"sm\").click(lambda: generate_example(\"lineal\"), outputs=[x_input, y_input])\n                            gr.Button(\"Cuadratico\", size=\"sm\").click(lambda: generate_example(\"cuadratico\"), outputs=[x_input, y_input])\n                            gr.Button(\"Seno\", size=\"sm\").click(lambda: generate_example(\"trig\"), outputs=[x_input, y_input])\n                            gr.Button(\"Exponencial\", size=\"sm\").click(lambda: generate_example(\"exp\"), outputs=[x_input, y_input])\n                    \n                    with gr.Column(scale=2):\n                        result_html = gr.HTML(label=\"Resultado\")\n                        plot_output = gr.Plot(label=\"Visualizacion\")\n                \n                with gr.Row():\n                    pred_html = gr.HTML(label=\"Predicciones\")\n                    alt_html = gr.HTML(label=\"Alternativas\")\n                \n                raw_formula = gr.Textbox(visible=False)\n                \n                solve_btn.click(solve_formula, [x_input, y_input, beam_slider, search_method], \n                               [result_html, plot_output, pred_html, alt_html, raw_formula])\n            \n            # TAB 2: Training\n            with gr.Tab(\"Entrenar Modelo\"):\n                with gr.Row():\n                    gr.HTML(\"\"\"\n                    <div style=\"background: #16213e; padding: 20px; border-radius: 10px; flex: 1;\">\n                        <h3 style=\"color: #ffd93d; margin: 0;\">Centro de Entrenamiento</h3>\n                    </div>\n                    \"\"\")\n                    with gr.Column():\n                        use_gpu = gr.Checkbox(label=\"Usar GPU\", value=torch.cuda.is_available())\n                        device_display = gr.HTML(value=f'<div style=\"padding: 10px; background: #0f0f23; border-radius: 8px; border-left: 3px solid {device_color};\"><span style=\"color: {device_color}; font-weight: bold;\">{device_info}</span></div>')\n                        use_gpu.change(toggle_device, [use_gpu], [device_display])\n                    with gr.Column():\n                        delete_model_btn = gr.Button(\"\ud83d\uddd1\ufe0f Borrar Modelo\", variant=\"secondary\", size=\"sm\")\n                        delete_status = gr.HTML()\n                        \n                        def delete_model_action():\n                            import os\n                            if os.path.exists(\"alpha_symbolic_model.pth\"):\n                                os.remove(\"alpha_symbolic_model.pth\")\n                                return '<div style=\"color: #ff6b6b; padding: 5px;\">\u2705 Modelo eliminado. Reinicia la app para usar pesos nuevos.</div>'\n                            return '<div style=\"color: #888; padding: 5px;\">No hay modelo guardado.</div>'\n                        \n                        delete_model_btn.click(delete_model_action, outputs=[delete_status])\n                \n                with gr.Tabs():\n                    # Basic\n                    with gr.Tab(\"Basico\"):\n                        gr.HTML('<p style=\"color: #888;\">Entrenamiento rapido con datos sinteticos</p>')\n                        with gr.Row():\n                            with gr.Column():\n                                epochs_basic = gr.Slider(10, 500, value=100, step=10, label=\"Epocas\")\n                                batch_basic = gr.Slider(16, 128, value=32, step=16, label=\"Batch Size\")\n                                points_basic = gr.Slider(10, 100, value=20, step=10, label=\"Puntos por Formula\")\n                                train_basic_btn = gr.Button(\"Entrenar Basico\", variant=\"primary\")\n                            with gr.Column():\n                                result_basic = gr.HTML()\n                                plot_basic = gr.Plot()\n                        train_basic_btn.click(train_basic, [epochs_basic, batch_basic, points_basic], [result_basic, plot_basic])\n                    \n                    # Curriculum\n                    with gr.Tab(\"Curriculum\"):\n                        gr.HTML('''\n                        <div style=\"background: #0f0f23; padding: 15px; border-radius: 8px; margin-bottom: 15px;\">\n                            <p style=\"color: #00d4ff; margin: 0;\"><strong>Curriculum Learning</strong></p>\n                            <p style=\"color: #888; margin: 5px 0 0 0;\">Empieza con formulas simples y aumenta la dificultad.</p>\n                        </div>\n                        ''')\n                        with gr.Row():\n                            with gr.Column():\n                                epochs_curriculum = gr.Slider(50, 2000, value=200, step=50, label=\"Epocas\")\n                                batch_curriculum = gr.Slider(16, 128, value=64, step=16, label=\"Batch Size\")\n                                points_curriculum = gr.Slider(10, 100, value=20, step=10, label=\"Puntos por Formula\")\n                                train_curriculum_btn = gr.Button(\"Entrenar Curriculum\", variant=\"primary\")\n                            with gr.Column():\n                                result_curriculum = gr.HTML()\n                                plot_curriculum = gr.Plot()\n                        train_curriculum_btn.click(train_curriculum, [epochs_curriculum, batch_curriculum, points_curriculum], [result_curriculum, plot_curriculum])\n                    \n                    # Self-Play\n                    with gr.Tab(\"Self-Play\"):\n                        gr.HTML('''\n                        <div style=\"background: #0f0f23; padding: 15px; border-radius: 8px; margin-bottom: 15px; border-left: 3px solid #ff6b6b;\">\n                            <p style=\"color: #ff6b6b; margin: 0;\"><strong>AlphaZero Self-Play</strong></p>\n                            <p style=\"color: #888; margin: 5px 0 0 0;\">El modelo resuelve problemas y aprende de sus exitos.</p>\n                        </div>\n                        ''')\n                        with gr.Row():\n                            with gr.Column():\n                                iterations_sp = gr.Slider(10, 1000, value=100, step=10, label=\"Iteraciones\")\n                                problems_sp = gr.Slider(5, 50, value=10, step=5, label=\"Problemas/Iter\")\n                                points_sp = gr.Slider(10, 100, value=20, step=10, label=\"Puntos por Formula\")\n                                train_sp_btn = gr.Button(\"Iniciar Self-Play\", variant=\"primary\")\n                            with gr.Column():\n                                result_sp = gr.HTML()\n                                plot_sp = gr.Plot()\n                        train_sp_btn.click(train_self_play, [iterations_sp, problems_sp, points_sp], [result_sp, plot_sp])\n            \n            # TAB 4: Benchmark\n            get_benchmark_tab()\n\n            # TAB 5: Info\n            with gr.Tab(\"Informacion\"):\n                device_info_current = get_device_info()\n                device_color_current = \"#4ade80\" if \"CUDA\" in device_info_current else \"#fbbf24\" if \"MPS\" in device_info_current else \"#888\"\n                \n                gr.HTML(f\"\"\"\n                <div style=\"background: #1a1a2e; padding: 30px; border-radius: 15px;\">\n                    <h2 style=\"color: #00d4ff;\">Que es AlphaSymbolic?</h2>\n                    <p style=\"color: #ccc; line-height: 1.8;\">\n                        Sistema de <strong style=\"color: #ff6b6b;\">regresion simbolica</strong> \n                        basado en <strong style=\"color: #00d4ff;\">Deep Learning</strong> y \n                        <strong style=\"color: #ffd93d;\">Monte Carlo Tree Search</strong>.\n                    </p>\n                    \n                    <h3 style=\"color: #00d4ff; margin-top: 30px;\">Dispositivo Actual</h3>\n                    <p style=\"color: {device_color_current}; font-size: 20px;\">{device_info_current}</p>\n                    \n                    <h3 style=\"color: #00d4ff; margin-top: 30px;\">Metodos de Busqueda</h3>\n                    <ul style=\"color: #ccc;\">\n                        <li><strong>Beam Search:</strong> Explora multiples candidatos en paralelo (rapido)</li>\n                        <li><strong>MCTS:</strong> Monte Carlo Tree Search (mas preciso, lento)</li>\n                    </ul>\n                    \n                    <h3 style=\"color: #00d4ff; margin-top: 30px;\">Operadores</h3>\n                    <div style=\"display: flex; flex-wrap: wrap; gap: 10px; margin: 15px 0;\">\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">+</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">-</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">*</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">/</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ff6b6b;\">sin</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ff6b6b;\">cos</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ffd93d;\">exp</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ffd93d;\">log</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #4ade80;\">pow</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #4ade80;\">sqrt</span>\n                    </div>\n                </div>\n                \"\"\")\n        \n        gr.HTML(\"\"\"\n        <div style=\"text-align: center; padding: 20px; color: #666; margin-top: 30px;\">\n            <p>Powered by PyTorch - SymPy - Scipy - Gradio</p>\n        </div>\n        \"\"\")\n    \n    return demo\n\n\nif __name__ == \"__main__\":\n    print(\"Iniciando AlphaSymbolic...\")\n    status, device_info = load_model()\n    print(f\"   {status} | {device_info}\")\n    print(\"Abriendo navegador...\")\n    \n    app = create_app()\n    app.launch(share=True, inbrowser=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run App\n",
        "print('Starting AlphaSymbolic on Colab GPU...')\n",
        "!python app.py"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}