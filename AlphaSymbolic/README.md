# ğŸ§  AlphaSymbolic

> **RegresiÃ³n SimbÃ³lica con Deep Reinforcement Learning (AlphaZero-Style)**

[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](../LICENSE)

Sistema de descubrimiento automÃ¡tico de fÃ³rmulas matemÃ¡ticas usando redes neuronales Transformer y Monte Carlo Tree Search, inspirado en AlphaTensor de DeepMind.

---

## ğŸš€ Inicio RÃ¡pido

```bash
# 1. Instalar dependencias
cd AlphaSymbolic
pip install -r requirements.txt

# 2. Entrenar el modelo (opcional, ya hay uno pre-entrenado)
python train_enhanced.py --epochs 500

# 3. Resolver un problema
python search_pro.py
```

---

## ğŸ“– GuÃ­a de Uso

### ğŸ” Resolver un Problema Simple

```python
from search_pro import solve_pro
import numpy as np

# Tus datos
x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
y = np.array([5, 7, 9, 11, 13, 15, 17, 19, 21, 23])  # y = 2x + 3

# Buscar fÃ³rmula
result, pareto = solve_pro(x, y)
print(result['final_formula'])  # DeberÃ­a encontrar "2*x + 3"
```

### ğŸ“ Entrenar el Modelo

```bash
# Entrenamiento bÃ¡sico (rÃ¡pido, ~5 min)
python train.py

# Entrenamiento avanzado con curriculum learning (~30 min)
python train_enhanced.py --epochs 1000 --batch 64

# Self-Play AlphaZero (mejora continua, ~horas)
python self_play.py --iterations 100 --problems 20
```

### ğŸ“Š Modos de BÃºsqueda

| Modo | Comando | Velocidad | PrecisiÃ³n |
|------|---------|-----------|-----------|
| **Beam Search** | `--method beam` | âš¡ RÃ¡pido | â­â­â­ |
| **MCTS** | `--method mcts` | ğŸ¢ Lento | â­â­â­â­ |

```bash
# Beam Search (recomendado)
python search_pro.py --method beam --beam-width 20

# MCTS (mÃ¡s exhaustivo)
python search_pro.py --method mcts --mcts-sims 500
```

---

## ğŸ”§ Operadores Soportados

| Tipo | Operadores |
|------|------------|
| **AritmÃ©ticos** | `+`, `-`, `*`, `/`, `pow`, `mod` |
| **TrigonomÃ©tricos** | `sin`, `cos`, `tan` |
| **Exponenciales** | `exp`, `log`, `sqrt` |
| **Especiales** | `abs`, `floor`, `ceil`, `gamma` |
| **Constantes** | `pi`, `e`, `C` (optimizable) |

---

## ğŸ“‚ Estructura del Proyecto

```
AlphaSymbolic/
â”œâ”€â”€ ğŸ§  Core (NÃºcleo)
â”‚   â”œâ”€â”€ grammar.py          # GramÃ¡tica y Ã¡rboles de expresiÃ³n
â”‚   â”œâ”€â”€ model.py            # Red neuronal Transformer
â”‚   â”œâ”€â”€ mcts.py             # Monte Carlo Tree Search
â”‚   â””â”€â”€ beam_search.py      # BÃºsqueda por haz
â”‚
â”œâ”€â”€ ğŸ“ˆ OptimizaciÃ³n
â”‚   â”œâ”€â”€ optimize_constants.py  # OptimizaciÃ³n numÃ©rica (scipy)
â”‚   â”œâ”€â”€ simplify.py            # SimplificaciÃ³n algebraica (SymPy)
â”‚   â””â”€â”€ pareto.py              # Frente de Pareto
â”‚
â”œâ”€â”€ ğŸ“ Entrenamiento
â”‚   â”œâ”€â”€ train.py              # Entrenamiento bÃ¡sico
â”‚   â”œâ”€â”€ train_enhanced.py     # Curriculum + Value Loss
â”‚   â”œâ”€â”€ self_play.py          # AlphaZero Loop
â”‚   â””â”€â”€ synthetic_data.py     # Generador de datos
â”‚
â”œâ”€â”€ ğŸ”§ Avanzado
â”‚   â”œâ”€â”€ multivar.py           # Multi-variable f(x1, x2, ...)
â”‚   â”œâ”€â”€ gpu_eval.py           # EvaluaciÃ³n batch GPU
â”‚   â”œâ”€â”€ cpp_binding.py        # IntegraciÃ³n C++
â”‚   â”œâ”€â”€ pattern_memory.py     # Memoria de patrones
â”‚   â””â”€â”€ detect_pattern.py     # DetecciÃ³n de patrones
â”‚
â”œâ”€â”€ ğŸš€ EjecuciÃ³n
â”‚   â”œâ”€â”€ search.py             # BÃºsqueda simple
â”‚   â””â”€â”€ search_pro.py         # Pipeline completo
â”‚
â””â”€â”€ ğŸ“‹ ConfiguraciÃ³n
    â””â”€â”€ requirements.txt
```

---

## ğŸ”¬ Pipeline de BÃºsqueda

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ALPHASIMBOLIC PIPELINE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. DETECCIÃ“N DE PATRÃ“N                                     â”‚
â”‚     â””â”€ Analiza Y: Â¿lineal? Â¿cuadrÃ¡tico? Â¿periÃ³dico?        â”‚
â”‚                                                             â”‚
â”‚  2. BÃšSQUEDA NEURONAL (Beam/MCTS)                          â”‚
â”‚     â””â”€ Transformer genera estructuras candidatas           â”‚
â”‚                                                             â”‚
â”‚  3. OPTIMIZACIÃ“N DE CONSTANTES                              â”‚
â”‚     â””â”€ scipy minimiza RMSE para cada C                     â”‚
â”‚                                                             â”‚
â”‚  4. FRENTE DE PARETO                                        â”‚
â”‚     â””â”€ Selecciona mejores (precisiÃ³n vs simplicidad)       â”‚
â”‚                                                             â”‚
â”‚  5. SIMPLIFICACIÃ“N                                          â”‚
â”‚     â””â”€ SymPy limpia fÃ³rmula final                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Ejemplos

### Ejemplo 1: Encontrar una fÃ³rmula lineal

```python
import numpy as np
from search_pro import solve_pro

x = np.linspace(0, 10, 20)
y = 3 * x - 5  # FÃ³rmula objetivo

result, _ = solve_pro(x, y)
# Output: "3*x - 5" o equivalente
```

### Ejemplo 2: FÃ³rmula cuadrÃ¡tica

```python
x = np.linspace(-5, 5, 30)
y = x**2 + 2*x + 1  # (x+1)^2

result, _ = solve_pro(x, y, beam_width=20)
# Output: "(x + 1)^2" o "x^2 + 2*x + 1"
```

### Ejemplo 3: Multi-variable

```python
from multivar import MultiVarExpressionTree, MultiVarDataGenerator

# Crear generador para 2 variables
gen = MultiVarDataGenerator(num_variables=2)

# Generar datos
x_dict = {'x0': np.array([1,2,3]), 'x1': np.array([4,5,6])}
# Buscar f(x0, x1) tal que y = x0 + x1*2
```

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Aumentar PrecisiÃ³n
```bash
python search_pro.py --beam-width 30 --method beam
```

### Entrenar MÃ¡s Tiempo
```bash
python train_enhanced.py --epochs 5000
python self_play.py --iterations 500
```

### Usar GPU
El sistema detecta automÃ¡ticamente CUDA:
```python
import torch
print(torch.cuda.is_available())  # True si GPU disponible
```

---

## ğŸ“ˆ Rendimiento

| ConfiguraciÃ³n | Tiempo | RMSE TÃ­pico |
|--------------|--------|-------------|
| Beam (width=10) | ~2s | ~1e-2 |
| Beam (width=30) | ~10s | ~1e-4 |
| MCTS (500 sims) | ~30s | ~1e-5 |
| MCTS + Self-Play | ~horas | ~1e-8 |

---

## ğŸ¤ ComparaciÃ³n con el Algoritmo GenÃ©tico Original

| CaracterÃ­stica | GA Original | AlphaSymbolic |
|---------------|-------------|---------------|
| MÃ©todo | MutaciÃ³n/Cruce | Deep RL + MCTS |
| Aprendizaje | No (heurÃ­stico) | SÃ­ (red neuronal) |
| Velocidad | RÃ¡pido | MÃ¡s lento pero smarter |
| Escalabilidad | Limitada | GPU paralelo |
| Multi-variable | No | âœ… SÃ­ |

---

## ğŸ“„ Licencia

Apache 2.0 - Ver [LICENSE](../LICENSE)

---

<div align="center">

**Desarrollado con ğŸ§  por AlphaSymbolic Team**

</div>
