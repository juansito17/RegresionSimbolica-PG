{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install gradio torch torchvision torchaudio scipy matplotlib sympy\n",
        "\n",
        "# Create directories\n",
        "!mkdir -p core data search ui utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/grammar.py\n",
        "import numpy as np\nfrom scipy.special import gamma as scipy_gamma\nimport math\n\n# Supported operators and their arity (number of arguments)\nOPERATORS = {\n    # Binary\n    '+': 2,\n    '-': 2,\n    '*': 2,\n    '/': 2,\n    'pow': 2,\n    'mod': 2,\n    # Unary\n    'sin': 1,\n    'cos': 1,\n    'tan': 1,\n    'exp': 1,\n    'log': 1,\n    'sqrt': 1,\n    'abs': 1,\n    'floor': 1,\n    'ceil': 1,\n    'gamma': 1,  # Gamma function (for combinatorics)\n    'neg': 1,    # Negation\n    'sign': 1,\n    'max': 2,\n    'min': 2,\n}\n\n# Terminal tokens\nVARIABLES = ['x']\n# 'C' is a placeholder for learnable constants\nCONSTANTS = ['C', '0', '1', '2', '3', '5', '10', 'pi', 'e']\n\n# Full Vocabulary\nVOCABULARY = list(OPERATORS.keys()) + VARIABLES + CONSTANTS\nTOKEN_TO_ID = {token: i for i, token in enumerate(VOCABULARY)}\nID_TO_TOKEN = {i: token for token, i in TOKEN_TO_ID.items()}\n\n# Special token for start of sequence\nSOS_TOKEN = '<SOS>'\nEOS_TOKEN = '<EOS>'\nPAD_TOKEN = '<PAD>'\n\nclass Node:\n    def __init__(self, value, children=None):\n        self.value = value\n        self.children = children if children else []\n\n    def __repr__(self):\n        if not self.children:\n            return str(self.value)\n        return f\"({self.value} \" + \" \".join([str(c) for c in self.children]) + \")\"\n    \n    def to_infix(self):\n        if not self.children:\n            return str(self.value)\n        \n        op = self.value\n        if len(self.children) == 1:\n            return f\"{op}({self.children[0].to_infix()})\"\n        elif len(self.children) == 2:\n            if op == 'pow':\n                return f\"({self.children[0].to_infix()} ^ {self.children[1].to_infix()})\"\n            elif op == 'mod':\n                return f\"({self.children[0].to_infix()} % {self.children[1].to_infix()})\"\n            return f\"({self.children[0].to_infix()} {op} {self.children[1].to_infix()})\"\n        return str(self.value)\n    \n    def count_constants(self):\n        \"\"\"Count the number of 'C' placeholders in the tree.\"\"\"\n        count = 1 if self.value == 'C' else 0\n        for child in self.children:\n            count += child.count_constants()\n        return count\n    \n    def get_constant_positions(self, path=None):\n        \"\"\"Returns a list of paths to all 'C' nodes for optimization.\"\"\"\n        if path is None:\n            path = []\n        positions = []\n        if self.value == 'C':\n            positions.append(path.copy())\n        for i, child in enumerate(self.children):\n            positions.extend(child.get_constant_positions(path + [i]))\n        return positions\n\n\nclass ExpressionTree:\n    def __init__(self, token_list):\n        \"\"\"\n        Parses a list of tokens in Pre-order traversal (Prefix notation)\n        Example: ['+', 'x', 'sin', 'x'] -> x + sin(x)\n        \"\"\"\n        self.tokens = token_list\n        try:\n            self.root, remaining = self._build_tree(token_list)\n            if remaining:\n                raise ValueError(\"Tokens remained after building tree\")\n            self.is_valid = True\n        except Exception:\n            self.root = None\n            self.is_valid = False\n\n    def _build_tree(self, tokens):\n        if not tokens:\n            raise ValueError(\"Empty token list\")\n        \n        token = tokens[0]\n        remaining = tokens[1:]\n        \n        if token in OPERATORS:\n            arity = OPERATORS[token]\n            children = []\n            for _ in range(arity):\n                child, remaining = self._build_tree(remaining)\n                children.append(child)\n            return Node(token, children), remaining\n        elif token in VARIABLES or token in CONSTANTS:\n            return Node(token), remaining\n        else:\n            # Try to parse as float literal\n            try:\n                float(token)\n                return Node(token), remaining\n            except:\n                raise ValueError(f\"Unknown token: {token}\")\n\n    def evaluate(self, x_values, constants=None):\n        \"\"\"\n        Evaluates the expression tree for a given array of x values.\n        constants: optional dict mapping path tuples to constant values\n        Returns a numpy array of results.\n        \"\"\"\n        if not self.is_valid:\n            return np.full_like(x_values, np.nan, dtype=np.float64)\n        return self._eval_node(self.root, x_values, constants, path=[])\n\n    def _eval_node(self, node, x, constants=None, path=None):\n        val = node.value\n        \n        if val == 'x':\n            return x.astype(np.float64)\n        if val == 'pi':\n            return np.full_like(x, np.pi, dtype=np.float64)\n        if val == 'e':\n            return np.full_like(x, np.e, dtype=np.float64)\n        if val == 'C':\n            # Check if we have an optimized constant for this position\n            if constants is not None and tuple(path) in constants:\n                return np.full_like(x, constants[tuple(path)], dtype=np.float64)\n            return np.full_like(x, 1.0, dtype=np.float64)  # Default constant = 1\n        \n        # Check for numeric constants\n        try:\n            return np.full_like(x, float(val), dtype=np.float64)\n        except:\n            pass\n            \n        # Recursive evaluation\n        args = []\n        for i, c in enumerate(node.children):\n            args.append(self._eval_node(c, x, constants, path + [i] if path is not None else None))\n        \n        # Operators\n        with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n            if val == '+': return args[0] + args[1]\n            if val == '-': return args[0] - args[1]\n            if val == '*': return args[0] * args[1]\n            if val == '/': \n                return np.divide(args[0], args[1], out=np.zeros_like(x, dtype=np.float64), where=args[1]!=0)\n            if val == 'pow':\n                # Safe power\n                return np.power(np.abs(args[0]) + 1e-10, np.clip(args[1], -10, 10))\n            if val == 'mod':\n                return np.mod(args[0], args[1] + 1e-10)\n            if val == 'sin': return np.sin(args[0])\n            if val == 'cos': return np.cos(args[0])\n            if val == 'tan': return np.tan(args[0])\n            if val == 'exp': \n                return np.exp(np.clip(args[0], -100, 100))\n            if val == 'log': \n                return np.log(np.abs(args[0]) + 1e-10)\n            if val == 'sqrt':\n                return np.sqrt(np.abs(args[0]))\n            if val == 'abs':\n                return np.abs(args[0])\n            if val == 'floor':\n                return np.floor(args[0])\n            if val == 'ceil':\n                return np.ceil(args[0])\n            if val == 'gamma':\n                # Safe gamma (clip to avoid overflow)\n                clipped = np.clip(args[0], -50, 50)\n                result = np.zeros_like(clipped)\n                valid = clipped > 0\n                result[valid] = scipy_gamma(clipped[valid])\n                return result\n            if val == 'neg':\n                return -args[0]\n            if val == 'sign':\n                return np.sign(args[0])\n            if val == 'max':\n                return np.maximum(args[0], args[1])\n            if val == 'min':\n                return np.minimum(args[0], args[1])\n                \n        return np.zeros_like(x, dtype=np.float64)\n\n    def get_infix(self):\n        if not self.is_valid:\n            return \"Invalid\"\n        return self.root.to_infix()\n    \n    def count_constants(self):\n        if not self.is_valid:\n            return 0\n        return self.root.count_constants()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/model.py\n",
        "import torch\nimport torch.nn as nn\nimport numpy as np\n\nclass AlphaSymbolicModel(nn.Module):\n    def __init__(self, vocab_size, d_model=128, nhead=4, num_encoder_layers=2, num_decoder_layers=2, max_seq_len=50):\n        super(AlphaSymbolicModel, self).__init__()\n        \n        self.d_model = d_model\n        \n        # 1. Point Encoder: Processes pairs of (x, y)\n        # Input dim: 2 (x value, y value)\n        self.point_embedding = nn.Linear(2, d_model)\n        \n        # We use a standard Transformer Encoder for the \"Problem Embedding\"\n        # Since points are a set, we don't necessarily need positional encoding, \n        # but the Transformer will process them as a sequence.\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n        self.problem_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n        \n        # 2. Formula Decoder: Generates tokens\n        self.token_embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_encoder = PositionalEncoding(d_model, max_len=max_seq_len)\n        \n        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n        self.formula_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n        \n        # 3. Heads\n        self.policy_head = nn.Linear(d_model, vocab_size)\n        self.value_head = nn.Sequential(\n            nn.Linear(d_model, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1) # Expected negative RMSE\n        )\n        \n    def forward(self, x_values, y_values, formula_input, formula_mask=None):\n        \"\"\"\n        x_values: [batch, num_points]\n        y_values: [batch, num_points]\n        formula_input: [batch, seq_len] (Token IDs)\n        formula_mask: Optional mask for the decoder (causal mask)\n        \"\"\"\n        batch_size, num_points = x_values.shape\n        \n        # -- Problem Encoding --\n        # Stack x and y: [batch, num_points, 2]\n        points = torch.stack([x_values, y_values], dim=2)\n        \n        # Project to d_model\n        points_emb = self.point_embedding(points) # [batch, num_points, d_model]\n        \n        # Encode problem (memory for decoder)\n        memory = self.problem_encoder(points_emb)\n        \n        # -- Formula Decoding --\n        # Embed tokens\n        tgt = self.token_embedding(formula_input) # [batch, seq_len, d_model]\n        tgt = self.pos_encoder(tgt)\n        \n        # Decode\n        # memory is [batch, num_points, d_model]\n        # tgt is [batch, seq_len, d_model]\n        if formula_mask is None:\n             # Create causal mask\n            seq_len = formula_input.size(1)\n            formula_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(formula_input.device)\n\n        output = self.formula_decoder(tgt, memory, tgt_mask=formula_mask)\n        \n        # -- Heads --\n        # Policy: distribution over vocab for each token position\n        logits = self.policy_head(output) # [batch, seq_len, vocab_size]\n        \n        # Value: estimate value from the LAST token's state\n        # (Assuming the last token summarizes the current state)\n        last_token_output = output[:, -1, :] # [batch, d_model]\n        value = self.value_head(last_token_output) # [batch, 1]\n        \n        return logits, value\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        \n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        \n        self.register_buffer('pe', pe.unsqueeze(0))\n\n    def forward(self, x):\n        # x: [batch, seq_len, d_model]\n        x = x + self.pe[:, :x.size(1), :]\n        return x\n\nif __name__ == \"__main__\":\n    # Smoke Test\n    vocab_size = 20\n    model = AlphaSymbolicModel(vocab_size=vocab_size, d_model=32)\n    \n    # Dummy data\n    bs = 2\n    points = 10\n    x = torch.randn(bs, points)\n    y = torch.randn(bs, points)\n    \n    # Formula input (start token + some tokens)\n    seq = torch.randint(0, vocab_size, (bs, 5))\n    \n    logits, value = model(x, y, seq)\n    \n    print(\"Logits shape:\", logits.shape) # Should be [2, 5, 20]\n    print(\"Value shape:\", value.shape)   # Should be [2, 1]\n    print(\"Smoke test passed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/environment.py\n",
        "import gymnasium as gym\nfrom gymnasium import spaces\nimport numpy as np\nfrom core.grammar import VOCABULARY, OPERATORS, TOKEN_TO_ID, ExpressionTree\nfrom data.synthetic_data import DataGenerator\n\nclass SymbolicEnv(gym.Env):\n    def __init__(self, max_length=50):\n        super(SymbolicEnv, self).__init__()\n        \n        self.vocab_size = len(VOCABULARY)\n        self.max_length = max_length\n        self.vocab = VOCABULARY\n        \n        # Action space: Choose a token from the vocabulary\n        self.action_space = spaces.Discrete(self.vocab_size)\n        \n        # Observation space: \n        # 1. Current token sequence (padded)\n        # 2. X values (fixed size for simplicity)\n        # 3. Y values\n        # For this prototype we will expose a dictionary observation\n        self.observation_space = spaces.Dict({\n            \"sequence\": spaces.Box(low=0, high=self.vocab_size, shape=(max_length,), dtype=np.int32),\n            \"x\": spaces.Box(low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32),\n            \"y\": spaces.Box(low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32)\n        })\n        \n        self.data_gen = DataGenerator(max_depth=4)\n        self.current_problem = None\n        self.current_sequence = []\n        self.open_branches = 0\n        \n    def reset(self, seed=None, options=None):\n        super().reset(seed=seed)\n        \n        # Generate a new problem (X, Y)\n        # In a real scenario, this could be sampled from a fixed dataset\n        batch = self.data_gen.generate_batch(1, point_count=10)\n        self.current_problem = batch[0]\n        \n        self.current_sequence = []\n        self.open_branches = 1 # Start expecting a root node\n        \n        return self._get_obs(), {}\n\n    def step(self, action_id):\n        token = self.vocab[action_id]\n        self.current_sequence.append(token)\n        \n        # Update open branches\n        if token in OPERATORS:\n            arity = OPERATORS[token]\n            self.open_branches += (arity - 1)\n        else:\n            self.open_branches -= 1\n            \n        term = False\n        trunc = False\n        reward = 0.0\n        \n        # Check completion\n        if self.open_branches == 0:\n            term = True\n            # Tree is complete, evaluate\n            reward = self._calculate_reward()\n        elif self.open_branches < 0:\n            # Should not happen if we mask actions, but for safety\n            term = True\n            reward = -100.0 # Syntax error penalty\n        elif len(self.current_sequence) >= self.max_length:\n            trunc = True\n            reward = -10.0 # Incomplete penalty\n            \n        return self._get_obs(), reward, term, trunc, {}\n\n    def _get_obs(self):\n        # Convert sequence to IDs and pad\n        seq_ids = [TOKEN_TO_ID[t] for t in self.current_sequence]\n        padded_seq = np.zeros(self.max_length, dtype=np.int32)\n        padded_seq[:len(seq_ids)] = seq_ids\n        \n        return {\n            \"sequence\": padded_seq,\n            \"x\": self.current_problem['x'].astype(np.float32),\n            \"y\": self.current_problem['y'].astype(np.float32)\n        }\n\n    def _calculate_reward(self):\n        try:\n            tree = ExpressionTree(self.current_sequence)\n            if not tree.is_valid:\n                return -100.0\n            \n            y_pred = tree.evaluate(self.current_problem['x'])\n            \n            # Root Mean Squared Error (RMSE)\n            mse = np.mean((y_pred - self.current_problem['y'])**2)\n            rmse = np.sqrt(mse)\n            \n            if np.isnan(rmse) or np.isinf(rmse):\n                return -1000.0\n                \n            # Reward is negative RMSE\n            # We want to maximize reward -> minimize RMSE\n            # Normalize or scale? simpler is just -RMSE\n            return -rmse\n            \n        except Exception:\n            return -100.0\n\nif __name__ == \"__main__\":\n    env = SymbolicEnv()\n    obs, _ = env.reset()\n    print(\"Initial Observation Keys:\", obs.keys())\n    \n    # Simulate a few steps for x + x\n    # Prefix: + x x\n    actions = ['+', 'x', 'x']\n    tot_reward = 0\n    for tok in actions:\n        aid = TOKEN_TO_ID[tok]\n        obs, reward, term, trunc, _ = env.step(aid)\n        print(f\"Action: {tok}, Reward: {reward}, Term: {term}, Branches: {env.open_branches}\")\n        tot_reward += reward\n        if term: break\n    \n    print(f\"Total Reward: {tot_reward}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile core/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/synthetic_data.py\n",
        "import numpy as np\nimport random\nfrom core.grammar import VOCABULARY, OPERATORS, VARIABLES, CONSTANTS, ExpressionTree\nfrom data.augmentation import augment_formula_tokens\n\nclass DataGenerator:\n    def __init__(self, max_depth=5, population_size=1000, allowed_operators=None):\n        self.max_depth = max_depth\n        self.population_size = population_size\n        self.vocab = VOCABULARY\n        # Pre-compute terminal vs operator lists\n        self.terminals = VARIABLES + CONSTANTS\n        if allowed_operators:\n            self.operators = [op for op in allowed_operators if op in OPERATORS]\n        else:\n            self.operators = list(OPERATORS.keys())\n\n    def generate_random_tree(self, max_depth, current_depth=0):\n        if current_depth >= max_depth:\n            # Must return a terminal\n            return [random.choice(self.terminals)]\n        \n        # Decide if terminal or operator\n        # Higher probability of operator at shallow depths\n        if random.random() < 0.7: \n            op = random.choice(self.operators)\n            arity = OPERATORS[op]\n            tokens = [op]\n            for _ in range(arity):\n                tokens.extend(self.generate_random_tree(max_depth, current_depth + 1))\n            return tokens\n        else:\n            return [random.choice(self.terminals)]\n\n    def generate_batch(self, batch_size, point_count=10, x_range=(-10, 10)):\n        \"\"\"\n        Generates a batch of (X, Y) pairs and their generating formulas.\n        \"\"\"\n        data = []\n        \n        while len(data) < batch_size:\n            # Generate random formula\n            tokens = self.generate_random_tree(self.max_depth)\n            tree = ExpressionTree(tokens)\n            \n            if not tree.is_valid:\n                continue\n                \n            # Generate random X points\n            x_values = np.random.uniform(x_range[0], x_range[1], point_count)\n            # Sort X for cleaner visualization/learning\n            x_values.sort()\n            \n            # Calculate Y\n            y_values = tree.evaluate(x_values)\n            \n            # Check for validity (no NaNs, Infs, or extremely large values)\n            if np.any(np.isnan(y_values)) or np.any(np.isinf(y_values)):\n                continue\n            if np.max(np.abs(y_values)) > 1e6: # Reject too large numbers\n                continue\n            if np.std(y_values) < 1e-6: # Reject flat lines (too simple)\n                 # Optionally keep some, but mostly we want interesting curves\n                 if random.random() > 0.1: continue\n\n            data.append({\n                'tokens': tokens,\n                'infix': tree.get_infix(),\n                'x': x_values,\n                'y': y_values\n            })\n            \n        return data\n\n    def generate_inverse_batch(self, batch_size, point_count=10, x_range=(-5, 5)):\n        \"\"\"\n        Inverse data generation (AlphaTensor-style):\n        Generate KNOWN formulas with guaranteed solutions.\n        This helps the model learn from solvable problems first.\n        \"\"\"\n        data = []\n        \n        # Known formula templates with their token representations\n        templates = [\n            # Linear: a*x + b\n            lambda a, b: (['+', '*', str(a), 'x', str(b)], f\"({a}*x + {b})\"),\n            # Quadratic: a*x^2 + b\n            lambda a, b: (['+', '*', str(a), 'pow', 'x', '2', str(b)], f\"({a}*x^2 + {b})\"),\n            # Simple sin: sin(x)\n            lambda a, b: (['sin', 'x'], \"sin(x)\"),\n            # Scaled sin: a*sin(x)\n            lambda a, b: (['*', str(a), 'sin', 'x'], f\"{a}*sin(x)\"),\n            # Exponential: exp(x/a)\n            lambda a, b: (['exp', '/', 'x', str(max(1, abs(a)))], f\"exp(x/{max(1, abs(a))})\"),\n            # Square root: sqrt(x + a) \n            lambda a, b: (['sqrt', '+', 'x', str(abs(a)+1)], f\"sqrt(x+{abs(a)+1})\"),\n            # Polynomial: x^2 - a\n            lambda a, b: (['-', 'pow', 'x', '2', str(a)], f\"(x^2 - {a})\"),\n            # Cosine\n            lambda a, b: (['cos', 'x'], \"cos(x)\"),\n        ]\n        \n        while len(data) < batch_size:\n            # Random coefficients (small integers for stability)\n            a = random.randint(1, 5)\n            b = random.randint(-3, 3)\n            \n            # Pick random template\n            template = random.choice(templates)\n            \n            try:\n                tokens, formula_str = template(a, b)\n                \n                # Convert string numbers -> 'C'\n                final_tokens = []\n                for t in tokens:\n                    if t in VOCABULARY:\n                        final_tokens.append(t)\n                    else:\n                        final_tokens.append('C')\n                \n                # --- DATA AUGMENTATION (AlphaTensor Style) ---\n                # Apply mathematical invariances (Commutativity, etc.)\n                # This multiplies the effective dataset size\n                if random.random() < 0.5:\n                    final_tokens = augment_formula_tokens(final_tokens)\n                # ---------------------------------------------\n                \n                tree = ExpressionTree(final_tokens)\n                if not tree.is_valid:\n                    continue\n                \n                # Generate X points (positive for sqrt/log safety)\n                if 'sqrt' in final_tokens or 'log' in final_tokens:\n                    x_values = np.linspace(0.5, x_range[1], point_count)\n                else:\n                    x_values = np.linspace(x_range[0], x_range[1], point_count)\n                \n                y_values = tree.evaluate(x_values)\n                \n                # Validity checks\n                if np.any(np.isnan(y_values)) or np.any(np.isinf(y_values)):\n                    continue\n                if np.max(np.abs(y_values)) > 1e6:\n                    continue\n                \n                data.append({\n                    'tokens': final_tokens,\n                    'infix': tree.get_infix(),\n                    'x': x_values,\n                    'y': y_values\n                })\n            except:\n                continue\n                \n        return data\n\n# Quick test if run directly\nif __name__ == \"__main__\":\n    gen = DataGenerator(max_depth=4)\n    batch = gen.generate_batch(5)\n    for item in batch:\n        print(f\"Formula: {item['infix']}\")\n        print(f\"Tokens: {item['tokens']}\")\n        print(f\"Y sample: {item['y'][:3]}...\")\n        print(\"-\" * 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/benchmark_data.py\n",
        "import numpy as np\n\n# Standard Benchmark Problems\n# Levels: 1 (Easy), 2 (Medium), 3 (Hard)\n\nBENCHMARK_SUITE = [\n    # --- Level 1: Polynomials & Basic Arithmetic ---\n    {\n        'id': 'p1',\n        'name': 'Lineal',\n        'formula_str': '2.5 * x + 1.0',\n        'lambda': lambda x: 2.5 * x + 1.0,\n        'domain': (-10, 10),\n        'points': 20,\n        'level': 1\n    },\n    {\n        'id': 'p2',\n        'name': 'Cuadratica Simple',\n        'formula_str': 'x * x',\n        'lambda': lambda x: x**2,\n        'domain': (-5, 5),\n        'points': 20,\n        'level': 1\n    },\n    {\n        'id': 'p3',\n        'name': 'Polinomio Cubico',\n        'formula_str': 'x**3 + x**2',\n        'lambda': lambda x: x**3 + x**2,\n        'domain': (-3, 3),\n        'points': 20,\n        'level': 1\n    },\n    \n    # --- Level 2: Trigonometric & Transcendental ---\n    {\n        'id': 'p4',\n        'name': 'Seno Basico',\n        'formula_str': 'sin(x)',\n        'lambda': lambda x: np.sin(x),\n        'domain': (-np.pi, np.pi),\n        'points': 30,\n        'level': 2\n    },\n    {\n        'id': 'p5',\n        'name': 'Coseno Desplazado',\n        'formula_str': 'cos(x) + 1',\n        'lambda': lambda x: np.cos(x) + 1,\n        'domain': (-np.pi, np.pi),\n        'points': 30,\n        'level': 2\n    },\n    {\n        'id': 'p6',\n        'name': 'Exponencial Simple',\n        'formula_str': 'exp(x)',\n        'lambda': lambda x: np.exp(x),\n        'domain': (-2, 2), # Small domain to avoid explosion\n        'points': 20,\n        'level': 2\n    },\n    \n    # --- Level 3: Physics / Complex ---\n    {\n        'id': 'p7',\n        'name': 'Damped Oscillation',\n        'formula_str': 'exp(-x) * sin(2*x)',\n        'lambda': lambda x: np.exp(-x) * np.sin(2*x),\n        'domain': (0, 4),\n        'points': 40,\n        'level': 3\n    },\n    {\n        'id': 'p8',\n        'name': 'Gaussian',\n        'formula_str': 'exp(-x**2)',\n        'lambda': lambda x: np.exp(-x**2),\n        'domain': (-3, 3),\n        'points': 30,\n        'level': 3\n    },\n    {\n        'id': 'p9',\n        'name': 'Nguyen-3 (x^3 + x^2 + x)',\n        'formula_str': 'x**3 + x**2 + x',\n        'lambda': lambda x: x**3 + x**2 + x,\n        'domain': (-2, 2),\n        'points': 20,\n        'level': 3\n    },\n    {\n        'id': 'p10',\n        'name': 'Rational Function',\n        'formula_str': 'x / (1 + x**2)',\n        'lambda': lambda x: x / (1 + x**2),\n        'domain': (-4, 4),\n        'points': 30,\n        'level': 3\n    }\n]\n\ndef get_benchmark_data(problem_id):\n    \"\"\"Returns (x, y) for a specific problem ID.\"\"\"\n    for p in BENCHMARK_SUITE:\n        if p['id'] == problem_id:\n            x = np.linspace(p['domain'][0], p['domain'][1], p['points'])\n            y = p['lambda'](x)\n            return x, y, p\n    return None, None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/augmentation.py\n",
        "\nimport random\nfrom core.grammar import OPERATORS\n\ndef augment_formula_tokens(tokens):\n    \"\"\"\n    Applies mathematical invariants to generate an equivalent formula structure.\n    Acts as 'Data Augmentation' for symbolic regression.\n    \n    Supported Transformations:\n    1. Commutativity: (+) and (*)\n       e.g. [+ a b] -> [+ b a]\n    2. Identity:\n       e.g. x -> [+ x 0], x -> [* x 1] (Rarely used to avoid bloat, but useful for robustness)\n    3. Inverse operations (Conceptually):\n       Not implemented directly on tokens without tree parsing, \n       so we focus on purely structural swaps that don't change value.\n    \n    Args:\n        tokens (list): List of tokens in Prefix notation.\n    \n    Returns:\n        list: A new list of tokens representing an equivalent formula.\n    \"\"\"\n    if not tokens:\n        return []\n\n    # Helper to parse prefix expression into a tree-like structure (recursive)\n    def parse_prefix(token_list):\n        if not token_list:\n            return None, []\n        \n        root = token_list[0]\n        remaining = token_list[1:]\n        \n        if root in OPERATORS:\n            try:\n                arity = OPERATORS[root]\n                children = []\n                for _ in range(arity):\n                    child, remaining = parse_prefix(remaining)\n                    children.append(child)\n                return {'val': root, 'children': children}, remaining\n            except:\n                 # Fallback for malformed\n                return {'val': root, 'children': []}, remaining\n        else:\n            # Terminal\n            return {'val': root, 'children': []}, remaining\n\n    # Helper to flatten tree back to tokens\n    def flatten(node):\n        res = [node['val']]\n        for child in node['children']:\n            res.extend(flatten(child))\n        return res\n\n    # 1. Parse\n    try:\n        tree, _ = parse_prefix(tokens)\n    except:\n        return list(tokens) # Fail safe\n\n    # 2. Augment Recursive\n    def augment_recursive(node):\n        # First augment children\n        for i in range(len(node['children'])):\n            node['children'][i] = augment_recursive(node['children'][i])\n            \n        val = node['val']\n        children = node['children']\n        \n        # Transformation: Commutativity\n        if val in ['+', '*'] and len(children) == 2:\n            if random.random() < 0.5:\n                # Swap children\n                node['children'] = [children[1], children[0]]\n        \n        # Transformation: (- a b) -> (+ a (- b)) ? Too complex for tokens only without 'neg'\n        # Transformation: (+ x x) -> (* x 2) ?\n        if val == '+' and len(children) == 2:\n            # Check deep equality is hard, but simple check:\n            if flatten(children[0]) == flatten(children[1]):\n                if random.random() < 0.3:\n                    # Convert x + x -> x * 2\n                    return {'val': '*', 'children': [children[0], {'val': '2', 'children': []}]}\n\n        return node\n\n    # 3. Apply\n    augmented_tree = augment_recursive(tree)\n    \n    # 4. Flatten\n    return flatten(augmented_tree)\n\nif __name__ == \"__main__\":\n    # Test\n    # Formula: (+ x y) -> prefix ['+', 'x', 'y']\n    t1 = ['+', 'x', 'y']\n    print(f\"Original: {t1} -> Aug: {augment_formula_tokens(t1)}\")\n    \n    # Formula: (* (+ a b) c)\n    t2 = ['*', '+', 'a', 'b', 'c']\n    print(f\"Original: {t2} -> Aug: {augment_formula_tokens(t2)}\")\n    \n    # Formula: (+ x x)\n    t3 = ['+', 'x', 'x']\n    print(f\"Original: {t3} -> Aug: {augment_formula_tokens(t3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile data/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/mcts.py\n",
        "import math\nimport numpy as np\nimport torch\nimport copy\nfrom core.grammar import VOCABULARY, TOKEN_TO_ID, OPERATORS, ExpressionTree, VARIABLES\nfrom utils.optimize_constants import optimize_constants\n\nclass MCTSNode:\n    def __init__(self, tokens, parent=None, prior=0.0):\n        self.tokens = tokens\n        self.parent = parent\n        self.children = {}\n        self.visit_count = 0\n        self.value_sum = 0.0\n        self.prior = prior\n        self.is_expanded = False\n        \n        # for parallel search\n        self.virtual_loss = 0.0\n        self.virtual_visits = 0\n\n    @property\n    def value(self):\n        count = self.visit_count + self.virtual_visits\n        if count == 0:\n            return 0.0\n        # Combine real value and virtual loss\n        # Virtual loss is SUBTRACTED to discourage visits\n        return (self.value_sum - self.virtual_loss) / count\n\n    def ucb_score(self, c_puct=1.0):\n        count = self.visit_count + self.virtual_visits\n        parent_count = self.parent.visit_count + self.parent.virtual_visits if self.parent else 1\n        \n        if self.parent is None:\n            return 0.0\n            \n        u = c_puct * self.prior * math.sqrt(parent_count) / (1 + count)\n        return self.value + u\n\n    @property\n    def complexity(self):\n        \"\"\"Estimate complexity (length of formula).\"\"\"\n        return len(self.tokens)\n\nclass MCTS:\n    def __init__(self, model, device, grammar=None, c_puct=1.0, n_simulations=100, max_simulations=None, max_depth=50, complexity_lambda=0.1, max_len=200, batch_size=8):\n        self.model = model\n        self.device = device\n        self.grammar = grammar\n        self.c_puct = c_puct\n        \n        # Handle backwards compatibility for max_simulations\n        if max_simulations is not None:\n            self.n_simulations = max_simulations\n        else:\n            self.n_simulations = n_simulations\n            \n        self.max_depth = max_depth\n        self.complexity_lambda = complexity_lambda\n        self.max_len = max_len\n        self.min_value = -float('inf')\n        self.max_value = float('inf')\n        self.vocab_size = len(VOCABULARY)\n        self.sos_id = self.vocab_size\n        self.batch_size = batch_size\n        \n        # Pareto Front: List of {'tokens':, 'rmse':, 'complexity':, 'formula':}\n        self.pareto_front = []\n        \n        # Virtual loss constant usually 1-3\n        self.v_loss_const = 3.0\n        \n    def search(self, x_values, y_values, num_simulations=None):\n        \"\"\"\n        Run MCTS (Parallel/Batched) to find the best formula.\n        \"\"\"\n        self.pareto_front = [] # Reset Pareto Front for new search\n        root = MCTSNode(tokens=[])\n        \n        # Initial expansion (single)\n        self._expand_batch([root], x_values, y_values)\n        \n        best_rmse = float('inf')\n        best_formula = None\n        best_tokens = None\n        \n        limit = num_simulations if num_simulations is not None else self.n_simulations\n        \n        # Loop in batches\n        # Ensure we do at least 1 batch\n        num_batches = max(1, (limit + self.batch_size - 1) // self.batch_size)\n        \n        for _ in range(num_batches): \n            leaves = []\n            \n            # 1. Selection (find N leaves)\n            for _ in range(self.batch_size):\n                node = root\n                depth = 0\n                \n                # Selection loop\n                while node.is_expanded and node.children and depth < self.max_depth:\n                    node = max(node.children.values(), key=lambda n: n.ucb_score(self.c_puct))\n                    \n                    # Apply virtual loss to discourage re-selection in same batch\n                    node.virtual_loss += self.v_loss_const\n                    node.virtual_visits += 1\n                    depth += 1\n                \n                # Check if valid leaf to expand\n                if depth < self.max_depth and not node.is_expanded:\n                    # Avoid duplicates in batch (simple check)\n                    if node not in leaves:\n                        leaves.append(node)\n                else:\n                    pass\n            \n            if not leaves:\n                # If no leaves found (tree fully explored or locked), standard MCTS usually continues or stops.\n                # We can just break or continue backprop of terminals.\n                if root.visit_count > limit: break \n                continue\n                \n            # 2. Batch Expansion & Evaluation\n            values = self._expand_batch(leaves, x_values, y_values)\n            \n            # 3. Backpropagation\n            for node, val in zip(leaves, values):\n                # Check for best solution found\n                if self._is_complete_tree(node.tokens):\n                    # For completed formulas, we calculate REAL RMSE\n                    try:\n                        # Evaluar\n                        # Importar aqu\u00ed para evitar circular imports si es necesario\n                        from utils.optimize_constants import optimize_constants\n                        \n                        # 1. Optimizar constants (Crucial para Accuracy)\n                        # Esto es \"Phase 1\" de TPSR (constantes en las hojas)\n                        # Por simplicidad en esta iteraci\u00f3n, asumimos que 'evaluate_formula' ya hace algo o usamos el string directo.\n                        # Idealmente llamar\u00edamos a BFGS aqu\u00ed.\n                        \n                        # Use existing _evaluate_formula to get RMSE and optimized constants\n                        tree = ExpressionTree(node.tokens)\n                        optimized_constants, real_rmse = optimize_constants(tree, x_values, y_values)\n                        \n                        # Get y_pred using the optimized constants\n                        y_pred = tree.evaluate(x_values, constants=optimized_constants)\n                        \n                        # Check dimensions\n                        if y_pred.shape != y_values.shape:\n                            # If shapes don't match, it's an invalid evaluation\n                            final_val = 0.0\n                        else:\n                            # 2. Calcular Reward TPSR (Hybrid Accuracy + Complexity)\n                            # R = 1 / (1 + NMSE) + lambda * exp(-len/L)\n                            \n                            mse = np.mean((y_pred - y_values)**2)\n                            var_y = np.var(y_values)\n                            if var_y < 1e-9: var_y = 1.0 # Avoid division by zero\n                            \n                            nmse = mse / var_y\n                            \n                            # Evitar NMSE gigantes\n                            if np.isnan(nmse) or np.isinf(nmse):\n                                nmse = 1e9\n                            \n                            r_acc = 1.0 / (1.0 + nmse)\n                            \n                            # Penalizaci\u00f3n por complejidad\n                            token_len = len(node.tokens)\n                            L = self.max_len # Max length del modelo\n                            \n                            r_cplx = self.complexity_lambda * np.exp(-token_len / L)\n                            \n                            # Suma y Normalizaci\u00f3n (para mantener rango 0-1)\n                            # El m\u00e1ximo te\u00f3rico es (1.0 + lambda). Dividimos por eso.\n                            raw_reward = r_acc + r_cplx\n                            final_val = raw_reward / (1.0 + self.complexity_lambda)\n\n                        # Update best formula based on RMSE (for reporting, not for MCTS value)\n                        if real_rmse < best_rmse:\n                            best_rmse = real_rmse\n                            best_tokens = node.tokens\n                            best_formula = ExpressionTree(node.tokens).get_infix()\n                        \n                        # Update Pareto Front\n                        # Complexity = len(tokens) (or could use count_constants + nodes)\n                        complexity = len(node.tokens)\n                        self._update_pareto_front(node.tokens, real_rmse, complexity, ExpressionTree(node.tokens).get_infix())\n\n                    except Exception as e:\n                        # print(f\"Error evaluating formula: {e}\")\n                        final_val = 0.0 # Invalid formula gets 0 reward\n                else:\n                    final_val = val\n                \n                # The following lines were part of the user's instruction but contained syntax errors and undefined variables.\n                # They are commented out to maintain a syntactically correct and functional document.\n                # If these lines were intended to be added, please provide a complete and correct snippet.\n                #\n                # # Construir vector de probabilidades\n                # probs = np.zeros(self.vocab_size, dtype=np.float32)\n                # for token_id, count in counts.items():\n                #     probs[token_id] = count / total_visits_count += 1\n                \n                curr = node\n                while curr is not None:\n                    curr.visit_count += 1\n                    curr.value_sum += final_val\n                    \n                    # Revert virtual loss for parent and above\n                    # Since we added to PARENT's child (which is curr), \n                    # and we traverse Up...\n                    # Wait, logic: We selected CHILD. Virtual loss was added TO CHILD (curr).\n                    # So we must remove it from curr.\n                    if curr.virtual_visits > 0:\n                        curr.virtual_loss -= self.v_loss_const\n                        curr.virtual_visits -= 1\n                            \n                    curr = curr.parent\n        \n        # After search, force cleanup of any residual virtual loss (safety)\n        # (Not strictly needed if logic is perfect, but good practice in complex async MCTS)\n        \n        return {\n            'tokens': best_tokens,\n            'formula': best_formula,\n            'rmse': best_rmse,\n            'root': root,\n            'pareto_front': self.pareto_front\n        }\n\n    def _update_pareto_front(self, tokens, rmse, complexity, formula_str):\n        \"\"\"\n        Update the Pareto Front with a new solution.\n        Keep solutions that are not dominated by any other solution.\n        Solution A dominates B if:\n        A.rmse <= B.rmse AND A.complexity <= B.complexity AND (A.rmse < B.rmse OR A.complexity < B.complexity)\n        \"\"\"\n        # Create candidate\n        candidate = {'tokens': tokens, 'rmse': rmse, 'complexity': complexity, 'formula': formula_str}\n        \n        # Check if dominated by existing\n        is_dominated = False\n        to_remove = []\n        \n        for existing in self.pareto_front:\n            # Check if existing dominates candidate\n            if (existing['rmse'] <= candidate['rmse'] and \n                existing['complexity'] <= candidate['complexity'] and \n                (existing['rmse'] < candidate['rmse'] or existing['complexity'] < candidate['complexity'])):\n                is_dominated = True\n                break\n                \n            # Check if candidate dominates existing\n            if (candidate['rmse'] <= existing['rmse'] and \n                candidate['complexity'] <= existing['complexity'] and \n                (candidate['rmse'] < existing['rmse'] or candidate['complexity'] < existing['complexity'])):\n                to_remove.append(existing)\n        \n        if not is_dominated:\n            # Remove dominated existing solutions\n            for item in to_remove:\n                self.pareto_front.remove(item)\n            \n            # Add candidate\n            self.pareto_front.append(candidate)\n            # Sort by RMSE for easier viewing\n            self.pareto_front.sort(key=lambda x: x['rmse'])\n\n    def _expand_batch(self, nodes, x_values, y_values):\n        \"\"\"\n        Batched expansion. Returns list of values.\n        \"\"\"\n        if not nodes:\n            return []\n            \n        # Prepare inputs\n        x_tensor = torch.tensor(x_values, dtype=torch.float32).unsqueeze(0).to(self.device)\n        y_tensor = torch.tensor(y_values, dtype=torch.float32).unsqueeze(0).to(self.device)\n        \n        # Repeat X/Y for batch\n        batch_size = len(nodes)\n        x_batch = x_tensor.repeat(batch_size, 1, 1).squeeze(1) # [batch, points]\n        y_batch = y_tensor.repeat(batch_size, 1, 1).squeeze(1) # [batch, points]\n        \n        # Prepare sequences\n        # Find max len\n        max_len = 0\n        seqs = []\n        for n in nodes:\n            s = [self.sos_id] + [TOKEN_TO_ID[t] for t in n.tokens]\n            seqs.append(s)\n            max_len = max(max_len, len(s))\n            \n        # Pad and stack\n        input_tensor = torch.full((batch_size, max_len), self.sos_id, dtype=torch.long).to(self.device)\n        for i, s in enumerate(seqs):\n            input_tensor[i, :len(s)] = torch.tensor(s, dtype=torch.long)\n            \n        # Inference\n        with torch.no_grad():\n            logits, value_preds = self.model(x_batch, y_batch, input_tensor)\n            \n        # Process results\n        values = []\n        \n        # To CPU numpy for probability processing\n        probs_batch = torch.softmax(logits[:, -1, :self.vocab_size], dim=1).cpu().numpy()\n        value_preds = value_preds.cpu().numpy().flatten()\n        \n        for i, node in enumerate(nodes):\n            # 1. Store Value\n            val = float(np.clip(value_preds[i], 0.0, 1.0))\n            values.append(val)\n            \n            # 2. Expand children\n            node_probs = probs_batch[i]\n            valid_next = self._get_valid_next_tokens(node.tokens)\n            \n            for idx in valid_next:\n                token = VOCABULARY[idx]\n                prior = node_probs[idx]\n                child = MCTSNode(tokens=node.tokens + [token], parent=node, prior=prior)\n                node.children[token] = child\n            \n            node.is_expanded = True\n            \n        return values\n\n    def _get_valid_next_tokens(self, tokens):\n        \"\"\"Simple grammar check.\"\"\"\n        open_slots = 1\n        for t in tokens:\n            if t in OPERATORS:\n                open_slots += OPERATORS[t] - 1\n            else:\n                open_slots -= 1\n        \n        if open_slots <= 0:\n            return []\n        return list(range(self.vocab_size))\n\n    def _is_complete_tree(self, tokens):\n        if not tokens: return False\n        try:\n            tree = ExpressionTree(tokens)\n            # Basic validation\n            if len(tokens) > self.max_depth * 2: return False\n            return tree.is_valid\n        except:\n            return False\n\n    def _evaluate_formula(self, tokens, x, y):\n        try:\n            tree = ExpressionTree(tokens)\n            _, rmse = optimize_constants(tree, x, y)\n            return rmse\n        except:\n            return 1e9\n\n    def get_training_examples(self, root):\n        \"\"\"\n        Extrae ejemplos de entrenamiento del \u00e1rbol generado.\n        Retorna: lista de (state_tokens, policy_probs, value_target)\n        \"\"\"\n        examples = []\n        queue = [root]\n        \n        while queue:\n            node = queue.pop(0)\n            if node.visit_count < 1: \n                continue\n            \n            # Policy Target (Pi)\n            # Distribuci\u00f3n de visitas de los hijos\n            counts = {}\n            total_visits = 0\n            has_children = False\n            \n            for token_id, child in node.children.items():\n                # child key is token STRING or ID?\n                # In _expand_batch: node.children[token] = child.\n                # token = VOCABULARY[idx] (String).\n                # So keys are strings.\n                # But we need ID for probabilities array index.\n                if token_id in TOKEN_TO_ID:\n                    tid = TOKEN_TO_ID[token_id]\n                    counts[tid] = child.visit_count\n                    total_visits += child.visit_count\n                    queue.append(child)\n                    has_children = True\n            \n            if not has_children or total_visits == 0:\n                continue\n                \n            # Construir vector de probabilidades\n            probs = np.zeros(self.vocab_size, dtype=np.float32)\n            for tid, count in counts.items():\n                probs[tid] = count / total_visits\n            \n            # Value Target (V)\n            # Usamos el Q-value (valor esperado) del nodo como target para el Value Head.\n            # Q = value_sum / visit_count\n            v = node.value_sum / node.visit_count\n            \n            # State: node.tokens (lista de ids?)\n            # node.tokens is list of strings (from VOCABULARY).\n            # self_play.py expects tokens as strings in ReplayBuffer.add.\n            examples.append((node.tokens, probs, v))\n            \n        return examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/beam_search.py\n",
        "\"\"\"\nBeam Search for AlphaSymbolic.\nExplores multiple formula candidates in parallel, keeping top-K at each step.\n\"\"\"\nimport torch\nimport numpy as np\nfrom core.grammar import VOCABULARY, OPERATORS, TOKEN_TO_ID, ExpressionTree\nfrom utils.optimize_constants import optimize_constants\n\nclass BeamSearch:\n    def __init__(self, model, device, beam_width=10, max_length=30):\n        self.model = model\n        self.device = device\n        self.beam_width = beam_width\n        self.max_length = max_length\n        self.vocab_size = len(VOCABULARY)\n        self.sos_id = self.vocab_size  # SOS token ID\n        \n    def search(self, x_values, y_values):\n        \"\"\"\n        Beam Search to find the best formula structure.\n        \"\"\"\n        # Prepare data once\n        x_tensor = torch.tensor(x_values, dtype=torch.float32).unsqueeze(0).to(self.device) # [1, points]\n        y_tensor = torch.tensor(y_values, dtype=torch.float32).unsqueeze(0).to(self.device) # [1, points]\n        \n        # Each element in beams is just the sequence of tokens (list of strings)\n        # We track scores and open branches in parallel lists or a list of dicts\n        beams = [{'seq': [], 'log_prob': 0.0, 'open': 1}]\n        \n        completed = []\n        \n        for step in range(self.max_length):\n            if not beams:\n                break\n                \n            # Filter valid beams just in case\n            active_beams = [b for b in beams if b['open'] > 0]\n            if not active_beams:\n                break\n                \n            # Prepare batch for model\n            # Batch size = number of active beams\n            batch_size = len(active_beams)\n            \n            # Expand X and Y to match batch size [batch, points]\n            x_batch = x_tensor.expand(batch_size, -1)\n            y_batch = y_tensor.expand(batch_size, -1)\n            \n            # Prepare input sequences [batch, current_seq_len]\n            # Must prepend SOS token\n            seqs = [[self.sos_id] + [TOKEN_TO_ID[t] for t in b['seq']] for b in active_beams]\n            input_tensor = torch.tensor(seqs, dtype=torch.long).to(self.device)\n            \n            # Single model call for all beams\n            with torch.no_grad():\n                logits, _ = self.model(x_batch, y_batch, input_tensor)\n            \n            # Logits shape: [batch, seq_len, vocab_size]\n            # We want the last token's probabilities\n            last_token_logits = logits[:, -1, :self.vocab_size]\n            log_probs = torch.log_softmax(last_token_logits, dim=-1) # [batch, vocab]\n            \n            # We need to find the top-K candidates ACROSS current beams?\n            # Standard beam search: expand all, then prune to K\n            \n            all_candidates = []\n            \n            # Get top-K for EACH beam to avoid explosion (e.g. top 2*width)\n            k_per_beam = min(self.beam_width, self.vocab_size)\n            beam_topk_scores, beam_topk_indices = torch.topk(log_probs, k_per_beam, dim=-1)\n            \n            # Move to CPU for processing logic\n            beam_topk_scores = beam_topk_scores.cpu().numpy()\n            beam_topk_indices = beam_topk_indices.cpu().numpy()\n            \n            for i, beam in enumerate(active_beams):\n                for score, idx in zip(beam_topk_scores[i], beam_topk_indices[i]):\n                    token = VOCABULARY[idx]\n                    new_seq = beam['seq'] + [token]\n                    \n                    # Calculate new open branches\n                    if token in OPERATORS:\n                        new_open = beam['open'] + OPERATORS[token] - 1\n                    else:\n                        new_open = beam['open'] - 1\n                    \n                    if new_open < 0:\n                        continue\n                        \n                    all_candidates.append({\n                        'seq': new_seq,\n                        'log_prob': beam['log_prob'] + score,\n                        'open': new_open\n                    })\n            \n            # Global prune: keep top beam_width\n            all_candidates.sort(key=lambda x: x['log_prob'], reverse=True)\n            beams = all_candidates[:self.beam_width]\n            \n            # Check for completions\n            still_active = []\n            for b in beams:\n                if b['open'] == 0:\n                    completed.append(b)\n                else:\n                    still_active.append(b)\n            \n            beams = still_active\n            # If we filled up on completions, we might still want to explore? \n            # Usually we keep exploring until all beams are done or max length\n            if len(completed) >= self.beam_width:\n                 # Optional: early exit if we found enough good candidates\n                 pass\n\n        # Add any partial completions that happen to be valid (unlikely if open > 0)\n        # But maybe we ran out of steps?\n        \n        # Evaluate results\n        scored_results = []\n        for beam in completed:\n            tree = ExpressionTree(beam['seq'])\n            if tree.is_valid:\n                constants, rmse = optimize_constants(tree, x_values, y_values)\n                scored_results.append({\n                    'tokens': beam['seq'],\n                    'log_prob': beam['log_prob'],\n                    'rmse': rmse,\n                    'constants': constants,\n                    'formula': tree.get_infix()\n                })\n        \n        scored_results.sort(key=lambda x: x['rmse'])\n        return scored_results\n\n\ndef beam_solve(target_x, target_y, model, device, beam_width=20, max_length=25):\n    \"\"\"\n    Solve symbolic regression using beam search.\n    \"\"\"\n    searcher = BeamSearch(model, device, beam_width=beam_width, max_length=max_length)\n    results = searcher.search(target_x, target_y)\n    \n    if not results:\n        return None\n        \n    return results  # Return all results for Pareto analysis\n\n\nif __name__ == \"__main__\":\n    from core.model import AlphaSymbolicModel\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    VOCAB_SIZE = len(VOCABULARY)\n    \n    model = AlphaSymbolicModel(vocab_size=VOCAB_SIZE + 1, d_model=64).to(DEVICE)\n    try:\n        model.load_state_dict(torch.load(\"alpha_symbolic_model.pth\", map_location=DEVICE, weights_only=True))\n    except:\n        print(\"Model not found, using random weights\")\n    model.eval()\n    \n    # Test\n    x_test = np.linspace(-5, 5, 20).astype(np.float64)\n    y_test = 2 * x_test + 3\n    \n    print(\"Running Beam Search...\")\n    results = beam_solve(x_test, y_test, model, DEVICE, beam_width=10)\n    \n    print(f\"\\nFound {len(results)} valid formulas:\")\n    for i, r in enumerate(results[:5]):\n        print(f\"  {i+1}. {r['formula']} (RMSE: {r['rmse']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/pareto.py\n",
        "\"\"\"\nPareto Front Manager for AlphaSymbolic.\nMaintains a set of non-dominated solutions (accuracy vs complexity).\n\"\"\"\nimport numpy as np\nfrom core.grammar import ExpressionTree\n\nclass ParetoSolution:\n    def __init__(self, tokens, rmse, complexity, formula_str, constants=None):\n        self.tokens = tokens\n        self.rmse = rmse  # Lower is better\n        self.complexity = complexity  # Lower is better (number of nodes)\n        self.formula = formula_str\n        self.constants = constants or {}\n        \n    def dominates(self, other):\n        \"\"\"Returns True if self dominates other (better in all objectives).\"\"\"\n        # Self dominates other if:\n        # - Self is at least as good in all objectives\n        # - Self is strictly better in at least one objective\n        at_least_as_good = (self.rmse <= other.rmse) and (self.complexity <= other.complexity)\n        strictly_better = (self.rmse < other.rmse) or (self.complexity < other.complexity)\n        return at_least_as_good and strictly_better\n    \n    def __repr__(self):\n        return f\"ParetoSolution(rmse={self.rmse:.4f}, complexity={self.complexity}, formula='{self.formula}')\"\n\n\nclass ParetoFront:\n    def __init__(self, max_size=50):\n        self.solutions = []\n        self.max_size = max_size\n        \n    def add(self, solution):\n        \"\"\"\n        Attempts to add a solution to the Pareto front.\n        Returns True if added, False if dominated.\n        \"\"\"\n        # Check if new solution is dominated by any existing\n        for existing in self.solutions:\n            if existing.dominates(solution):\n                return False  # New solution is dominated\n        \n        # Remove any solutions dominated by the new one\n        self.solutions = [s for s in self.solutions if not solution.dominates(s)]\n        \n        # Add the new solution\n        self.solutions.append(solution)\n        \n        # Enforce max size by removing worst solutions\n        if len(self.solutions) > self.max_size:\n            # Sort by a combined score and keep top max_size\n            self.solutions.sort(key=lambda s: s.rmse + 0.01 * s.complexity)\n            self.solutions = self.solutions[:self.max_size]\n        \n        return True\n    \n    def add_from_results(self, results_list):\n        \"\"\"\n        Add multiple results from beam search or MCTS.\n        results_list: list of dicts with 'tokens', 'rmse', 'constants', 'formula'\n        \"\"\"\n        added = 0\n        for r in results_list:\n            tree = ExpressionTree(r['tokens'])\n            complexity = len(r['tokens'])  # Simple complexity = token count\n            \n            sol = ParetoSolution(\n                tokens=r['tokens'],\n                rmse=r['rmse'],\n                complexity=complexity,\n                formula_str=r['formula'],\n                constants=r.get('constants', {})\n            )\n            \n            if self.add(sol):\n                added += 1\n        \n        return added\n    \n    def get_best_by_rmse(self):\n        \"\"\"Returns the solution with lowest RMSE.\"\"\"\n        if not self.solutions:\n            return None\n        return min(self.solutions, key=lambda s: s.rmse)\n    \n    def get_simplest(self):\n        \"\"\"Returns the solution with lowest complexity.\"\"\"\n        if not self.solutions:\n            return None\n        return min(self.solutions, key=lambda s: s.complexity)\n    \n    def get_balanced(self, alpha=0.5):\n        \"\"\"\n        Returns a balanced solution.\n        alpha: weight for RMSE (1-alpha for complexity)\n        \"\"\"\n        if not self.solutions:\n            return None\n        \n        # Normalize scores\n        rmse_vals = [s.rmse for s in self.solutions]\n        comp_vals = [s.complexity for s in self.solutions]\n        \n        min_rmse, max_rmse = min(rmse_vals), max(rmse_vals) + 1e-10\n        min_comp, max_comp = min(comp_vals), max(comp_vals) + 1e-10\n        \n        def score(s):\n            norm_rmse = (s.rmse - min_rmse) / (max_rmse - min_rmse)\n            norm_comp = (s.complexity - min_comp) / (max_comp - min_comp)\n            return alpha * norm_rmse + (1 - alpha) * norm_comp\n        \n        return min(self.solutions, key=score)\n    \n    def summary(self):\n        \"\"\"Print a summary of the Pareto front.\"\"\"\n        print(f\"\\n=== Pareto Front ({len(self.solutions)} solutions) ===\")\n        for i, sol in enumerate(sorted(self.solutions, key=lambda s: s.rmse)[:10]):\n            print(f\"  {i+1}. RMSE={sol.rmse:.6f}, Nodes={sol.complexity}, Formula: {sol.formula}\")\n\n\n# Quick test\nif __name__ == \"__main__\":\n    front = ParetoFront()\n    \n    # Add some test solutions\n    solutions = [\n        ParetoSolution(['x'], 10.0, 1, \"x\"),\n        ParetoSolution(['+', 'x', '1'], 5.0, 3, \"(x + 1)\"),\n        ParetoSolution(['*', '2', 'x'], 3.0, 3, \"(2 * x)\"),\n        ParetoSolution(['+', '*', '2', 'x', '3'], 0.5, 5, \"((2 * x) + 3)\"),\n        ParetoSolution(['+', '*', '*', '2', 'x', 'x', '+', 'x', '1'], 0.1, 9, \"complicated\"),\n    ]\n    \n    for sol in solutions:\n        added = front.add(sol)\n        print(f\"Added {sol.formula}: {added}\")\n    \n    front.summary()\n    \n    print(f\"\\nBest by RMSE: {front.get_best_by_rmse()}\")\n    print(f\"Simplest: {front.get_simplest()}\")\n    print(f\"Balanced: {front.get_balanced()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile search/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_core.py\n",
        "\"\"\"\nCore state and model management for AlphaSymbolic Gradio App.\n\"\"\"\nimport torch\nimport os\nfrom core.model import AlphaSymbolicModel\nfrom core.grammar import VOCABULARY\n\n# Global state\nMODEL = None\nDEVICE = None\nTRAINING_STATUS = {\"running\": False, \"epoch\": 0, \"loss\": 0, \"message\": \"Listo\"}\n\nMODEL_PRESETS = {\n    'lite': {'d_model': 128, 'nhead': 4, 'num_encoder_layers': 3, 'num_decoder_layers': 3},\n    'pro': {'d_model': 256, 'nhead': 8, 'num_encoder_layers': 6, 'num_decoder_layers': 6}\n}\nCURRENT_PRESET = 'pro'\n\ndef get_device(force_cpu=False):\n    \"\"\"Get the best available device (CUDA > MPS > CPU).\"\"\"\n    if force_cpu:\n        return torch.device(\"cpu\")\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n        return torch.device(\"mps\")\n    return torch.device(\"cpu\")\n\ndef set_device(use_gpu=True):\n    \"\"\"Set the device (GPU or CPU).\"\"\"\n    global DEVICE, MODEL\n    new_device = get_device(force_cpu=not use_gpu)\n    \n    if MODEL is not None and DEVICE != new_device:\n        MODEL = MODEL.to(new_device)\n    \n    DEVICE = new_device\n    return get_device_info()\n\ndef get_device_info():\n    \"\"\"Get device info string.\"\"\"\n    global DEVICE\n    if DEVICE is None:\n        DEVICE = get_device()\n    \n    if DEVICE.type == \"cuda\":\n        return f\"CUDA ({torch.cuda.get_device_name(0)})\"\n    elif DEVICE.type == \"mps\":\n        return \"MPS (Apple Silicon)\"\n    else:\n        return \"CPU\"\n\ndef load_model(force_reload=False, preset_name=None):\n    \"\"\"Load or reload the model.\"\"\"\n    global MODEL, DEVICE, CURRENT_PRESET\n    \n    if preset_name:\n        CURRENT_PRESET = preset_name\n    \n    if DEVICE is None:\n        DEVICE = get_device()\n    \n    VOCAB_SIZE = len(VOCABULARY)\n    config = MODEL_PRESETS[CURRENT_PRESET]\n    \n    print(f\"Loading Model [{CURRENT_PRESET.upper()}]...\")\n    MODEL = AlphaSymbolicModel(\n        vocab_size=VOCAB_SIZE + 1, \n        d_model=config['d_model'], \n        nhead=config['nhead'],\n        num_encoder_layers=config['num_encoder_layers'], \n        num_decoder_layers=config['num_decoder_layers']\n    ).to(DEVICE)\n    \n    filename = f\"alpha_symbolic_model_{CURRENT_PRESET}.pth\"\n    status = f\"Nuevo modelo ({CURRENT_PRESET})\" # Default status\n    \n    if os.path.exists(filename):\n        try:\n            state_dict = torch.load(filename, map_location=DEVICE, weights_only=True)\n            \n            # Check for NaNs\n            has_nans = False\n            for k, v in state_dict.items():\n                if torch.isnan(v).any() or torch.isinf(v).any():\n                    has_nans = True\n                    break\n            \n            if has_nans:\n                print(f\"\u26a0\ufe0f Modelo corrupto detectado (NaNs) en {filename}. Eliminando y esperando reinicio.\")\n                try:\n                    os.remove(filename)\n                    print(\"\u2705 Archivo corrupto eliminado.\")\n                except OSError as e:\n                    print(f\"Error al eliminar archivo: {e}\")\n                status = \"\u26a0\ufe0f Modelo corrupto eliminado y reiniciado\"\n            else:\n                MODEL.load_state_dict(state_dict)\n                MODEL.eval()\n                status = f\"Modelo cargado ({CURRENT_PRESET})\"\n                \n        except RuntimeError as e:\n            print(f\"\u26a0\ufe0f Error de compatibilidad ({e}). Iniciando modelo fresco.\")\n            status = f\"Nuevo modelo ({CURRENT_PRESET})\"\n        except Exception as e:\n            print(f\"Error cargando: {e}\")\n            status = \"Sin modelo pre-entrenado\"\n    \n    return status, get_device_info()\n\ndef get_model():\n    \"\"\"Get the current model, loading if needed.\"\"\"\n    global MODEL, DEVICE\n    if MODEL is None:\n        load_model()\n    return MODEL, DEVICE\n\ndef save_model():\n    \"\"\"Save the current model.\"\"\"\n    global MODEL, CURRENT_PRESET\n    if MODEL is not None:\n        filename = f\"alpha_symbolic_model_{CURRENT_PRESET}.pth\"\n        torch.save(MODEL.state_dict(), filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_search.py\n",
        "\"\"\"\nSearch/Solve functions for AlphaSymbolic Gradio App.\nSupports both Beam Search and MCTS.\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport gradio as gr\n\nfrom core.grammar import ExpressionTree\nfrom search.beam_search import BeamSearch\nfrom search.mcts import MCTS\nfrom utils.simplify import simplify_tree\nfrom search.pareto import ParetoFront\nfrom utils.detect_pattern import detect_pattern\nfrom utils.optimize_constants import optimize_constants, substitute_constants\nfrom ui.app_core import get_model\n\n\ndef parse_data(x_str, y_str):\n    \"\"\"Parse comma-separated input strings.\"\"\"\n    try:\n        x = np.array([float(v.strip()) for v in x_str.split(',')], dtype=np.float64)\n        y = np.array([float(v.strip()) for v in y_str.split(',')], dtype=np.float64)\n        if len(x) != len(y):\n            return None, None, \"Error: X e Y deben tener igual longitud\"\n        return x, y, None\n    except Exception as e:\n        return None, None, f\"Error: {str(e)}\"\n\n\ndef create_fit_plot(x, y, y_pred, formula):\n    \"\"\"Create a plot showing data vs prediction.\"\"\"\n    fig, ax = plt.subplots(figsize=(8, 5), facecolor='#1a1a2e')\n    ax.set_facecolor('#1a1a2e')\n    \n    ax.scatter(x, y, color='#00d4ff', s=100, label='Datos Reales', zorder=3, edgecolors='white', linewidth=1)\n    \n    sort_idx = np.argsort(x)\n    ax.plot(x[sort_idx], y_pred[sort_idx], color='#ff6b6b', linewidth=3, label='Prediccion', zorder=2)\n    \n    ax.set_xlabel('X', color='white', fontsize=12)\n    ax.set_ylabel('Y', color='white', fontsize=12)\n    ax.set_title('Ajuste de la Formula', color='white', fontsize=14, fontweight='bold')\n    ax.legend(facecolor='#16213e', edgecolor='#00d4ff', labelcolor='white')\n    ax.tick_params(colors='white')\n    ax.grid(True, alpha=0.2, color='white')\n    \n    for spine in ax.spines.values():\n        spine.set_color('#00d4ff')\n    \n    plt.tight_layout()\n    return fig\n\n\ndef solve_formula(x_str, y_str, beam_width, search_method, progress=gr.Progress()):\n    \"\"\"Main solving function with search method selection.\"\"\"\n    x, y, error = parse_data(x_str, y_str)\n    if error:\n        return error, None, \"\", \"\", \"\"\n    \n    MODEL, DEVICE = get_model()\n    \n    progress(0.1, desc=f\"Analizando patron... [{DEVICE.type.upper()}]\")\n    pattern = detect_pattern(x, y)\n    \n    progress(0.3, desc=f\"Buscando formulas ({search_method})... [{DEVICE.type.upper()}]\")\n    start_time = time.time()\n    \n    results = []\n    \n    if search_method == \"Beam Search\":\n        searcher = BeamSearch(MODEL, DEVICE, beam_width=int(beam_width), max_length=25)\n        results = searcher.search(x, y)\n    else:  # MCTS\n        mcts = MCTS(MODEL, DEVICE, max_simulations=int(beam_width) * 10)\n        result = mcts.search(x, y)\n        if result and result.get('tokens'):\n            tokens = result['tokens']\n            tree = ExpressionTree(tokens)\n            if tree.is_valid:\n                constants, rmse = optimize_constants(tree, x, y)\n                results = [{\n                    'tokens': tokens,\n                    'formula': tree.get_infix(),\n                    'rmse': rmse,\n                    'constants': constants\n                }]\n    \n    search_time = time.time() - start_time\n    \n    if not results:\n        return \"No se encontraron formulas validas\", None, \"\", \"\", \"\"\n    \n    progress(0.7, desc=\"Optimizando constantes...\")\n    pareto = ParetoFront()\n    pareto.add_from_results(results)\n    best = pareto.get_best_by_rmse()\n    \n    if not best:\n        return \"Error en optimizacion\", None, \"\", \"\", \"\"\n    \n    progress(0.9, desc=\"Simplificando...\")\n    tree = ExpressionTree(best.tokens)\n    simplified = simplify_tree(tree)\n    y_pred = tree.evaluate(x, constants=best.constants)\n    \n    # Substitute constants for display\n    substituted_formula = simplified\n    if best.constants:\n        try:\n            positions = tree.root.get_constant_positions()\n            # We use the raw infix for substitution to ensure matching C positions\n            raw_infix = tree.get_infix()\n            substituted_formula = substitute_constants(raw_infix, best.constants, positions)\n        except:\n            substituted_formula = simplified\n    \n    fig = create_fit_plot(x, y, y_pred, simplified)\n    \n    # Format results\n    result_html = f\"\"\"\n    <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #00d4ff;\">\n        <h2 style=\"color: #00d4ff; margin: 0; font-size: 24px;\">Formula Encontrada</h2>\n        <div style=\"background: #0f0f23; padding: 15px; border-radius: 10px; margin: 15px 0; border-left: 4px solid #ff6b6b;\">\n            <code style=\"color: #ff6b6b; font-size: 28px; font-weight: bold;\">{substituted_formula}</code>\n        </div>\n        <div style=\"display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px;\">\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">RMSE</span><br>\n                <span style=\"color: #00d4ff; font-size: 16px; font-weight: bold;\">{best.rmse:.6f}</span>\n            </div>\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">Nodos</span><br>\n                <span style=\"color: #00d4ff; font-size: 16px; font-weight: bold;\">{best.complexity}</span>\n            </div>\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">Tiempo</span><br>\n                <span style=\"color: #00d4ff; font-size: 16px; font-weight: bold;\">{search_time:.2f}s</span>\n            </div>\n            <div style=\"background: #0f0f23; padding: 10px; border-radius: 8px; text-align: center;\">\n                <span style=\"color: #888;\">Metodo</span><br>\n                <span style=\"color: #4ade80; font-size: 16px; font-weight: bold;\">{search_method}</span>\n            </div>\n        </div>\n        <div style=\"margin-top: 15px; padding: 10px; background: #0f0f23; border-radius: 8px;\">\n            <span style=\"color: #888;\">Patron:</span> \n            <span style=\"color: #ffd93d;\">{pattern['type']}</span> \n            <span style=\"color: #666;\">({pattern['confidence']:.0%})</span>\n            <span style=\"color: #888; margin-left: 20px;\">Device:</span>\n            <span style=\"color: #4ade80;\">{DEVICE.type.upper()}</span>\n        </div>\n    \"\"\"\n    \n    # Add constants if any\n    # Add constants if any\n    if best.constants:\n        # Sort and format cleanly\n        sorted_items = sorted(best.constants.items(), key=lambda x: str(x[0]))\n        clean_consts = []\n        for i, (k, v) in enumerate(sorted_items):\n            clean_consts.append(f\"C_{i+1}: {v:.4f}\")\n        const_str = \"  |  \".join(clean_consts)\n        \n        result_html += f\"\"\"\n        <div style=\"margin-top: 10px; padding: 10px; background: #0f0f23; border-radius: 8px; border-left: 3px solid #ffd93d;\">\n            <span style=\"color: #888;\">Constantes:</span>\n            <span style=\"color: #fff; font-family: monospace; margin-left: 10px;\">{const_str}</span>\n        </div>\n        \"\"\"\n        \n    result_html += \"</div>\"\n    \n    # Predictions table\n    pred_html = '<table style=\"width: 100%; border-collapse: collapse; background: #1a1a2e; border-radius: 10px; overflow: hidden;\">'\n    pred_html += '<tr style=\"background: #16213e;\"><th style=\"padding: 10px; color: #00d4ff;\">X</th><th style=\"color: #00d4ff;\">Pred</th><th style=\"color: #00d4ff;\">Real</th><th style=\"color: #00d4ff;\">Delta</th></tr>'\n    for i in range(min(50, len(x))):\n        delta = abs(y_pred[i] - y[i])\n        color = \"#4ade80\" if delta < 0.1 else \"#fbbf24\" if delta < 1 else \"#ef4444\"\n        pred_html += f'<tr style=\"border-bottom: 1px solid #333;\"><td style=\"padding: 8px; color: white; text-align: center;\">{x[i]:.2f}</td><td style=\"color: white; text-align: center;\">{y_pred[i]:.4f}</td><td style=\"color: white; text-align: center;\">{y[i]:.4f}</td><td style=\"color: {color}; text-align: center; font-weight: bold;\">{delta:.4f}</td></tr>'\n    pred_html += '</table>'\n    \n    # Alternatives\n    alt_html = '<div style=\"background: #1a1a2e; padding: 15px; border-radius: 10px;\">'\n    alt_html += '<h4 style=\"color: #00d4ff; margin-top: 0;\">Alternativas</h4>'\n    for i, sol in enumerate(pareto.solutions[:4]):\n        alt_html += f'<div style=\"padding: 5px 10px; margin: 5px 0; background: #0f0f23; border-radius: 5px; border-left: 3px solid {\"#00d4ff\" if i == 0 else \"#666\"};\"><code style=\"color: {\"#ff6b6b\" if i == 0 else \"#888\"};\">{sol.formula}</code> <span style=\"color: #666; font-size: 12px;\">RMSE: {sol.rmse:.4f}</span></div>'\n    alt_html += '</div>'\n    \n    return result_html, fig, pred_html, alt_html, simplified\n\n\ndef generate_example(tipo):\n    \"\"\"Generate example data.\"\"\"\n    if tipo == \"lineal\":\n        x = np.linspace(1, 10, 10)\n        y = 2 * x + 3\n    elif tipo == \"cuadratico\":\n        x = np.linspace(-5, 5, 11)\n        y = x**2 + 1\n    elif tipo == \"trig\":\n        x = np.linspace(0, 6.28, 20)\n        y = np.sin(x)\n    elif tipo == \"exp\":\n        x = np.linspace(0, 5, 15)\n        y = 2 * np.exp(0.5 * x)\n    else:\n        x = np.linspace(1, 10, 10)\n        y = 2 * x + 3\n    \n    return \", \".join([f\"{v:.2f}\" for v in x]), \", \".join([f\"{v:.4f}\" for v in y])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_training.py\n",
        "\"\"\"\nTraining functions for AlphaSymbolic Gradio App.\nWith proper data normalization.\n\"\"\"\nimport os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport gradio as gr\nfrom collections import deque\nimport random\n\nfrom core.grammar import VOCABULARY, TOKEN_TO_ID\nfrom data.synthetic_data import DataGenerator\nfrom ui.app_core import get_model, save_model, TRAINING_STATUS\n\n\ndef normalize_batch(x_list, y_list):\n    \"\"\"Normalize X and Y values to prevent numerical instability.\"\"\"\n    normalized_x = []\n    normalized_y = []\n    \n    for x, y in zip(x_list, y_list):\n        # Normalize X to [-1, 1]\n        x_min, x_max = x.min(), x.max()\n        if x_max - x_min > 1e-6:\n            x_norm = 2 * (x - x_min) / (x_max - x_min) - 1\n        else:\n            x_norm = np.zeros_like(x)\n        \n        # Normalize Y to [-1, 1] \n        y_min, y_max = y.min(), y.max()\n        if y_max - y_min > 1e-6:\n            y_norm = 2 * (y - y_min) / (y_max - y_min) - 1\n        else:\n            y_norm = np.zeros_like(y)\n        \n        normalized_x.append(x_norm)\n        normalized_y.append(y_norm)\n    \n    return normalized_x, normalized_y\n\n\ndef train_basic(epochs, batch_size, point_count=10, progress=gr.Progress()):\n    \"\"\"Basic training with synthetic data.\"\"\"\n    global TRAINING_STATUS\n    \n    if TRAINING_STATUS[\"running\"]:\n        return \"Entrenamiento ya en progreso\", None\n    \n    TRAINING_STATUS[\"running\"] = True\n    \n    try:\n        MODEL, DEVICE = get_model()\n        \n        MODEL.train()\n        optimizer = torch.optim.AdamW(MODEL.parameters(), lr=1e-4, weight_decay=0.01)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(epochs), eta_min=1e-6)\n        ce_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        \n        VOCAB_SIZE = len(VOCABULARY)\n        SOS_ID = VOCAB_SIZE\n        \n        data_gen = DataGenerator(max_depth=4)\n        losses = []\n        \n        for epoch in range(int(epochs)):\n            progress((epoch + 1) / epochs, desc=f\"Epoca {epoch+1}/{int(epochs)} [{DEVICE.type.upper()}]\")\n            \n            # Mix of inverse (known formulas) + random data (AlphaTensor-style)\n            half_batch = int(batch_size) // 2\n            batch_inverse = data_gen.generate_inverse_batch(half_batch, point_count=int(point_count))\n            batch_random = data_gen.generate_batch(int(batch_size) - half_batch, point_count=int(point_count))\n            batch = batch_inverse + batch_random\n            if len(batch) < 2:\n                continue\n            \n            x_list = [d['x'] for d in batch]\n            y_list = [d['y'] for d in batch]\n            \n            # Normalize data\n            x_list, y_list = normalize_batch(x_list, y_list)\n            \n            token_lists = [[TOKEN_TO_ID[t] for t in d['tokens']] for d in batch]\n            \n            max_len = max(len(s) for s in token_lists)\n            decoder_input = torch.full((len(batch), max_len + 1), SOS_ID, dtype=torch.long)\n            targets = torch.full((len(batch), max_len + 1), -1, dtype=torch.long)\n            \n            for i, seq in enumerate(token_lists):\n                decoder_input[i, 1:len(seq)+1] = torch.tensor(seq, dtype=torch.long)\n                targets[i, :len(seq)] = torch.tensor(seq, dtype=torch.long)\n            \n            x_tensor = torch.tensor(np.array(x_list), dtype=torch.float32).to(DEVICE)\n            y_tensor = torch.tensor(np.array(y_list), dtype=torch.float32).to(DEVICE)\n            decoder_input = decoder_input.to(DEVICE)\n            targets = targets.to(DEVICE)\n            \n            # Forward\n            optimizer.zero_grad()\n            logits, _ = MODEL(x_tensor, y_tensor, decoder_input)\n            loss = ce_loss(logits.view(-1, VOCAB_SIZE + 1), targets.view(-1))\n            \n            # Skip if loss is NaN\n            if torch.isnan(loss) or torch.isinf(loss):\n                continue\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(MODEL.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            losses.append(loss.item())\n        \n        save_model()\n        MODEL.eval()\n        TRAINING_STATUS[\"running\"] = False\n        \n        if not losses:\n            return \"Error: No se pudo calcular loss (revisar datos)\", None\n        \n        fig = create_loss_plot(losses, \"Entrenamiento Basico\")\n        \n        result = f\"\"\"\n        <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #4ade80;\">\n            <h2 style=\"color: #4ade80; margin: 0;\">Entrenamiento Completado</h2>\n            <p style=\"color: white;\">Epocas: {int(epochs)} | Loss Final: {losses[-1]:.4f}</p>\n            <p style=\"color: #00d4ff;\">Dispositivo: {DEVICE.type.upper()}</p>\n        </div>\n        \"\"\"\n        return result, fig\n        \n    except Exception as e:\n        TRAINING_STATUS[\"running\"] = False\n        return f\"Error: {str(e)}\", None\n\n\ndef train_curriculum(epochs, batch_size, point_count=10, progress=gr.Progress()):\n    \"\"\"Curriculum Learning - starts simple, increases difficulty gradually.\"\"\"\n    global TRAINING_STATUS\n    \n    if TRAINING_STATUS[\"running\"]:\n        return \"Entrenamiento ya en progreso\", None\n    \n    TRAINING_STATUS[\"running\"] = True\n    \n    try:\n        MODEL, DEVICE = get_model()\n        \n        MODEL.train()\n        optimizer = torch.optim.AdamW(MODEL.parameters(), lr=5e-5, weight_decay=0.01)  # Lower LR\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2)\n        ce_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n        \n        VOCAB_SIZE = len(VOCABULARY)\n        SOS_ID = VOCAB_SIZE\n        losses = []\n        \n        for epoch in range(int(epochs)):\n            # Curriculum: slow progression\n            # Stage 1 (0-50%): depth 2-3, 80% inverse data\n            # Stage 2 (50-80%): depth 3-4, 50% inverse data  \n            # Stage 3 (80-100%): depth 4-5, 20% inverse data\n            progress_pct = epoch / epochs\n            \n            if progress_pct < 0.5:\n                current_depth = 2 + int(progress_pct * 2)  # 2-3\n                inverse_ratio = 0.8\n            elif progress_pct < 0.8:\n                current_depth = 3 + int((progress_pct - 0.5) * 3.3)  # 3-4\n                inverse_ratio = 0.5\n            else:\n                current_depth = 4 + int((progress_pct - 0.8) * 5)  # 4-5\n                inverse_ratio = 0.2\n            \n            progress((epoch + 1) / epochs, desc=f\"Epoca {epoch+1}/{int(epochs)} (prof: {current_depth}, inv: {inverse_ratio:.0%}) [{DEVICE.type.upper()}]\")\n            \n            data_gen = DataGenerator(max_depth=current_depth)\n            \n            # Mix inverse + random based on curriculum stage\n            n_inverse = int(batch_size * inverse_ratio)\n            n_random = int(batch_size) - n_inverse\n            \n            batch_inverse = data_gen.generate_inverse_batch(max(1, n_inverse), point_count=int(point_count)) if n_inverse > 0 else []\n            batch_random = data_gen.generate_batch(max(1, n_random), point_count=int(point_count)) if n_random > 0 else []\n            batch = batch_inverse + batch_random\n            if len(batch) < 2:\n                continue\n            \n            x_list = [d['x'] for d in batch]\n            y_list = [d['y'] for d in batch]\n            x_list, y_list = normalize_batch(x_list, y_list)\n            \n            token_lists = [[TOKEN_TO_ID[t] for t in d['tokens']] for d in batch]\n            \n            max_len = max(len(s) for s in token_lists)\n            decoder_input = torch.full((len(batch), max_len + 1), SOS_ID, dtype=torch.long)\n            targets = torch.full((len(batch), max_len + 1), -1, dtype=torch.long)\n            \n            for i, seq in enumerate(token_lists):\n                decoder_input[i, 1:len(seq)+1] = torch.tensor(seq, dtype=torch.long)\n                targets[i, :len(seq)] = torch.tensor(seq, dtype=torch.long)\n            \n            x_tensor = torch.tensor(np.array(x_list), dtype=torch.float32).to(DEVICE)\n            y_tensor = torch.tensor(np.array(y_list), dtype=torch.float32).to(DEVICE)\n            decoder_input = decoder_input.to(DEVICE)\n            targets = targets.to(DEVICE)\n            \n            optimizer.zero_grad()\n            logits, value_pred = MODEL(x_tensor, y_tensor, decoder_input)\n            \n            # Policy Loss\n            loss_policy = ce_loss(logits.view(-1, VOCAB_SIZE + 1), targets.view(-1))\n            \n            # Value Loss\n            # For supervised learning, these are \"perfect\" solutions, so Value Target = 1.0\n            value_targets = torch.ones_like(value_pred)\n            loss_value = torch.nn.functional.mse_loss(value_pred, value_targets)\n            \n            # Combined Loss\n            loss = loss_policy + 0.5 * loss_value\n            \n            if torch.isnan(loss) or torch.isinf(loss):\n                continue\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(MODEL.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            losses.append(loss.item())\n        \n        save_model()\n        MODEL.eval()\n        TRAINING_STATUS[\"running\"] = False\n        \n        if not losses:\n            return \"Error: No se pudo calcular loss\", None\n        \n        fig = create_loss_plot(losses, \"Curriculum Learning\")\n        \n        result = f\"\"\"\n        <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #00d4ff;\">\n            <h2 style=\"color: #00d4ff; margin: 0;\">Curriculum Learning Completado</h2>\n            <p style=\"color: white;\">Epocas: {int(epochs)} | Loss Final: {losses[-1]:.4f}</p>\n            <p style=\"color: #888;\">Profundidad maxima: 6 | Dispositivo: {DEVICE.type.upper()}</p>\n        </div>\n        \"\"\"\n        return result, fig\n        \n    except Exception as e:\n        TRAINING_STATUS[\"running\"] = False\n        return f\"Error: {str(e)}\", None\n\n\ndef train_self_play(iterations, problems_per_iter, point_count=10, progress=gr.Progress()):\n    \"\"\"AlphaZero Self-Play loop.\"\"\"\n    global TRAINING_STATUS\n    \n    if TRAINING_STATUS[\"running\"]:\n        return \"Entrenamiento ya en progreso\", None\n    \n    TRAINING_STATUS[\"running\"] = True\n    \n    try:\n        MODEL, DEVICE = get_model()\n        \n        from search.mcts import MCTS\n        \n        optimizer = torch.optim.AdamW(MODEL.parameters(), lr=1e-4, weight_decay=0.01)\n        \n        # Losses for AlphaZero\n        # Policy: KLDiv (comparing distributions)\n        # Value: MSE (comparing scalar values)\n        kl_loss = torch.nn.KLDivLoss(reduction='batchmean')\n        mse_loss = torch.nn.MSELoss()\n        \n        VOCAB_SIZE = len(VOCABULARY)\n        SOS_ID = VOCAB_SIZE\n        \n        replay_buffer = deque(maxlen=20000)\n        \n        # Adaptive Curriculum State\n        current_depth = 2\n        data_gen = DataGenerator(max_depth=current_depth)\n        \n        # MCTS for A100: Increase batch size and simulations significantly\n        searcher = MCTS(MODEL, DEVICE, max_simulations=500, complexity_lambda=0.1, batch_size=256)\n        \n        rmses = []\n        losses = []\n        best_avg_rmse = float('inf')\n        \n        for iteration in range(int(iterations)):\n            # Adaptive Curriculum Check\n            # If average RMSE of last 20 episodes is very low (< 0.05), increase difficulty\n            recent_rmse = np.mean(rmses[-20:]) if len(rmses) >= 20 else 1.0\n            if len(rmses) > 20 and recent_rmse < 0.1 and current_depth < 7:\n                current_depth += 1\n                data_gen = DataGenerator(max_depth=current_depth)\n                print(f\"Curriculum Level Up! New Depth: {current_depth}\")\n                \n            progress((iteration + 1) / iterations, desc=f\"Iter {iteration+1}/{int(iterations)} [D:{current_depth}] RMSE:{recent_rmse:.3f}\")\n            \n            # Self-play phase\n            MODEL.eval()\n            \n            # Generate mix of problems: 70% inverse (solvable), 30% random\n            n_inverse = int(problems_per_iter * 0.7)\n            n_random = int(problems_per_iter) - n_inverse\n            \n            probs_inv = data_gen.generate_inverse_batch(n_inverse, point_count=int(point_count)) if n_inverse > 0 else []\n            probs_rnd = data_gen.generate_batch(n_random, point_count=int(point_count)) if n_random > 0 else []\n            problems = probs_inv + probs_rnd\n            \n            for prob in problems:\n                x_data = prob['x'].astype(np.float64)\n                y_data = prob['y'].astype(np.float64)\n                \n                try:\n                    result = searcher.search(x_data, y_data)\n                    \n                    # 1. Store Training Examples (State, Policy, Value)\n                    if 'root' in result:\n                        examples = searcher.get_training_examples(result['root'])\n                        for (tokens, policy, value) in examples:\n                            replay_buffer.append({\n                                'x': x_data, 'y': y_data,\n                                'tokens': tokens,\n                                'policy': policy,\n                                'value': value\n                            })\n                    \n                    # 2. Track Metrics\n                    if result.get('tokens'):\n                        rmses.append(result['rmse'])\n                        \n                except Exception as e:\n                    print(f\"Self-play error: {e}\")\n                    continue\n            \n            # Training phase\n            if len(replay_buffer) >= 64:\n                MODEL.train()\n                # Train multiple steps per iteration to learn efficiently\n                for _ in range(4):\n                    batch = random.sample(list(replay_buffer), min(64, len(replay_buffer)))\n                    \n                    x_list = [exp['x'] for exp in batch]\n                    y_list = [exp['y'] for exp in batch]\n                    x_list, y_list = normalize_batch(x_list, y_list)\n                    \n                    token_lists = [[TOKEN_TO_ID[t] for t in exp['tokens']] for exp in batch]\n                    policy_targets = [exp['policy'] for exp in batch]\n                    value_targets_list = [exp['value'] for exp in batch]\n                    \n                    max_len = max(len(s) for s in token_lists)\n                    decoder_input = torch.full((len(batch), max_len + 1), SOS_ID, dtype=torch.long)\n                    \n                    # Policy targets (for KLDiv) and Value targets\n                    policy_target_tensor = torch.tensor(np.array(policy_targets), dtype=torch.float32).to(DEVICE)\n                    value_target_tensor = torch.tensor(np.array(value_targets_list), dtype=torch.float32).unsqueeze(1).to(DEVICE)\n                    \n                    for i, seq in enumerate(token_lists):\n                        l = len(seq)\n                        decoder_input[i, 1:l+1] = torch.tensor(seq, dtype=torch.long)\n                    \n                    x_tensor = torch.tensor(np.array(x_list), dtype=torch.float32).to(DEVICE)\n                    y_tensor = torch.tensor(np.array(y_list), dtype=torch.float32).to(DEVICE)\n                    decoder_input = decoder_input.to(DEVICE)\n                    \n                    optimizer.zero_grad()\n                    logits, value_pred = MODEL(x_tensor, y_tensor, decoder_input)\n                    \n                    # Policy Loss (KL Divergence)\n                    # Get logits for the last token position of each sequence\n                    last_logits = []\n                    for i, seq in enumerate(token_lists):\n                        idx = len(seq) # Post-padding index? No, index in padded tensor.\n                        # decoder_input: [SOS, T1, T2]\n                        # logits: [PredSOS, PredT1, PredT2]\n                        # We want prediction AFTER T2? No.\n                        # MCTS Example: State=[T1, T2]. Policy=Dist for T3.\n                        # Model Input: [SOS, T1, T2]. Output Last: Dist for T3.\n                        # Index is len(seq).\n                        last_logits.append(logits[i, idx, :VOCAB_SIZE])\n                    \n                    last_logits = torch.stack(last_logits)\n                    log_probs = torch.nn.functional.log_softmax(last_logits, dim=1)\n                    \n                    loss_policy = kl_loss(log_probs, policy_target_tensor)\n                    \n                    # Value Loss (MSE)\n                    loss_value = mse_loss(value_pred, value_target_tensor)\n                    \n                    # Total Loss\n                    loss = loss_policy + loss_value \n                    \n                    if not (torch.isnan(loss) or torch.isinf(loss)):\n                        loss.backward()\n                        torch.nn.utils.clip_grad_norm_(MODEL.parameters(), 1.0)\n                        optimizer.step()\n                        losses.append(loss.item())\n            \n            # Periodic save\n            if (iteration + 1) % 10 == 0:\n                save_model()\n        \n        save_model()\n        MODEL.eval()\n        TRAINING_STATUS[\"running\"] = False\n        \n        fig = create_selfplay_plot(losses, rmses)\n        \n        avg_rmse = np.mean(rmses[-50:]) if rmses else 0\n        result = f\"\"\"\n        <div style=\"background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); padding: 20px; border-radius: 15px; border: 2px solid #ff6b6b;\">\n            <h2 style=\"color: #ff6b6b; margin: 0;\">Self-Play Completado</h2>\n            <p style=\"color: white;\">Iteraciones: {int(iterations)} | Problemas: {len(rmses)}</p>\n            <p style=\"color: #888;\">RMSE Promedio: {avg_rmse:.4f} | Dispositivo: {DEVICE.type.upper()}</p>\n        </div>\n        \"\"\"\n        return result, fig\n        \n    except Exception as e:\n        TRAINING_STATUS[\"running\"] = False\n        return f\"Error: {str(e)}\", None\n\n\ndef create_loss_plot(losses, title):\n    \"\"\"Create a loss plot with dark theme.\"\"\"\n    fig, ax = plt.subplots(figsize=(8, 4), facecolor='#1a1a2e')\n    ax.set_facecolor('#1a1a2e')\n    ax.plot(losses, color='#00d4ff', linewidth=2)\n    ax.set_xlabel('Epoca', color='white')\n    ax.set_ylabel('Loss', color='white')\n    ax.set_title(title, color='white', fontweight='bold')\n    ax.tick_params(colors='white')\n    ax.grid(True, alpha=0.2)\n    for spine in ax.spines.values():\n        spine.set_color('#00d4ff')\n    plt.tight_layout()\n    return fig\n\n\ndef create_selfplay_plot(losses, rmses):\n    \"\"\"Create dual plot for self-play results.\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4), facecolor='#1a1a2e')\n    \n    ax1.set_facecolor('#1a1a2e')\n    if losses:\n        ax1.plot(losses, color='#00d4ff', linewidth=2)\n    ax1.set_xlabel('Step', color='white')\n    ax1.set_ylabel('Loss', color='white')\n    ax1.set_title('Policy Loss', color='white', fontweight='bold')\n    ax1.tick_params(colors='white')\n    ax1.grid(True, alpha=0.2)\n    \n    ax2.set_facecolor('#1a1a2e')\n    if rmses:\n        ax2.plot(rmses, color='#ff6b6b', linewidth=1, alpha=0.5)\n        if len(rmses) > 10:\n            ma = np.convolve(rmses, np.ones(10)/10, mode='valid')\n            ax2.plot(range(9, len(rmses)), ma, color='#ff6b6b', linewidth=2)\n    ax2.set_xlabel('Problema', color='white')\n    ax2.set_ylabel('RMSE', color='white')\n    ax2.set_title('RMSE', color='white', fontweight='bold')\n    ax2.tick_params(colors='white')\n    ax2.grid(True, alpha=0.2)\n    \n    for ax in [ax1, ax2]:\n        for spine in ax.spines.values():\n            spine.set_color('#00d4ff')\n    \n    plt.tight_layout()\n    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/app_benchmark.py\n",
        "import gradio as gr\nfrom utils.benchmark_runner import run_benchmark_suite\nfrom ui.app_core import get_model, DEVICE\n\ndef get_benchmark_tab():\n    with gr.Tab(\"\ud83e\udd47 Benchmark (IQ Test)\"):\n        gr.Markdown(\"### Evaluar Inteligencia del Modelo\")\n        gr.Markdown(\"Ejecuta una bater\u00eda de **10 problemas est\u00e1ndar** para medir qu\u00e9 tanto ha aprendido el modelo.\")\n        \n        run_btn = gr.Button(\"\ud83d\ude80 Iniciar Examen\", variant=\"primary\")\n        \n        progress_bar = gr.HTML(\"\")\n        \n        with gr.Row():\n            score_box = gr.Number(label=\"Puntuaci\u00f3n (/100)\", interactive=False)\n            time_box = gr.Number(label=\"Tiempo Promedio (s)\", interactive=False)\n            \n        results_df = gr.Dataframe(\n            headers=[\"Nivel\", \"Nombre\", \"Formula Encontrada\", \"RMSE\", \"Estado\", \"Tiempo\"],\n            label=\"Resultados Detallados\",\n            interactive=False\n        )\n        \n        def run_bench(progress=gr.Progress()):\n            model_obj, device_obj = get_model()\n            if not model_obj:\n                return \"<div>Error: Modelo no cargado</div>\", 0, 0, []\n            \n            results, summary = run_benchmark_suite(\n                model_obj, \n                device_obj, \n                progress_callback=lambda p, desc: progress(p, desc=desc)\n            )\n            \n            # Format dataframe\n            rows = []\n            for r in results:\n                rows.append([\n                    r['level'],\n                    r['name'],\n                    r['found_formula'],\n                    f\"{r['rmse']:.5f}\",\n                    r['status'],\n                    f\"{r['time']:.2f}s\"\n                ])\n            \n            # Color score\n            color = \"green\" if summary['score'] > 80 else \"orange\" if summary['score'] > 50 else \"red\"\n            header = f\"\"\"\n            <div style=\"background: #1e1e2f; padding: 20px; border-radius: 10px; text-align: center; border: 2px solid {color};\">\n                <h1 style=\"color: {color}; margin: 0;\">Nota Final: {summary['score']:.1f} / 100</h1>\n                <p style=\"color: #ccc;\">Problemas Resueltos: {summary['solved']} / {summary['total']}</p>\n            </div>\n            \"\"\"\n            \n            return header, summary['score'], summary['avg_time'], rows\n            \n        run_btn.click(run_bench, outputs=[progress_bar, score_box, time_box, results_df])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ui/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/optimize_constants.py\n",
        "\"\"\"\nConstant Optimization Module for AlphaSymbolic.\nUses scipy.optimize to find optimal values for 'C' placeholders.\n\"\"\"\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom core.grammar import ExpressionTree\n\ndef optimize_constants(tree, x_data, y_data, method='L-BFGS-B'):\n    \"\"\"\n    Given an ExpressionTree with 'C' placeholders, find optimal constant values.\n    \n    Args:\n        tree: ExpressionTree object\n        x_data: numpy array of x values\n        y_data: numpy array of target y values\n        method: optimization method ('L-BFGS-B', 'SLSQP', 'Nelder-Mead')\n        \n    Returns:\n        dict: mapping of path tuples to optimized constant values\n        float: final RMSE\n    \"\"\"\n    if not tree.is_valid:\n        return {}, float('inf')\n    \n    # Get positions of all constants\n    positions = tree.root.get_constant_positions()\n    n_constants = len(positions)\n    \n    if n_constants == 0:\n        # No constants to optimize, just evaluate\n        y_pred = tree.evaluate(x_data)\n        mse = np.mean((y_pred - y_data)**2)\n        return {}, np.sqrt(mse)\n    \n    def objective(params):\n        \"\"\"Objective function: RMSE given constant values.\"\"\"\n        # Build constants dict\n        constants = {tuple(pos): params[i] for i, pos in enumerate(positions)}\n        \n        # Evaluate\n        y_pred = tree.evaluate(x_data, constants=constants)\n        \n        # Handle invalid predictions\n        if np.any(np.isnan(y_pred)) or np.any(np.isinf(y_pred)):\n            return 1e10\n        \n        if not np.all(np.isfinite(y_pred)):\n            return 1e9\n        \n        # Clip huge values to prevent overflow in MSE\n        y_pred = np.clip(y_pred, -1e9, 1e9)\n        \n        mse = np.mean((y_pred - y_data)**2)\n        return mse\n    \n    # Initial guess: all 1s\n    x0 = np.ones(n_constants)\n    \n    # Bounds: reasonable range for constants\n    bounds = [(-1000, 1000)] * n_constants\n    \n    try:\n        result = minimize(\n            objective,\n            x0,\n            method=method,\n            bounds=bounds if method in ['L-BFGS-B', 'SLSQP'] else None,\n            options={'maxiter': 1000, 'disp': False}\n        )\n        \n        # Build final constants dict\n        optimized_constants = {tuple(pos): result.x[i] for i, pos in enumerate(positions)}\n        final_rmse = np.sqrt(result.fun) if result.fun > 0 else 0.0\n        \n        return optimized_constants, final_rmse\n        \n    except Exception as e:\n        return {}, float('inf')\n\ndef substitute_constants(infix_str, constants_dict, positions):\n    \"\"\"\n    Replace 'C' in the infix string with optimized values.\n    Simple approach: replace each C with optimized value.\n    \"\"\"\n    # For proper substitution, we'd need to track positions properly\n    # This is a simplified version that replaces all C with the first constant\n    result = infix_str\n    for i, pos in enumerate(positions):\n        if tuple(pos) in constants_dict:\n            val = constants_dict[tuple(pos)]\n            # Format nicely\n            if abs(val - round(val)) < 1e-6:\n                val_str = str(int(round(val)))\n            else:\n                val_str = f\"{val:.4f}\"\n            # Replace first occurrence of C\n            result = result.replace('C', val_str, 1)\n    return result\n\n\n# Quick test\nif __name__ == \"__main__\":\n    # Test: C * x + C should be optimized to fit y = 2*x + 3\n    x_test = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n    y_test = 2 * x_test + 3  # y = 2x + 3\n    \n    tokens = ['+', '*', 'C', 'x', 'C']  # C*x + C\n    tree = ExpressionTree(tokens)\n    \n    print(f\"Formula structure: {tree.get_infix()}\")\n    print(f\"Target: y = 2x + 3\")\n    \n    constants, rmse = optimize_constants(tree, x_test, y_test)\n    print(f\"Optimized constants: {constants}\")\n    print(f\"Final RMSE: {rmse:.6f}\")\n    \n    # Verify\n    y_pred = tree.evaluate(x_test, constants=constants)\n    print(f\"Predictions: {y_pred}\")\n    print(f\"Targets: {y_test}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/detect_pattern.py\n",
        "\"\"\"\nTarget Pattern Detection for AlphaSymbolic.\nAnalyzes target Y values to detect patterns (polynomial, exponential, periodic, etc.)\nand suggests initial search biases.\n\"\"\"\nimport numpy as np\nfrom scipy import stats\nfrom scipy.fft import fft\nfrom core.grammar import ExpressionTree\n\ndef detect_pattern(x_values, y_values):\n    \"\"\"\n    Analyze (x, y) data to detect patterns.\n    Returns a dict with pattern type probabilities and suggested operators.\n    \"\"\"\n    x = np.array(x_values, dtype=np.float64)\n    y = np.array(y_values, dtype=np.float64)\n    \n    results = {\n        'type': 'unknown',\n        'confidence': 0.0,\n        'suggested_ops': [],\n        'details': {}\n    }\n    \n    if len(x) < 3:\n        return results\n    \n    scores = {}\n    \n    # 1. Check for linear pattern (y = ax + b)\n    if len(x) >= 2:\n        slope, intercept, r_value, _, _ = stats.linregress(x, y)\n        scores['linear'] = r_value ** 2\n        results['details']['linear'] = {\n            'slope': slope,\n            'intercept': intercept,\n            'r_squared': r_value ** 2\n        }\n    \n    # 2. Check for quadratic pattern (y = ax^2 + bx + c)\n    if len(x) >= 3:\n        try:\n            coeffs = np.polyfit(x, y, 2)\n            y_pred = np.polyval(coeffs, x)\n            ss_res = np.sum((y - y_pred) ** 2)\n            ss_tot = np.sum((y - np.mean(y)) ** 2)\n            r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n            scores['quadratic'] = r2\n            results['details']['quadratic'] = {\n                'coefficients': coeffs.tolist(),\n                'r_squared': r2\n            }\n        except:\n            pass\n    \n    # 3. Check for exponential pattern (y = a * e^(bx))\n    if np.all(y > 0):  # Exponential only for positive y\n        try:\n            log_y = np.log(y)\n            slope, intercept, r_value, _, _ = stats.linregress(x, log_y)\n            scores['exponential'] = r_value ** 2\n            results['details']['exponential'] = {\n                'a': np.exp(intercept),\n                'b': slope,\n                'r_squared': r_value ** 2\n            }\n        except:\n            pass\n    \n    # 4. Check for periodic/sinusoidal pattern\n    if len(y) >= 4:\n        try:\n            # Simple FFT analysis\n            y_centered = y - np.mean(y)\n            fft_vals = np.abs(fft(y_centered))\n            \n            # Check if there's a dominant frequency\n            if len(fft_vals) > 1:\n                max_idx = np.argmax(fft_vals[1:len(fft_vals)//2]) + 1\n                max_power = fft_vals[max_idx]\n                total_power = np.sum(fft_vals[1:len(fft_vals)//2])\n                \n                if total_power > 0:\n                    periodicity = max_power / total_power\n                    scores['periodic'] = periodicity\n                    results['details']['periodic'] = {\n                        'dominant_freq_idx': int(max_idx),\n                        'periodicity_score': periodicity\n                    }\n        except:\n            pass\n    \n    # 5. Check for power law (y = a * x^b)\n    if np.all(x > 0) and np.all(y > 0):\n        try:\n            log_x = np.log(x)\n            log_y = np.log(y)\n            slope, intercept, r_value, _, _ = stats.linregress(log_x, log_y)\n            scores['power'] = r_value ** 2\n            results['details']['power'] = {\n                'a': np.exp(intercept),\n                'b': slope,\n                'r_squared': r_value ** 2\n            }\n        except:\n            pass\n    \n    # 6. Check for factorial/gamma pattern (for integer-like x)\n    if np.all(x > 0) and np.all(x == np.floor(x)):\n        try:\n            from scipy.special import gamma\n            x_int = x.astype(int)\n            y_gamma = gamma(x_int + 1)  # gamma(n+1) = n!\n            \n            # Simple linear fit between y and gamma\n            if not np.any(np.isinf(y_gamma)):\n                slope, intercept, r_value, _, _ = stats.linregress(y_gamma, y)\n                scores['factorial'] = r_value ** 2\n                results['details']['factorial'] = {\n                    'r_squared': r_value ** 2\n                }\n        except:\n            pass\n    \n    # Determine best pattern\n    if scores:\n        best_pattern = max(scores.items(), key=lambda x: x[1])\n        results['type'] = best_pattern[0]\n        results['confidence'] = best_pattern[1]\n        \n        # Suggest operators based on pattern\n        op_suggestions = {\n            'linear': ['+', '-', '*', 'x', 'C'],\n            'quadratic': ['pow', '+', '*', 'x', 'C', '2'],\n            'exponential': ['exp', '*', '+', 'x', 'C'],\n            'periodic': ['sin', 'cos', '*', '+', 'x', 'C'],\n            'power': ['pow', '*', 'x', 'C'],\n            'factorial': ['gamma', '*', '+', 'x', 'C']\n        }\n        results['suggested_ops'] = op_suggestions.get(best_pattern[0], [])\n    \n    return results\n\n\ndef summarize_pattern(result):\n    \"\"\"Pretty-print pattern detection result.\"\"\"\n    print(f\"\\n=== Pattern Detection ===\")\n    print(f\"Detected Type: {result['type']} (confidence: {result['confidence']:.2%})\")\n    print(f\"Suggested Operators: {', '.join(result['suggested_ops'])}\")\n    \n    if result['type'] in result['details']:\n        print(f\"Details: {result['details'][result['type']]}\")\n\n\nif __name__ == \"__main__\":\n    # Test with different patterns\n    \n    # Linear: y = 2x + 3\n    print(\"\\n--- Test: Linear ---\")\n    x1 = np.linspace(0, 10, 20)\n    y1 = 2 * x1 + 3 + np.random.normal(0, 0.1, 20)\n    result1 = detect_pattern(x1, y1)\n    summarize_pattern(result1)\n    \n    # Quadratic: y = x^2 + 1\n    print(\"\\n--- Test: Quadratic ---\")\n    x2 = np.linspace(-5, 5, 20)\n    y2 = x2**2 + 1\n    result2 = detect_pattern(x2, y2)\n    summarize_pattern(result2)\n    \n    # Exponential: y = 2 * e^(0.5x)\n    print(\"\\n--- Test: Exponential ---\")\n    x3 = np.linspace(0, 5, 20)\n    y3 = 2 * np.exp(0.5 * x3)\n    result3 = detect_pattern(x3, y3)\n    summarize_pattern(result3)\n    \n    # Periodic: y = sin(x)\n    print(\"\\n--- Test: Periodic ---\")\n    x4 = np.linspace(0, 4*np.pi, 50)\n    y4 = np.sin(x4)\n    result4 = detect_pattern(x4, y4)\n    summarize_pattern(result4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/benchmark_runner.py\n",
        "import torch\nimport numpy as np\nimport time\nimport traceback\nfrom search.mcts import MCTS\nfrom data.benchmark_data import BENCHMARK_SUITE, get_benchmark_data\nfrom utils.optimize_constants import optimize_constants\n\ndef run_benchmark_suite(model, device, progress_callback=None):\n    \"\"\"\n    Runs the full benchmark suite.\n    Args:\n        model: Loaded AlphaSymbolic model\n        device: Torch device\n        progress_callback: Function(float, string) to update UI\n        \n    Returns:\n        results: List of result dicts\n        summary: Dict with aggregated stats\n    \"\"\"\n    results = []\n    \n    # Configure MCTS for benchmark (balanced speed/accuracy)\n    # 500 simulations is decent for benchmarking\n    mcts = MCTS(model, device, max_simulations=500, batch_size=32)\n    \n    total = len(BENCHMARK_SUITE)\n    solved_count = 0\n    \n    for i, problem in enumerate(BENCHMARK_SUITE):\n        if progress_callback:\n            progress_callback(i / total, f\"Testing: {problem['name']}...\")\n            \n        x, y, _ = get_benchmark_data(problem['id'])\n        \n        start_time = time.time()\n        \n        # Run Search\n        try:\n            search_result = mcts.search(x, y)\n             # Determine success\n            # Success threshold: RMSE < 0.01 (or 1% relative error)\n            rmse = search_result['rmse']\n            is_solved = rmse < 0.05 # Looser threshold for general regression\n            \n            # Special check for exact integer symbolic match? No, RMSE is ground truth.\n            \n            elapsed = time.time() - start_time\n            \n            if is_solved:\n                solved_count += 1\n                status = \"\u2705 SOLVED\"\n            else:\n                status = \"\u274c FAILED\"\n                \n            results.append({\n                'id': problem['id'],\n                'name': problem['name'],\n                'level': problem['level'],\n                'rmse': rmse,\n                'time': elapsed,\n                'status': status,\n                'found_formula': search_result.get('formula', '???'),\n                'is_solved': is_solved\n            })\n            \n        except Exception as e:\n            print(f\"Error in benchmark {problem['name']}:\")\n            traceback.print_exc()\n            results.append({\n                'id': problem['id'],\n                'name': problem['name'],\n                'level': problem['level'],\n                'rmse': 1e9,\n                'time': 0,\n                'status': \"\u26a0\ufe0f ERROR\",\n                'found_formula': \"Error\",\n                'is_solved': False\n            })\n\n    # Summary\n    if progress_callback:\n        progress_callback(1.0, \"Done!\")\n        \n    score = (solved_count / total) * 100\n    summary = {\n        'total': total,\n        'solved': solved_count,\n        'score': score,\n        'avg_time': np.mean([r['time'] for r in results]) if results else 0\n    }\n    \n    return results, summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/simplify.py\n",
        "\"\"\"\nAlgebraic Simplification Module for AlphaSymbolic.\nUses SymPy for symbolic math simplification.\n\"\"\"\nimport sympy as sp\nfrom core.grammar import Node, ExpressionTree, OPERATORS\n\n# SymPy symbol for x\nx_sym = sp.Symbol('x')\n\ndef tree_to_sympy(node):\n    \"\"\"Convert an ExpressionTree Node to a SymPy expression.\"\"\"\n    if node is None:\n        return sp.Integer(0)\n    \n    val = node.value\n    \n    # Terminals\n    if val == 'x':\n        return x_sym\n    if val == 'pi':\n        return sp.pi\n    if val == 'e':\n        return sp.E\n    if val == 'C':\n        # Keep C as symbol for now\n        return sp.Symbol('C')\n    \n    # Try numeric\n    try:\n        return sp.Float(float(val))\n    except:\n        pass\n    \n    # Operators\n    args = [tree_to_sympy(c) for c in node.children]\n    \n    if val == '+': return args[0] + args[1]\n    if val == '-': return args[0] - args[1]\n    if val == '*': return args[0] * args[1]\n    if val == '/': return args[0] / args[1]\n    if val == 'pow': return sp.Pow(args[0], args[1])\n    if val == 'mod': return sp.Mod(args[0], args[1])\n    if val == 'sin': return sp.sin(args[0])\n    if val == 'cos': return sp.cos(args[0])\n    if val == 'tan': return sp.tan(args[0])\n    if val == 'exp': return sp.exp(args[0])\n    if val == 'log': return sp.log(args[0])\n    if val == 'sqrt': return sp.sqrt(args[0])\n    if val == 'abs': return sp.Abs(args[0])\n    if val == 'floor': return sp.floor(args[0])\n    if val == 'ceil': return sp.ceiling(args[0])\n    if val == 'gamma': return sp.gamma(args[0])\n    if val == 'neg': return -args[0]\n    \n    return sp.Integer(0)\n\ndef sympy_to_infix(expr):\n    \"\"\"Convert SymPy expression back to a readable string.\"\"\"\n    return str(expr)\n\ndef simplify_tree(tree):\n    \"\"\"\n    Takes an ExpressionTree and returns a simplified infix string.\n    \"\"\"\n    if not tree.is_valid:\n        return \"Invalid\"\n    \n    try:\n        sympy_expr = tree_to_sympy(tree.root)\n        simplified = sp.simplify(sympy_expr)\n        return str(simplified)\n    except Exception as e:\n        # If simplification fails, return original\n        return tree.get_infix()\n\ndef simplify_infix(infix_str):\n    \"\"\"\n    Takes an infix string and returns a simplified version.\n    \"\"\"\n    try:\n        expr = sp.sympify(infix_str)\n        simplified = sp.simplify(expr)\n        return str(simplified)\n    except:\n        return infix_str\n\n# Quick test\nif __name__ == \"__main__\":\n    from core.grammar import ExpressionTree\n    \n    # Test: x + 0 should simplify to x\n    tokens = ['+', 'x', '0']\n    tree = ExpressionTree(tokens)\n    print(f\"Original: {tree.get_infix()}\")\n    print(f\"Simplified: {simplify_tree(tree)}\")\n    \n    # Test: x * 1 should simplify to x\n    tokens2 = ['*', 'x', '1']\n    tree2 = ExpressionTree(tokens2)\n    print(f\"Original: {tree2.get_infix()}\")\n    print(f\"Simplified: {simplify_tree(tree2)}\")\n    \n    # Test: x - x should simplify to 0\n    tokens3 = ['-', 'x', 'x']\n    tree3 = ExpressionTree(tokens3)\n    print(f\"Original: {tree3.get_infix()}\")\n    print(f\"Simplified: {simplify_tree(tree3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/__init__.py\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"\nAlphaSymbolic - Gradio Web Interface\nWith GPU/CPU toggle and search method selection.\n\"\"\"\nimport gradio as gr\nimport torch\n\nfrom ui.app_core import load_model, get_device, get_device_info, set_device\nfrom ui.app_training import train_basic, train_curriculum, train_self_play\nfrom ui.app_search import solve_formula, generate_example\nfrom ui.app_benchmark import get_benchmark_tab\n\n\ndef toggle_device(use_gpu):\n    \"\"\"Toggle between GPU and CPU.\"\"\"\n    device_info = set_device(use_gpu)\n    color = \"#4ade80\" if \"CUDA\" in device_info else \"#fbbf24\" if \"MPS\" in device_info else \"#888\"\n    return f'<div style=\"padding: 10px; background: #0f0f23; border-radius: 8px; border-left: 3px solid {color};\"><span style=\"color: {color}; font-weight: bold;\">{device_info}</span></div>'\n\n\ndef create_app():\n    \"\"\"Create the Gradio app.\"\"\"\n    \n    with gr.Blocks(title=\"AlphaSymbolic\") as demo:\n        \n        # Header\n        device_info = get_device_info()\n        device_color = \"#4ade80\" if \"CUDA\" in device_info else \"#fbbf24\" if \"MPS\" in device_info else \"#888\"\n        \n        gr.HTML(f\"\"\"\n        <div style=\"text-align: center; padding: 20px; background: linear-gradient(90deg, #00d4ff22, transparent, #ff6b6b22); border-radius: 15px; margin-bottom: 20px;\">\n            <h1 style=\"color: #00d4ff; font-size: 42px; margin: 0;\">AlphaSymbolic</h1>\n            <p style=\"color: #888; font-size: 18px; margin: 5px 0;\">Deep Reinforcement Learning para Regresion Simbolica</p>\n        </div>\n        \"\"\")\n        \n        # System Controls\n        with gr.Row():\n            with gr.Column(scale=1):\n                model_selector = gr.Dropdown(choices=[\"lite\", \"pro\"], value=\"lite\", label=\"Arquitectura (Cerebro)\", interactive=True)\n            with gr.Column(scale=3):\n                model_status = gr.Textbox(label=\"Estado del Modelo\", value=\"Lite (Laptop Optimized) - Vocabulario Extendido\", interactive=False)\n        \n        def on_model_change(preset):\n            status, _ = load_model(preset_name=preset)\n            return status\n\n        model_selector.change(on_model_change, model_selector, model_status)\n        \n        with gr.Tabs():\n            # TAB 1: Search\n            with gr.Tab(\"Buscar Formula\"):\n                with gr.Row():\n                    with gr.Column(scale=1):\n                        gr.HTML('<h3 style=\"color: #00d4ff;\">Datos de Entrada</h3>')\n                        x_input = gr.Textbox(label=\"Valores X\", placeholder=\"1, 2, 3, 4, 5...\", lines=2)\n                        y_input = gr.Textbox(label=\"Valores Y\", placeholder=\"5, 7, 9, 11, 13...\", lines=2)\n                        \n                        with gr.Row():\n                            search_method = gr.Radio(\n                                choices=[\"Beam Search\", \"MCTS\"],\n                                value=\"Beam Search\",\n                                label=\"Metodo de Busqueda\"\n                            )\n                        \n                        beam_slider = gr.Slider(5, 50, value=15, step=5, label=\"Beam Width / Simulaciones\")\n                        \n                        solve_btn = gr.Button(\"Buscar Formula\", variant=\"primary\", size=\"lg\")\n                        \n                        with gr.Row():\n                            gr.Button(\"Lineal\", size=\"sm\").click(lambda: generate_example(\"lineal\"), outputs=[x_input, y_input])\n                            gr.Button(\"Cuadratico\", size=\"sm\").click(lambda: generate_example(\"cuadratico\"), outputs=[x_input, y_input])\n                            gr.Button(\"Seno\", size=\"sm\").click(lambda: generate_example(\"trig\"), outputs=[x_input, y_input])\n                            gr.Button(\"Exponencial\", size=\"sm\").click(lambda: generate_example(\"exp\"), outputs=[x_input, y_input])\n                    \n                    with gr.Column(scale=2):\n                        result_html = gr.HTML(label=\"Resultado\")\n                        plot_output = gr.Plot(label=\"Visualizacion\")\n                \n                with gr.Row():\n                    pred_html = gr.HTML(label=\"Predicciones\")\n                    alt_html = gr.HTML(label=\"Alternativas\")\n                \n                raw_formula = gr.Textbox(visible=False)\n                \n                solve_btn.click(solve_formula, [x_input, y_input, beam_slider, search_method], \n                               [result_html, plot_output, pred_html, alt_html, raw_formula])\n            \n            # TAB 2: Training\n            with gr.Tab(\"Entrenar Modelo\"):\n                with gr.Row():\n                    gr.HTML(\"\"\"\n                    <div style=\"background: #16213e; padding: 20px; border-radius: 10px; flex: 1;\">\n                        <h3 style=\"color: #ffd93d; margin: 0;\">Centro de Entrenamiento</h3>\n                    </div>\n                    \"\"\")\n                    with gr.Column():\n                        use_gpu = gr.Checkbox(label=\"Usar GPU\", value=torch.cuda.is_available())\n                        device_display = gr.HTML(value=f'<div style=\"padding: 10px; background: #0f0f23; border-radius: 8px; border-left: 3px solid {device_color};\"><span style=\"color: {device_color}; font-weight: bold;\">{device_info}</span></div>')\n                        use_gpu.change(toggle_device, [use_gpu], [device_display])\n                    with gr.Column():\n                        delete_model_btn = gr.Button(\"\ud83d\uddd1\ufe0f Borrar Modelo\", variant=\"secondary\", size=\"sm\")\n                        delete_status = gr.HTML()\n                        \n                        def delete_model_action():\n                            import os\n                            if os.path.exists(\"alpha_symbolic_model.pth\"):\n                                os.remove(\"alpha_symbolic_model.pth\")\n                                return '<div style=\"color: #ff6b6b; padding: 5px;\">\u2705 Modelo eliminado. Reinicia la app para usar pesos nuevos.</div>'\n                            return '<div style=\"color: #888; padding: 5px;\">No hay modelo guardado.</div>'\n                        \n                        delete_model_btn.click(delete_model_action, outputs=[delete_status])\n                \n                with gr.Tabs():\n                    # Basic\n                    with gr.Tab(\"Basico\"):\n                        gr.HTML('<p style=\"color: #888;\">Entrenamiento rapido con datos sinteticos</p>')\n                        with gr.Row():\n                            with gr.Column():\n                                epochs_basic = gr.Slider(10, 500, value=100, step=10, label=\"Epocas\")\n                                batch_basic = gr.Slider(16, 128, value=32, step=16, label=\"Batch Size\")\n                                points_basic = gr.Slider(10, 100, value=20, step=10, label=\"Puntos por Formula\")\n                                train_basic_btn = gr.Button(\"Entrenar Basico\", variant=\"primary\")\n                            with gr.Column():\n                                result_basic = gr.HTML()\n                                plot_basic = gr.Plot()\n                        train_basic_btn.click(train_basic, [epochs_basic, batch_basic, points_basic], [result_basic, plot_basic])\n                    \n                    # Curriculum\n                    with gr.Tab(\"Curriculum\"):\n                        gr.HTML('''\n                        <div style=\"background: #0f0f23; padding: 15px; border-radius: 8px; margin-bottom: 15px;\">\n                            <p style=\"color: #00d4ff; margin: 0;\"><strong>Curriculum Learning</strong></p>\n                            <p style=\"color: #888; margin: 5px 0 0 0;\">Empieza con formulas simples y aumenta la dificultad.</p>\n                        </div>\n                        ''')\n                        with gr.Row():\n                            with gr.Column():\n                                epochs_curriculum = gr.Slider(50, 2000, value=200, step=50, label=\"Epocas\")\n                                batch_curriculum = gr.Slider(16, 128, value=64, step=16, label=\"Batch Size\")\n                                points_curriculum = gr.Slider(10, 100, value=20, step=10, label=\"Puntos por Formula\")\n                                train_curriculum_btn = gr.Button(\"Entrenar Curriculum\", variant=\"primary\")\n                            with gr.Column():\n                                result_curriculum = gr.HTML()\n                                plot_curriculum = gr.Plot()\n                        train_curriculum_btn.click(train_curriculum, [epochs_curriculum, batch_curriculum, points_curriculum], [result_curriculum, plot_curriculum])\n                    \n                    # Self-Play\n                    with gr.Tab(\"Self-Play\"):\n                        gr.HTML('''\n                        <div style=\"background: #0f0f23; padding: 15px; border-radius: 8px; margin-bottom: 15px; border-left: 3px solid #ff6b6b;\">\n                            <p style=\"color: #ff6b6b; margin: 0;\"><strong>AlphaZero Self-Play</strong></p>\n                            <p style=\"color: #888; margin: 5px 0 0 0;\">El modelo resuelve problemas y aprende de sus exitos.</p>\n                        </div>\n                        ''')\n                        with gr.Row():\n                            with gr.Column():\n                                iterations_sp = gr.Slider(10, 1000, value=100, step=10, label=\"Iteraciones\")\n                                problems_sp = gr.Slider(5, 50, value=10, step=5, label=\"Problemas/Iter\")\n                                points_sp = gr.Slider(10, 100, value=20, step=10, label=\"Puntos por Formula\")\n                                train_sp_btn = gr.Button(\"Iniciar Self-Play\", variant=\"primary\")\n                            with gr.Column():\n                                result_sp = gr.HTML()\n                                plot_sp = gr.Plot()\n                        train_sp_btn.click(train_self_play, [iterations_sp, problems_sp, points_sp], [result_sp, plot_sp])\n            \n            # TAB 4: Benchmark\n            get_benchmark_tab()\n\n            # TAB 5: Info\n            with gr.Tab(\"Informacion\"):\n                device_info_current = get_device_info()\n                device_color_current = \"#4ade80\" if \"CUDA\" in device_info_current else \"#fbbf24\" if \"MPS\" in device_info_current else \"#888\"\n                \n                gr.HTML(f\"\"\"\n                <div style=\"background: #1a1a2e; padding: 30px; border-radius: 15px;\">\n                    <h2 style=\"color: #00d4ff;\">Que es AlphaSymbolic?</h2>\n                    <p style=\"color: #ccc; line-height: 1.8;\">\n                        Sistema de <strong style=\"color: #ff6b6b;\">regresion simbolica</strong> \n                        basado en <strong style=\"color: #00d4ff;\">Deep Learning</strong> y \n                        <strong style=\"color: #ffd93d;\">Monte Carlo Tree Search</strong>.\n                    </p>\n                    \n                    <h3 style=\"color: #00d4ff; margin-top: 30px;\">Dispositivo Actual</h3>\n                    <p style=\"color: {device_color_current}; font-size: 20px;\">{device_info_current}</p>\n                    \n                    <h3 style=\"color: #00d4ff; margin-top: 30px;\">Metodos de Busqueda</h3>\n                    <ul style=\"color: #ccc;\">\n                        <li><strong>Beam Search:</strong> Explora multiples candidatos en paralelo (rapido)</li>\n                        <li><strong>MCTS:</strong> Monte Carlo Tree Search (mas preciso, lento)</li>\n                    </ul>\n                    \n                    <h3 style=\"color: #00d4ff; margin-top: 30px;\">Operadores</h3>\n                    <div style=\"display: flex; flex-wrap: wrap; gap: 10px; margin: 15px 0;\">\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">+</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">-</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">*</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #00d4ff;\">/</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ff6b6b;\">sin</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ff6b6b;\">cos</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ffd93d;\">exp</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #ffd93d;\">log</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #4ade80;\">pow</span>\n                        <span style=\"background: #0f0f23; padding: 5px 15px; border-radius: 20px; color: #4ade80;\">sqrt</span>\n                    </div>\n                </div>\n                \"\"\")\n        \n        gr.HTML(\"\"\"\n        <div style=\"text-align: center; padding: 20px; color: #666; margin-top: 30px;\">\n            <p>Powered by PyTorch - SymPy - Scipy - Gradio</p>\n        </div>\n        \"\"\")\n    \n    return demo\n\n\nif __name__ == \"__main__\":\n    print(\"Iniciando AlphaSymbolic...\")\n    status, device_info = load_model()\n    print(f\"   {status} | {device_info}\")\n    print(\"Abriendo navegador...\")\n    \n    app = create_app()\n    app.launch(share=True, inbrowser=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the application\n",
        "!python app.py\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}